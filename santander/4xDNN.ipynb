{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# playing with data from https://www.kaggle.com/c/santander-customer-satisfaction\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import gmtime, strftime\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.learn as skflow\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from sklearn import datasets, cross_validation, metrics, preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(strftime(\"%H:%M:%S\", gmtime()))\n",
    "\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "data_id = data.pop('ID') # don't need\n",
    "\n",
    "data = data.sample(frac=1) # shuffle rows /// .reset_index(drop=True)\n",
    "\n",
    "data_target = data.pop('TARGET')\n",
    "\n",
    "X, y = data, data_target\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4)\n",
    "\n",
    "print(\"data loaded\")\n",
    "\n",
    "# adabas supports DecisionTreeClassifier or SGDClassifier\n",
    "\n",
    "print(data.shape)\n",
    "print(data_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danny/.local/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:688: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "# creating an addition column by running a standard classifier which appeared to\n",
    "# give a promising result, ROC =  0.547613084251\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "classifier = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "classifier.fit(X,y)\n",
    "# classifier.fit(X_train, y_train)\n",
    "\n",
    "result = classifier.predict(X)\n",
    "# result = classifier.predict(X_test)\n",
    "\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# print(\"ROC = \",roc_auc_score(result, y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b1cab886c1a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_target\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "print(result.shape)\n",
    "print(data.shape)\n",
    "\n",
    "X, y = data, data_target\n",
    "\n",
    "X['Q'] = result\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "# scale values\n",
    "# X = StandardScaler().fit_transform(X)\n",
    "X.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dnn0\n",
      "Step #100, epoch #1, avg. train loss: 45393.71484\n",
      "Step #200, epoch #2, avg. train loss: 0.39721\n",
      "Step #300, epoch #3, avg. train loss: 1.50730\n",
      "Step #400, epoch #4, avg. train loss: 0.23359\n",
      "Step #500, epoch #5, avg. train loss: 0.20111\n",
      "Step #600, epoch #6, avg. train loss: 0.19703\n",
      "Step #700, epoch #7, avg. train loss: 0.19281\n",
      "Step #800, epoch #8, avg. train loss: 0.19869\n",
      "Step #900, epoch #10, avg. train loss: 0.18905\n",
      "Step #1000, epoch #11, avg. train loss: 0.18937\n",
      "Step #1100, epoch #12, avg. train loss: 0.18452\n",
      "Step #1200, epoch #13, avg. train loss: 0.18560\n",
      "Step #1300, epoch #14, avg. train loss: 0.18526\n",
      "Step #1400, epoch #15, avg. train loss: 0.18518\n",
      "Step #1500, epoch #16, avg. train loss: 0.18054\n",
      "Step #1600, epoch #17, avg. train loss: 0.18523\n",
      "Step #1700, epoch #18, avg. train loss: 0.18163\n",
      "Step #1800, epoch #20, avg. train loss: 0.18135\n",
      "Step #1900, epoch #21, avg. train loss: 0.18456\n",
      "Step #2000, epoch #22, avg. train loss: 0.17986\n",
      "Step #2100, epoch #23, avg. train loss: 0.18406\n",
      "Step #2200, epoch #24, avg. train loss: 0.17908\n",
      "Step #2300, epoch #25, avg. train loss: 0.17730\n",
      "Step #2400, epoch #26, avg. train loss: 0.18485\n",
      "Step #2500, epoch #27, avg. train loss: 0.17623\n",
      "Step #2600, epoch #28, avg. train loss: 0.17966\n",
      "Step #2700, epoch #30, avg. train loss: 0.17547\n",
      "Step #2800, epoch #31, avg. train loss: 0.17699\n",
      "Step #2900, epoch #32, avg. train loss: 0.17678\n",
      "Step #3000, epoch #33, avg. train loss: 0.17668\n",
      "Step #3100, epoch #34, avg. train loss: 0.17753\n",
      "Step #3200, epoch #35, avg. train loss: 0.17723\n",
      "Step #3300, epoch #36, avg. train loss: 0.17576\n",
      "Step #3400, epoch #37, avg. train loss: 0.17522\n",
      "Step #3500, epoch #38, avg. train loss: 0.17653\n",
      "Step #3600, epoch #40, avg. train loss: 0.17606\n",
      "Step #3700, epoch #41, avg. train loss: 0.17472\n",
      "Step #3800, epoch #42, avg. train loss: 0.17471\n",
      "Step #3900, epoch #43, avg. train loss: 0.17508\n",
      "Step #4000, epoch #44, avg. train loss: 0.17479\n",
      "Step #4100, epoch #45, avg. train loss: 0.17675\n",
      "Step #4200, epoch #46, avg. train loss: 0.17358\n",
      "Step #4300, epoch #47, avg. train loss: 0.17294\n",
      "Step #4400, epoch #48, avg. train loss: 0.17557\n",
      "Step #4500, epoch #50, avg. train loss: 0.17462\n",
      "Step #4600, epoch #51, avg. train loss: 0.17521\n",
      "Step #4700, epoch #52, avg. train loss: 0.17321\n",
      "Step #4800, epoch #53, avg. train loss: 0.17255\n",
      "Step #4900, epoch #54, avg. train loss: 0.17595\n",
      "Step #5000, epoch #55, avg. train loss: 0.17310\n",
      "Step #5100, epoch #56, avg. train loss: 0.17031\n",
      "Step #5200, epoch #57, avg. train loss: 0.17511\n",
      "Step #5300, epoch #58, avg. train loss: 0.17281\n",
      "Step #5400, epoch #60, avg. train loss: 0.17422\n",
      "Step #5500, epoch #61, avg. train loss: 0.17337\n",
      "Step #5600, epoch #62, avg. train loss: 0.17123\n",
      "Step #5700, epoch #63, avg. train loss: 0.17519\n",
      "Step #5800, epoch #64, avg. train loss: 0.17268\n",
      "Step #5900, epoch #65, avg. train loss: 0.17219\n",
      "Step #6000, epoch #66, avg. train loss: 0.17452\n",
      "Step #6100, epoch #67, avg. train loss: 0.17274\n",
      "Step #6200, epoch #68, avg. train loss: 0.17143\n",
      "Step #6300, epoch #70, avg. train loss: 0.17199\n",
      "Step #6400, epoch #71, avg. train loss: 0.17166\n",
      "Step #6500, epoch #72, avg. train loss: 0.17431\n",
      "Step #6600, epoch #73, avg. train loss: 0.17220\n",
      "Step #6700, epoch #74, avg. train loss: 0.17389\n",
      "Step #6800, epoch #75, avg. train loss: 0.17216\n",
      "Step #6900, epoch #76, avg. train loss: 0.17263\n",
      "Step #7000, epoch #77, avg. train loss: 0.16920\n",
      "Step #7100, epoch #78, avg. train loss: 0.17456\n",
      "Step #7200, epoch #80, avg. train loss: 0.17485\n",
      "Step #7300, epoch #81, avg. train loss: 0.17248\n",
      "Step #7400, epoch #82, avg. train loss: 0.17136\n",
      "Step #7500, epoch #83, avg. train loss: 0.16990\n",
      "Step #7600, epoch #84, avg. train loss: 0.17440\n",
      "Step #7700, epoch #85, avg. train loss: 0.17122\n",
      "Step #7800, epoch #86, avg. train loss: 0.17054\n",
      "Step #7900, epoch #87, avg. train loss: 0.16946\n",
      "Step #8000, epoch #88, avg. train loss: 0.17169\n",
      "Step #8100, epoch #90, avg. train loss: 0.16984\n",
      "Step #8200, epoch #91, avg. train loss: 0.17229\n",
      "Step #8300, epoch #92, avg. train loss: 0.17099\n",
      "Step #8400, epoch #93, avg. train loss: 0.16810\n",
      "Step #8500, epoch #94, avg. train loss: 0.17091\n",
      "Step #8600, epoch #95, avg. train loss: 0.17128\n",
      "Step #8700, epoch #96, avg. train loss: 0.17090\n",
      "Step #8800, epoch #97, avg. train loss: 0.17189\n",
      "Step #8900, epoch #98, avg. train loss: 0.16802\n",
      "Step #9000, epoch #100, avg. train loss: 0.17020\n",
      "Step #9100, epoch #101, avg. train loss: 0.16937\n",
      "Step #9200, epoch #102, avg. train loss: 0.17181\n",
      "Step #9300, epoch #103, avg. train loss: 0.16545\n",
      "Step #9400, epoch #104, avg. train loss: 0.17025\n",
      "Step #9500, epoch #105, avg. train loss: 0.17053\n",
      "Step #9600, epoch #106, avg. train loss: 0.17115\n",
      "Step #9700, epoch #107, avg. train loss: 0.16937\n",
      "Step #9800, epoch #108, avg. train loss: 0.17145\n",
      "Step #9900, epoch #110, avg. train loss: 0.16714\n",
      "Step #10000, epoch #111, avg. train loss: 0.16971\n",
      "ROC =  0.499982862039\n",
      "dnn1\n",
      "Step #100, epoch #1, avg. train loss: 147583.39062\n",
      "Step #200, epoch #2, avg. train loss: 7993.19727\n",
      "Step #300, epoch #3, avg. train loss: 8358.84375\n",
      "Step #400, epoch #4, avg. train loss: 8379.88867\n",
      "Step #500, epoch #5, avg. train loss: 327.58279\n",
      "Step #600, epoch #6, avg. train loss: 0.16414\n",
      "Step #700, epoch #7, avg. train loss: 0.38309\n",
      "Step #800, epoch #8, avg. train loss: 0.16430\n",
      "Step #900, epoch #10, avg. train loss: 25342.41016\n",
      "Step #1000, epoch #11, avg. train loss: 2342.97168\n",
      "Step #1100, epoch #12, avg. train loss: 0.16146\n",
      "Step #1200, epoch #13, avg. train loss: 0.16583\n",
      "Step #1300, epoch #14, avg. train loss: 0.16416\n",
      "Step #1400, epoch #15, avg. train loss: 0.16645\n",
      "Step #1500, epoch #16, avg. train loss: 0.16359\n",
      "Step #1600, epoch #17, avg. train loss: 0.16611\n",
      "Step #1700, epoch #18, avg. train loss: 0.16477\n",
      "Step #1800, epoch #20, avg. train loss: 0.16223\n",
      "Step #1900, epoch #21, avg. train loss: 0.16573\n",
      "Step #2000, epoch #22, avg. train loss: 0.16387\n",
      "Step #2100, epoch #23, avg. train loss: 0.16620\n",
      "Step #2200, epoch #24, avg. train loss: 0.16311\n",
      "Step #2300, epoch #25, avg. train loss: 0.16233\n",
      "Step #2400, epoch #26, avg. train loss: 0.16744\n",
      "Step #2500, epoch #27, avg. train loss: 0.16273\n",
      "Step #2600, epoch #28, avg. train loss: 0.16498\n",
      "Step #2700, epoch #30, avg. train loss: 0.16230\n",
      "Step #2800, epoch #31, avg. train loss: 0.16315\n",
      "Step #2900, epoch #32, avg. train loss: 0.16413\n",
      "Step #3000, epoch #33, avg. train loss: 44.70672\n",
      "Step #3100, epoch #34, avg. train loss: 0.16305\n",
      "Step #3200, epoch #35, avg. train loss: 0.16361\n",
      "Step #3300, epoch #36, avg. train loss: 0.16457\n",
      "Step #3400, epoch #37, avg. train loss: 0.16250\n",
      "Step #3500, epoch #38, avg. train loss: 0.16453\n",
      "Step #3600, epoch #40, avg. train loss: 0.16467\n",
      "Step #3700, epoch #41, avg. train loss: 0.16451\n",
      "Step #3800, epoch #42, avg. train loss: 0.16177\n",
      "Step #3900, epoch #43, avg. train loss: 0.16595\n",
      "Step #4000, epoch #44, avg. train loss: 0.16264\n",
      "Step #4100, epoch #45, avg. train loss: 0.16821\n",
      "Step #4200, epoch #46, avg. train loss: 0.16189\n",
      "Step #4300, epoch #47, avg. train loss: 0.16289\n",
      "Step #4400, epoch #48, avg. train loss: 0.16665\n",
      "Step #4500, epoch #50, avg. train loss: 0.16409\n",
      "Step #4600, epoch #51, avg. train loss: 0.16485\n",
      "Step #4700, epoch #52, avg. train loss: 0.16299\n",
      "Step #4800, epoch #53, avg. train loss: 0.16289\n",
      "Step #4900, epoch #54, avg. train loss: 0.16538\n",
      "Step #5000, epoch #55, avg. train loss: 0.16510\n",
      "Step #5100, epoch #56, avg. train loss: 0.16142\n",
      "Step #5200, epoch #57, avg. train loss: 0.16741\n",
      "Step #5300, epoch #58, avg. train loss: 0.16364\n",
      "Step #5400, epoch #60, avg. train loss: 0.16368\n",
      "Step #5500, epoch #61, avg. train loss: 0.16558\n",
      "Step #5600, epoch #62, avg. train loss: 0.16267\n",
      "Step #5700, epoch #63, avg. train loss: 0.16543\n",
      "Step #5800, epoch #64, avg. train loss: 0.16461\n",
      "Step #5900, epoch #65, avg. train loss: 0.16297\n",
      "Step #6000, epoch #66, avg. train loss: 0.16673\n",
      "Step #6100, epoch #67, avg. train loss: 0.16379\n",
      "Step #6200, epoch #68, avg. train loss: 0.16342\n",
      "Step #6300, epoch #70, avg. train loss: 0.16350\n",
      "Step #6400, epoch #71, avg. train loss: 0.16279\n",
      "Step #6500, epoch #72, avg. train loss: 0.16608\n",
      "Step #6600, epoch #73, avg. train loss: 0.16476\n",
      "Step #6700, epoch #74, avg. train loss: 0.16608\n",
      "Step #6800, epoch #75, avg. train loss: 0.16429\n",
      "Step #6900, epoch #76, avg. train loss: 0.16400\n",
      "Step #7000, epoch #77, avg. train loss: 0.16159\n",
      "Step #7100, epoch #78, avg. train loss: 0.16718\n",
      "Step #7200, epoch #80, avg. train loss: 0.16405\n",
      "Step #7300, epoch #81, avg. train loss: 0.16481\n",
      "Step #7400, epoch #82, avg. train loss: 0.16600\n",
      "Step #7500, epoch #83, avg. train loss: 0.16431\n",
      "Step #7600, epoch #84, avg. train loss: 0.16634\n",
      "Step #7700, epoch #85, avg. train loss: 0.16373\n",
      "Step #7800, epoch #86, avg. train loss: 0.16408\n",
      "Step #7900, epoch #87, avg. train loss: 0.16275\n",
      "Step #8000, epoch #88, avg. train loss: 0.16524\n",
      "Step #8100, epoch #90, avg. train loss: 0.16222\n",
      "Step #8200, epoch #91, avg. train loss: 0.16460\n",
      "Step #8300, epoch #92, avg. train loss: 0.16642\n",
      "Step #8400, epoch #93, avg. train loss: 0.16084\n",
      "Step #8500, epoch #94, avg. train loss: 0.16429\n",
      "Step #8600, epoch #95, avg. train loss: 0.16529\n",
      "Step #8700, epoch #96, avg. train loss: 0.16515\n",
      "Step #8800, epoch #97, avg. train loss: 0.16581\n",
      "Step #8900, epoch #98, avg. train loss: 0.16246\n",
      "Step #9000, epoch #100, avg. train loss: 0.16458\n",
      "Step #9100, epoch #101, avg. train loss: 0.16373\n",
      "Step #9200, epoch #102, avg. train loss: 0.16603\n",
      "Step #9300, epoch #103, avg. train loss: 0.16162\n",
      "Step #9400, epoch #104, avg. train loss: 0.16565\n",
      "Step #9500, epoch #105, avg. train loss: 0.16296\n",
      "Step #9600, epoch #106, avg. train loss: 0.16717\n",
      "Step #9700, epoch #107, avg. train loss: 0.16331\n",
      "Step #9800, epoch #108, avg. train loss: 0.16707\n",
      "Step #9900, epoch #110, avg. train loss: 0.16249\n",
      "Step #10000, epoch #111, avg. train loss: 0.16477\n",
      "Step #10100, epoch #112, avg. train loss: 0.16663\n",
      "Step #10200, epoch #113, avg. train loss: 0.16495\n",
      "Step #10300, epoch #114, avg. train loss: 0.16077\n",
      "Step #10400, epoch #115, avg. train loss: 0.16869\n",
      "Step #10500, epoch #116, avg. train loss: 0.16383\n",
      "Step #10600, epoch #117, avg. train loss: 0.16259\n",
      "Step #10700, epoch #118, avg. train loss: 0.16515\n",
      "Step #10800, epoch #120, avg. train loss: 0.16548\n",
      "Step #10900, epoch #121, avg. train loss: 0.16450\n",
      "Step #11000, epoch #122, avg. train loss: 0.16317\n",
      "Step #11100, epoch #123, avg. train loss: 0.16521\n",
      "Step #11200, epoch #124, avg. train loss: 0.16506\n",
      "Step #11300, epoch #125, avg. train loss: 0.16499\n",
      "Step #11400, epoch #126, avg. train loss: 0.16145\n",
      "Step #11500, epoch #127, avg. train loss: 0.16520\n",
      "Step #11600, epoch #128, avg. train loss: 0.16309\n",
      "Step #11700, epoch #130, avg. train loss: 0.16679\n",
      "Step #11800, epoch #131, avg. train loss: 0.16552\n",
      "Step #11900, epoch #132, avg. train loss: 0.16317\n",
      "Step #12000, epoch #133, avg. train loss: 0.16429\n",
      "Step #12100, epoch #134, avg. train loss: 11091.10254\n",
      "Step #12200, epoch #135, avg. train loss: 0.16230\n",
      "Step #12300, epoch #136, avg. train loss: 0.16609\n",
      "Step #12400, epoch #137, avg. train loss: 0.20124\n",
      "Step #12500, epoch #138, avg. train loss: 0.16894\n",
      "Step #12600, epoch #140, avg. train loss: 0.16536\n",
      "Step #12700, epoch #141, avg. train loss: 0.16491\n",
      "Step #12800, epoch #142, avg. train loss: 0.16390\n",
      "Step #12900, epoch #143, avg. train loss: 0.16365\n",
      "Step #13000, epoch #144, avg. train loss: 0.16445\n",
      "Step #13100, epoch #145, avg. train loss: 0.16126\n",
      "Step #13200, epoch #146, avg. train loss: 0.16855\n",
      "Step #13300, epoch #147, avg. train loss: 0.16641\n",
      "Step #13400, epoch #148, avg. train loss: 0.16226\n",
      "Step #13500, epoch #150, avg. train loss: 0.16479\n",
      "Step #13600, epoch #151, avg. train loss: 0.16611\n",
      "Step #13700, epoch #152, avg. train loss: 0.16446\n",
      "Step #13800, epoch #153, avg. train loss: 0.16381\n",
      "Step #13900, epoch #154, avg. train loss: 0.16340\n",
      "Step #14000, epoch #155, avg. train loss: 0.16481\n",
      "Step #14100, epoch #156, avg. train loss: 0.16443\n",
      "Step #14200, epoch #157, avg. train loss: 0.16665\n",
      "Step #14300, epoch #158, avg. train loss: 0.16226\n",
      "Step #14400, epoch #160, avg. train loss: 0.16353\n",
      "Step #14500, epoch #161, avg. train loss: 0.16507\n",
      "Step #14600, epoch #162, avg. train loss: 0.16448\n",
      "Step #14700, epoch #163, avg. train loss: 0.16189\n",
      "Step #14800, epoch #164, avg. train loss: 0.16856\n",
      "Step #14900, epoch #165, avg. train loss: 0.16391\n",
      "Step #15000, epoch #166, avg. train loss: 0.16484\n",
      "Step #15100, epoch #167, avg. train loss: 0.16143\n",
      "Step #15200, epoch #168, avg. train loss: 0.16363\n",
      "Step #15300, epoch #170, avg. train loss: 0.16489\n",
      "Step #15400, epoch #171, avg. train loss: 0.16406\n",
      "Step #15500, epoch #172, avg. train loss: 0.16422\n",
      "Step #15600, epoch #173, avg. train loss: 0.16703\n",
      "Step #15700, epoch #174, avg. train loss: 0.16454\n",
      "Step #15800, epoch #175, avg. train loss: 0.16105\n",
      "Step #15900, epoch #176, avg. train loss: 0.16572\n",
      "Step #16000, epoch #177, avg. train loss: 0.16412\n",
      "Step #16100, epoch #178, avg. train loss: 0.16563\n",
      "Step #16200, epoch #180, avg. train loss: 0.16445\n",
      "Step #16300, epoch #181, avg. train loss: 0.16430\n",
      "Step #16400, epoch #182, avg. train loss: 0.16545\n",
      "Step #16500, epoch #183, avg. train loss: 0.16335\n",
      "Step #16600, epoch #184, avg. train loss: 0.16156\n",
      "Step #16700, epoch #185, avg. train loss: 0.16777\n",
      "Step #16800, epoch #186, avg. train loss: 0.16320\n",
      "Step #16900, epoch #187, avg. train loss: 0.16521\n",
      "Step #17000, epoch #188, avg. train loss: 0.16478\n",
      "Step #17100, epoch #190, avg. train loss: 0.16374\n",
      "Step #17200, epoch #191, avg. train loss: 0.16427\n",
      "Step #17300, epoch #192, avg. train loss: 0.16521\n",
      "Step #17400, epoch #193, avg. train loss: 0.16452\n",
      "Step #17500, epoch #194, avg. train loss: 0.16211\n",
      "Step #17600, epoch #195, avg. train loss: 0.16755\n",
      "Step #17700, epoch #196, avg. train loss: 0.16454\n",
      "Step #17800, epoch #197, avg. train loss: 0.16171\n",
      "Step #17900, epoch #198, avg. train loss: 0.16473\n",
      "Step #18000, epoch #200, avg. train loss: 0.16399\n",
      "Step #18100, epoch #201, avg. train loss: 0.16355\n",
      "Step #18200, epoch #202, avg. train loss: 0.16671\n",
      "Step #18300, epoch #203, avg. train loss: 0.16639\n",
      "Step #18400, epoch #204, avg. train loss: 0.16102\n",
      "Step #18500, epoch #205, avg. train loss: 0.16203\n",
      "Step #18600, epoch #206, avg. train loss: 0.16948\n",
      "Step #18700, epoch #207, avg. train loss: 0.16390\n",
      "Step #18800, epoch #208, avg. train loss: 0.16477\n",
      "Step #18900, epoch #210, avg. train loss: 0.16289\n",
      "Step #19000, epoch #211, avg. train loss: 0.16436\n",
      "Step #19100, epoch #212, avg. train loss: 0.16422\n",
      "Step #19200, epoch #213, avg. train loss: 0.16481\n",
      "Step #19300, epoch #214, avg. train loss: 0.16218\n",
      "Step #19400, epoch #215, avg. train loss: 0.16569\n",
      "Step #19500, epoch #216, avg. train loss: 0.16531\n",
      "Step #19600, epoch #217, avg. train loss: 0.16501\n",
      "Step #19700, epoch #218, avg. train loss: 0.16283\n",
      "Step #19800, epoch #220, avg. train loss: 0.16296\n",
      "Step #19900, epoch #221, avg. train loss: 0.16479\n",
      "Step #20000, epoch #222, avg. train loss: 0.16629\n",
      "Step #20100, epoch #223, avg. train loss: 0.16432\n",
      "Step #20200, epoch #224, avg. train loss: 0.16245\n",
      "Step #20300, epoch #225, avg. train loss: 0.16576\n",
      "Step #20400, epoch #226, avg. train loss: 0.16340\n",
      "Step #20500, epoch #227, avg. train loss: 0.16586\n",
      "Step #20600, epoch #228, avg. train loss: 0.16555\n",
      "Step #20700, epoch #230, avg. train loss: 0.16502\n",
      "Step #20800, epoch #231, avg. train loss: 0.16350\n",
      "Step #20900, epoch #232, avg. train loss: 0.16476\n",
      "Step #21000, epoch #233, avg. train loss: 0.16522\n",
      "Step #21100, epoch #234, avg. train loss: 0.16116\n",
      "Step #21200, epoch #235, avg. train loss: 0.16510\n",
      "Step #21300, epoch #236, avg. train loss: 0.16318\n",
      "Step #21400, epoch #237, avg. train loss: 257.55838\n",
      "Step #21500, epoch #238, avg. train loss: 0.16285\n",
      "Step #21600, epoch #240, avg. train loss: 0.16465\n",
      "Step #21700, epoch #241, avg. train loss: 0.16199\n",
      "Step #21800, epoch #242, avg. train loss: 0.16377\n",
      "Step #21900, epoch #243, avg. train loss: 0.16717\n",
      "Step #22000, epoch #244, avg. train loss: 0.16476\n",
      "Step #22100, epoch #245, avg. train loss: 0.16549\n",
      "Step #22200, epoch #246, avg. train loss: 0.16263\n",
      "Step #22300, epoch #247, avg. train loss: 0.16569\n",
      "Step #22400, epoch #248, avg. train loss: 0.16498\n",
      "Step #22500, epoch #250, avg. train loss: 0.16297\n",
      "Step #22600, epoch #251, avg. train loss: 0.16310\n",
      "Step #22700, epoch #252, avg. train loss: 0.16628\n",
      "Step #22800, epoch #253, avg. train loss: 0.16559\n",
      "Step #22900, epoch #254, avg. train loss: 0.16520\n",
      "Step #23000, epoch #255, avg. train loss: 0.16384\n",
      "Step #23100, epoch #256, avg. train loss: 0.16329\n",
      "Step #23200, epoch #257, avg. train loss: 0.16616\n",
      "Step #23300, epoch #258, avg. train loss: 0.16370\n",
      "Step #23400, epoch #260, avg. train loss: 0.16286\n",
      "Step #23500, epoch #261, avg. train loss: 0.16495\n",
      "Step #23600, epoch #262, avg. train loss: 0.16466\n",
      "Step #23700, epoch #263, avg. train loss: 0.16138\n",
      "Step #23800, epoch #264, avg. train loss: 0.16879\n",
      "Step #23900, epoch #265, avg. train loss: 0.16317\n",
      "Step #24000, epoch #266, avg. train loss: 0.16261\n",
      "Step #24100, epoch #267, avg. train loss: 0.16553\n",
      "Step #24200, epoch #268, avg. train loss: 0.16374\n",
      "Step #24300, epoch #270, avg. train loss: 0.16457\n",
      "Step #24400, epoch #271, avg. train loss: 0.16335\n",
      "Step #24500, epoch #272, avg. train loss: 0.16441\n",
      "Step #24600, epoch #273, avg. train loss: 0.16520\n",
      "Step #24700, epoch #274, avg. train loss: 0.16013\n",
      "Step #24800, epoch #275, avg. train loss: 0.16945\n",
      "Step #24900, epoch #276, avg. train loss: 0.16321\n",
      "Step #25000, epoch #277, avg. train loss: 0.16541\n",
      "Step #25100, epoch #278, avg. train loss: 0.16552\n",
      "Step #25200, epoch #280, avg. train loss: 0.16405\n",
      "Step #25300, epoch #281, avg. train loss: 0.16467\n",
      "Step #25400, epoch #282, avg. train loss: 0.16245\n",
      "Step #25500, epoch #283, avg. train loss: 0.16792\n",
      "Step #25600, epoch #284, avg. train loss: 0.16243\n",
      "Step #25700, epoch #285, avg. train loss: 0.16396\n",
      "Step #25800, epoch #286, avg. train loss: 0.16639\n",
      "Step #25900, epoch #287, avg. train loss: 0.16367\n",
      "Step #26000, epoch #288, avg. train loss: 0.16370\n",
      "Step #26100, epoch #290, avg. train loss: 0.16399\n",
      "Step #26200, epoch #291, avg. train loss: 0.16562\n",
      "Step #26300, epoch #292, avg. train loss: 0.16303\n",
      "Step #26400, epoch #293, avg. train loss: 0.16404\n",
      "Step #26500, epoch #294, avg. train loss: 0.16476\n",
      "Step #26600, epoch #295, avg. train loss: 0.16330\n",
      "Step #26700, epoch #296, avg. train loss: 0.16499\n",
      "Step #26800, epoch #297, avg. train loss: 0.16632\n",
      "Step #26900, epoch #298, avg. train loss: 0.16327\n",
      "Step #27000, epoch #300, avg. train loss: 0.16336\n",
      "Step #27100, epoch #301, avg. train loss: 0.16476\n",
      "Step #27200, epoch #302, avg. train loss: 0.16278\n",
      "Step #27300, epoch #303, avg. train loss: 0.16424\n",
      "Step #27400, epoch #304, avg. train loss: 0.16768\n",
      "Step #27500, epoch #305, avg. train loss: 0.16327\n",
      "Step #27600, epoch #306, avg. train loss: 0.16607\n",
      "Step #27700, epoch #307, avg. train loss: 0.16254\n",
      "Step #27800, epoch #308, avg. train loss: 0.16328\n",
      "Step #27900, epoch #310, avg. train loss: 0.16462\n",
      "Step #28000, epoch #311, avg. train loss: 0.16401\n",
      "Step #28100, epoch #312, avg. train loss: 0.16266\n",
      "Step #28200, epoch #313, avg. train loss: 0.16583\n",
      "Step #28300, epoch #314, avg. train loss: 0.16329\n",
      "Step #28400, epoch #315, avg. train loss: 0.16658\n",
      "Step #28500, epoch #316, avg. train loss: 0.16661\n",
      "Step #28600, epoch #317, avg. train loss: 0.16421\n",
      "Step #28700, epoch #318, avg. train loss: 0.16677\n",
      "Step #28800, epoch #320, avg. train loss: 0.16472\n",
      "Step #28900, epoch #321, avg. train loss: 0.16508\n",
      "Step #29000, epoch #322, avg. train loss: 0.16273\n",
      "Step #29100, epoch #323, avg. train loss: 0.16689\n",
      "Step #29200, epoch #324, avg. train loss: 0.16566\n",
      "Step #29300, epoch #325, avg. train loss: 0.16478\n",
      "Step #29400, epoch #326, avg. train loss: 0.16769\n",
      "Step #29500, epoch #327, avg. train loss: 0.16266\n",
      "Step #29600, epoch #328, avg. train loss: 0.16380\n",
      "Step #29700, epoch #330, avg. train loss: 0.16815\n",
      "Step #29800, epoch #331, avg. train loss: 0.16422\n",
      "Step #29900, epoch #332, avg. train loss: 0.16534\n",
      "Step #30000, epoch #333, avg. train loss: 0.16125\n",
      "Step #30100, epoch #334, avg. train loss: 0.16617\n",
      "Step #30200, epoch #335, avg. train loss: 0.16514\n",
      "Step #30300, epoch #336, avg. train loss: 0.16321\n",
      "Step #30400, epoch #337, avg. train loss: 0.16517\n",
      "Step #30500, epoch #338, avg. train loss: 0.16250\n",
      "Step #30600, epoch #340, avg. train loss: 0.16569\n",
      "Step #30700, epoch #341, avg. train loss: 0.16477\n",
      "Step #30800, epoch #342, avg. train loss: 0.16299\n",
      "Step #30900, epoch #343, avg. train loss: 0.16450\n",
      "Step #31000, epoch #344, avg. train loss: 0.16472\n",
      "Step #31100, epoch #345, avg. train loss: 0.16573\n",
      "Step #31200, epoch #346, avg. train loss: 0.16558\n",
      "Step #31300, epoch #347, avg. train loss: 0.16198\n",
      "Step #31400, epoch #348, avg. train loss: 0.16410\n",
      "Step #31500, epoch #350, avg. train loss: 0.16501\n",
      "Step #31600, epoch #351, avg. train loss: 0.16572\n",
      "Step #31700, epoch #352, avg. train loss: 0.16349\n",
      "Step #31800, epoch #353, avg. train loss: 0.16479\n",
      "Step #31900, epoch #354, avg. train loss: 0.16412\n",
      "Step #32000, epoch #355, avg. train loss: 0.16771\n",
      "Step #32100, epoch #356, avg. train loss: 0.16296\n",
      "Step #32200, epoch #357, avg. train loss: 0.16685\n",
      "Step #32300, epoch #358, avg. train loss: 0.16479\n",
      "Step #32400, epoch #360, avg. train loss: 0.16494\n",
      "Step #32500, epoch #361, avg. train loss: 0.16439\n",
      "Step #32600, epoch #362, avg. train loss: 0.16341\n",
      "Step #32700, epoch #363, avg. train loss: 0.16373\n",
      "Step #32800, epoch #364, avg. train loss: 0.16544\n",
      "Step #32900, epoch #365, avg. train loss: 0.16450\n",
      "Step #33000, epoch #366, avg. train loss: 0.16664\n",
      "Step #33100, epoch #367, avg. train loss: 0.16248\n",
      "Step #33200, epoch #368, avg. train loss: 0.16637\n",
      "Step #33300, epoch #370, avg. train loss: 0.16373\n",
      "Step #33400, epoch #371, avg. train loss: 0.16313\n",
      "Step #33500, epoch #372, avg. train loss: 0.16389\n",
      "Step #33600, epoch #373, avg. train loss: 0.16547\n",
      "Step #33700, epoch #374, avg. train loss: 0.16170\n",
      "Step #33800, epoch #375, avg. train loss: 0.16799\n",
      "Step #33900, epoch #376, avg. train loss: 0.16455\n",
      "Step #34000, epoch #377, avg. train loss: 0.16313\n",
      "Step #34100, epoch #378, avg. train loss: 0.16739\n",
      "Step #34200, epoch #380, avg. train loss: 0.16214\n",
      "Step #34300, epoch #381, avg. train loss: 0.16581\n",
      "Step #34400, epoch #382, avg. train loss: 0.16301\n",
      "Step #34500, epoch #383, avg. train loss: 0.16589\n",
      "Step #34600, epoch #384, avg. train loss: 0.16462\n",
      "Step #34700, epoch #385, avg. train loss: 0.15941\n",
      "Step #34800, epoch #386, avg. train loss: 0.16598\n",
      "Step #34900, epoch #387, avg. train loss: 0.16487\n",
      "Step #35000, epoch #388, avg. train loss: 0.16343\n",
      "Step #35100, epoch #390, avg. train loss: 0.16309\n",
      "Step #35200, epoch #391, avg. train loss: 0.16460\n",
      "Step #35300, epoch #392, avg. train loss: 0.16221\n",
      "Step #35400, epoch #393, avg. train loss: 0.16805\n",
      "Step #35500, epoch #394, avg. train loss: 0.16523\n",
      "Step #35600, epoch #395, avg. train loss: 0.16023\n",
      "Step #35700, epoch #396, avg. train loss: 0.16663\n",
      "Step #35800, epoch #397, avg. train loss: 0.16015\n",
      "Step #35900, epoch #398, avg. train loss: 0.16810\n",
      "Step #36000, epoch #400, avg. train loss: 0.16409\n",
      "Step #36100, epoch #401, avg. train loss: 0.16540\n",
      "Step #36200, epoch #402, avg. train loss: 0.16613\n",
      "Step #36300, epoch #403, avg. train loss: 0.16478\n",
      "Step #36400, epoch #404, avg. train loss: 0.16522\n",
      "Step #36500, epoch #405, avg. train loss: 0.16732\n",
      "Step #36600, epoch #406, avg. train loss: 0.16049\n",
      "Step #36700, epoch #407, avg. train loss: 0.16673\n",
      "Step #36800, epoch #408, avg. train loss: 0.16535\n",
      "Step #36900, epoch #410, avg. train loss: 0.16276\n",
      "Step #37000, epoch #411, avg. train loss: 0.16598\n",
      "Step #37100, epoch #412, avg. train loss: 0.16345\n",
      "Step #37200, epoch #413, avg. train loss: 0.16303\n",
      "Step #37300, epoch #414, avg. train loss: 0.16563\n",
      "Step #37400, epoch #415, avg. train loss: 0.15991\n",
      "Step #37500, epoch #416, avg. train loss: 0.16744\n",
      "Step #37600, epoch #417, avg. train loss: 0.16439\n",
      "Step #37700, epoch #418, avg. train loss: 0.16328\n",
      "Step #37800, epoch #420, avg. train loss: 0.16425\n",
      "Step #37900, epoch #421, avg. train loss: 0.16491\n",
      "Step #38000, epoch #422, avg. train loss: 0.16417\n",
      "Step #38100, epoch #423, avg. train loss: 0.16206\n",
      "Step #38200, epoch #424, avg. train loss: 0.16427\n",
      "Step #38300, epoch #425, avg. train loss: 0.16734\n",
      "Step #38400, epoch #426, avg. train loss: 0.16413\n",
      "Step #38500, epoch #427, avg. train loss: 0.16240\n",
      "Step #38600, epoch #428, avg. train loss: 0.16488\n",
      "Step #38700, epoch #430, avg. train loss: 0.16651\n",
      "Step #38800, epoch #431, avg. train loss: 0.16629\n",
      "Step #38900, epoch #432, avg. train loss: 0.16038\n",
      "Step #39000, epoch #433, avg. train loss: 0.16315\n",
      "Step #39100, epoch #434, avg. train loss: 0.16663\n",
      "Step #39200, epoch #435, avg. train loss: 0.16848\n",
      "Step #39300, epoch #436, avg. train loss: 0.16371\n",
      "Step #39400, epoch #437, avg. train loss: 0.16544\n",
      "Step #39500, epoch #438, avg. train loss: 0.16284\n",
      "Step #39600, epoch #440, avg. train loss: 0.16319\n",
      "Step #39700, epoch #441, avg. train loss: 0.16440\n",
      "Step #39800, epoch #442, avg. train loss: 0.16522\n",
      "Step #39900, epoch #443, avg. train loss: 0.16424\n",
      "Step #40000, epoch #444, avg. train loss: 0.16796\n",
      "Step #40100, epoch #445, avg. train loss: 0.16262\n",
      "Step #40200, epoch #446, avg. train loss: 0.16471\n",
      "Step #40300, epoch #447, avg. train loss: 0.16404\n",
      "Step #40400, epoch #448, avg. train loss: 0.16631\n",
      "Step #40500, epoch #450, avg. train loss: 0.16526\n",
      "Step #40600, epoch #451, avg. train loss: 0.16635\n",
      "Step #40700, epoch #452, avg. train loss: 0.16015\n",
      "Step #40800, epoch #453, avg. train loss: 0.16683\n",
      "Step #40900, epoch #454, avg. train loss: 0.16055\n",
      "Step #41000, epoch #455, avg. train loss: 0.16584\n",
      "Step #41100, epoch #456, avg. train loss: 0.16380\n",
      "Step #41200, epoch #457, avg. train loss: 0.16313\n",
      "Step #41300, epoch #458, avg. train loss: 0.16866\n",
      "Step #41400, epoch #460, avg. train loss: 0.16407\n",
      "Step #41500, epoch #461, avg. train loss: 0.16451\n",
      "Step #41600, epoch #462, avg. train loss: 0.16450\n",
      "Step #41700, epoch #463, avg. train loss: 0.16358\n",
      "Step #41800, epoch #464, avg. train loss: 0.16270\n",
      "Step #41900, epoch #465, avg. train loss: 0.16504\n",
      "Step #42000, epoch #466, avg. train loss: 0.16299\n",
      "Step #42100, epoch #467, avg. train loss: 0.16744\n",
      "Step #42200, epoch #468, avg. train loss: 0.16584\n",
      "Step #42300, epoch #470, avg. train loss: 0.16206\n",
      "Step #42400, epoch #471, avg. train loss: 0.16516\n",
      "Step #42500, epoch #472, avg. train loss: 0.16543\n",
      "Step #42600, epoch #473, avg. train loss: 0.16462\n",
      "Step #42700, epoch #474, avg. train loss: 0.16386\n",
      "Step #42800, epoch #475, avg. train loss: 0.16245\n",
      "Step #42900, epoch #476, avg. train loss: 0.16473\n",
      "Step #43000, epoch #477, avg. train loss: 0.16586\n",
      "Step #43100, epoch #478, avg. train loss: 0.16265\n",
      "Step #43200, epoch #480, avg. train loss: 0.16659\n",
      "Step #43300, epoch #481, avg. train loss: 0.16436\n",
      "Step #43400, epoch #482, avg. train loss: 0.16888\n",
      "Step #43500, epoch #483, avg. train loss: 0.16189\n",
      "Step #43600, epoch #484, avg. train loss: 0.16408\n",
      "Step #43700, epoch #485, avg. train loss: 0.16660\n",
      "Step #43800, epoch #486, avg. train loss: 0.16207\n",
      "Step #43900, epoch #487, avg. train loss: 0.16503\n",
      "Step #44000, epoch #488, avg. train loss: 0.16494\n",
      "Step #44100, epoch #490, avg. train loss: 0.16299\n",
      "Step #44200, epoch #491, avg. train loss: 0.16416\n",
      "Step #44300, epoch #492, avg. train loss: 0.16221\n",
      "Step #44400, epoch #493, avg. train loss: 0.16736\n",
      "Step #44500, epoch #494, avg. train loss: 0.16337\n",
      "Step #44600, epoch #495, avg. train loss: 0.16503\n",
      "Step #44700, epoch #496, avg. train loss: 0.16550\n",
      "Step #44800, epoch #497, avg. train loss: 0.16725\n",
      "Step #44900, epoch #498, avg. train loss: 0.16337\n",
      "Step #45000, epoch #500, avg. train loss: 0.16250\n",
      "Step #45100, epoch #501, avg. train loss: 0.16468\n",
      "Step #45200, epoch #502, avg. train loss: 0.16401\n",
      "Step #45300, epoch #503, avg. train loss: 0.16645\n",
      "Step #45400, epoch #504, avg. train loss: 0.16204\n",
      "Step #45500, epoch #505, avg. train loss: 0.16375\n",
      "Step #45600, epoch #506, avg. train loss: 0.16526\n",
      "Step #45700, epoch #507, avg. train loss: 0.16306\n",
      "Step #45800, epoch #508, avg. train loss: 0.16249\n",
      "Step #45900, epoch #510, avg. train loss: 0.16824\n",
      "Step #46000, epoch #511, avg. train loss: 0.16336\n",
      "Step #46100, epoch #512, avg. train loss: 0.16628\n",
      "Step #46200, epoch #513, avg. train loss: 0.16337\n",
      "Step #46300, epoch #514, avg. train loss: 0.16369\n",
      "Step #46400, epoch #515, avg. train loss: 0.16511\n",
      "Step #46500, epoch #516, avg. train loss: 0.16731\n",
      "Step #46600, epoch #517, avg. train loss: 0.16232\n",
      "Step #46700, epoch #518, avg. train loss: 0.16258\n",
      "Step #46800, epoch #520, avg. train loss: 0.16542\n",
      "Step #46900, epoch #521, avg. train loss: 0.16300\n",
      "Step #47000, epoch #522, avg. train loss: 0.16408\n",
      "Step #47100, epoch #523, avg. train loss: 0.16529\n",
      "Step #47200, epoch #524, avg. train loss: 0.16454\n",
      "Step #47300, epoch #525, avg. train loss: 0.16526\n",
      "Step #47400, epoch #526, avg. train loss: 0.16556\n",
      "Step #47500, epoch #527, avg. train loss: 0.16248\n",
      "Step #47600, epoch #528, avg. train loss: 0.16338\n",
      "Step #47700, epoch #530, avg. train loss: 0.16785\n",
      "Step #47800, epoch #531, avg. train loss: 0.16513\n",
      "Step #47900, epoch #532, avg. train loss: 0.16244\n",
      "Step #48000, epoch #533, avg. train loss: 0.16690\n",
      "Step #48100, epoch #534, avg. train loss: 0.16409\n",
      "Step #48200, epoch #535, avg. train loss: 0.16389\n",
      "Step #48300, epoch #536, avg. train loss: 0.16710\n",
      "Step #48400, epoch #537, avg. train loss: 0.16287\n",
      "Step #48500, epoch #538, avg. train loss: 0.16594\n",
      "Step #48600, epoch #540, avg. train loss: 0.16366\n",
      "Step #48700, epoch #541, avg. train loss: 0.16404\n",
      "Step #48800, epoch #542, avg. train loss: 0.16320\n",
      "Step #48900, epoch #543, avg. train loss: 0.16424\n",
      "Step #49000, epoch #544, avg. train loss: 0.16429\n",
      "Step #49100, epoch #545, avg. train loss: 0.16514\n",
      "Step #49200, epoch #546, avg. train loss: 0.16525\n",
      "Step #49300, epoch #547, avg. train loss: 0.16461\n",
      "Step #49400, epoch #548, avg. train loss: 0.16615\n",
      "Step #49500, epoch #550, avg. train loss: 0.16374\n",
      "Step #49600, epoch #551, avg. train loss: 0.16449\n",
      "Step #49700, epoch #552, avg. train loss: 0.16406\n",
      "Step #49800, epoch #553, avg. train loss: 0.16876\n",
      "Step #49900, epoch #554, avg. train loss: 0.15931\n",
      "Step #50000, epoch #555, avg. train loss: 0.16559\n",
      "Step #50100, epoch #556, avg. train loss: 0.16580\n",
      "Step #50200, epoch #557, avg. train loss: 0.16469\n",
      "Step #50300, epoch #558, avg. train loss: 0.16288\n",
      "Step #50400, epoch #560, avg. train loss: 0.16375\n",
      "Step #50500, epoch #561, avg. train loss: 0.16361\n",
      "Step #50600, epoch #562, avg. train loss: 0.16487\n",
      "Step #50700, epoch #563, avg. train loss: 0.16514\n",
      "Step #50800, epoch #564, avg. train loss: 0.16159\n",
      "Step #50900, epoch #565, avg. train loss: 0.16519\n",
      "Step #51000, epoch #566, avg. train loss: 0.16567\n",
      "Step #51100, epoch #567, avg. train loss: 0.16359\n",
      "Step #51200, epoch #568, avg. train loss: 0.16497\n",
      "Step #51300, epoch #570, avg. train loss: 0.16222\n",
      "Step #51400, epoch #571, avg. train loss: 0.16486\n",
      "Step #51500, epoch #572, avg. train loss: 0.16306\n",
      "Step #51600, epoch #573, avg. train loss: 0.16427\n",
      "Step #51700, epoch #574, avg. train loss: 0.16539\n",
      "Step #51800, epoch #575, avg. train loss: 0.16397\n",
      "Step #51900, epoch #576, avg. train loss: 0.16171\n",
      "Step #52000, epoch #577, avg. train loss: 0.16670\n",
      "Step #52100, epoch #578, avg. train loss: 0.16448\n",
      "Step #52200, epoch #580, avg. train loss: 0.16700\n",
      "Step #52300, epoch #581, avg. train loss: 0.16569\n",
      "Step #52400, epoch #582, avg. train loss: 0.16586\n",
      "Step #52500, epoch #583, avg. train loss: 0.16514\n",
      "Step #52600, epoch #584, avg. train loss: 0.16311\n",
      "Step #52700, epoch #585, avg. train loss: 0.16562\n",
      "Step #52800, epoch #586, avg. train loss: 0.16193\n",
      "Step #52900, epoch #587, avg. train loss: 0.16682\n",
      "Step #53000, epoch #588, avg. train loss: 0.16736\n",
      "Step #53100, epoch #590, avg. train loss: 0.16525\n",
      "Step #53200, epoch #591, avg. train loss: 0.16450\n",
      "Step #53300, epoch #592, avg. train loss: 0.16375\n",
      "Step #53400, epoch #593, avg. train loss: 0.16517\n",
      "Step #53500, epoch #594, avg. train loss: 0.16605\n",
      "Step #53600, epoch #595, avg. train loss: 0.16271\n",
      "Step #53700, epoch #596, avg. train loss: 0.16172\n",
      "Step #53800, epoch #597, avg. train loss: 0.16580\n",
      "Step #53900, epoch #598, avg. train loss: 0.16140\n",
      "Step #54000, epoch #600, avg. train loss: 0.16429\n",
      "Step #54100, epoch #601, avg. train loss: 0.16555\n",
      "Step #54200, epoch #602, avg. train loss: 0.16440\n",
      "Step #54300, epoch #603, avg. train loss: 0.16632\n",
      "Step #54400, epoch #604, avg. train loss: 0.16208\n",
      "Step #54500, epoch #605, avg. train loss: 0.16479\n",
      "Step #54600, epoch #606, avg. train loss: 0.16403\n",
      "Step #54700, epoch #607, avg. train loss: 0.16463\n",
      "Step #54800, epoch #608, avg. train loss: 0.16262\n",
      "Step #54900, epoch #610, avg. train loss: 0.16431\n",
      "Step #55000, epoch #611, avg. train loss: 0.16394\n",
      "Step #55100, epoch #612, avg. train loss: 0.16353\n",
      "Step #55200, epoch #613, avg. train loss: 0.16193\n",
      "Step #55300, epoch #614, avg. train loss: 0.16653\n",
      "Step #55400, epoch #615, avg. train loss: 0.16396\n",
      "Step #55500, epoch #616, avg. train loss: 0.16442\n",
      "Step #55600, epoch #617, avg. train loss: 0.16513\n",
      "Step #55700, epoch #618, avg. train loss: 0.16275\n",
      "Step #55800, epoch #620, avg. train loss: 0.16455\n",
      "Step #55900, epoch #621, avg. train loss: 0.16418\n",
      "Step #56000, epoch #622, avg. train loss: 0.16542\n",
      "Step #56100, epoch #623, avg. train loss: 0.16256\n",
      "Step #56200, epoch #624, avg. train loss: 0.16410\n",
      "Step #56300, epoch #625, avg. train loss: 0.16588\n",
      "Step #56400, epoch #626, avg. train loss: 0.16176\n",
      "Step #56500, epoch #627, avg. train loss: 0.16913\n",
      "Step #56600, epoch #628, avg. train loss: 0.16551\n",
      "Step #56700, epoch #630, avg. train loss: 0.16483\n",
      "Step #56800, epoch #631, avg. train loss: 0.16496\n",
      "Step #56900, epoch #632, avg. train loss: 0.16377\n",
      "Step #57000, epoch #633, avg. train loss: 0.16267\n",
      "Step #57100, epoch #634, avg. train loss: 0.16354\n",
      "Step #57200, epoch #635, avg. train loss: 0.16763\n",
      "Step #57300, epoch #636, avg. train loss: 0.16265\n",
      "Step #57400, epoch #637, avg. train loss: 0.16702\n",
      "Step #57500, epoch #638, avg. train loss: 0.16505\n",
      "Step #57600, epoch #640, avg. train loss: 0.16619\n",
      "Step #57700, epoch #641, avg. train loss: 0.16275\n",
      "Step #57800, epoch #642, avg. train loss: 0.16431\n",
      "Step #57900, epoch #643, avg. train loss: 0.16423\n",
      "Step #58000, epoch #644, avg. train loss: 0.16186\n",
      "Step #58100, epoch #645, avg. train loss: 0.16272\n",
      "Step #58200, epoch #646, avg. train loss: 0.16708\n",
      "Step #58300, epoch #647, avg. train loss: 0.16361\n",
      "Step #58400, epoch #648, avg. train loss: 0.16499\n",
      "Step #58500, epoch #650, avg. train loss: 0.16516\n",
      "Step #58600, epoch #651, avg. train loss: 0.16545\n",
      "Step #58700, epoch #652, avg. train loss: 0.16377\n",
      "Step #58800, epoch #653, avg. train loss: 0.16678\n",
      "Step #58900, epoch #654, avg. train loss: 0.16520\n",
      "Step #59000, epoch #655, avg. train loss: 0.16405\n",
      "Step #59100, epoch #656, avg. train loss: 0.16318\n",
      "Step #59200, epoch #657, avg. train loss: 0.16616\n",
      "Step #59300, epoch #658, avg. train loss: 0.16309\n",
      "Step #59400, epoch #660, avg. train loss: 0.16757\n",
      "Step #59500, epoch #661, avg. train loss: 0.16459\n",
      "Step #59600, epoch #662, avg. train loss: 0.16860\n",
      "Step #59700, epoch #663, avg. train loss: 0.16368\n",
      "Step #59800, epoch #664, avg. train loss: 0.16449\n",
      "Step #59900, epoch #665, avg. train loss: 0.16504\n",
      "Step #60000, epoch #666, avg. train loss: 0.16497\n",
      "Step #60100, epoch #667, avg. train loss: 0.16393\n",
      "Step #60200, epoch #668, avg. train loss: 0.16690\n",
      "Step #60300, epoch #670, avg. train loss: 0.16318\n",
      "Step #60400, epoch #671, avg. train loss: 0.16320\n",
      "Step #60500, epoch #672, avg. train loss: 0.16566\n",
      "Step #60600, epoch #673, avg. train loss: 0.16307\n",
      "Step #60700, epoch #674, avg. train loss: 0.16546\n",
      "Step #60800, epoch #675, avg. train loss: 0.16124\n",
      "Step #60900, epoch #676, avg. train loss: 0.16563\n",
      "Step #61000, epoch #677, avg. train loss: 0.16839\n",
      "Step #61100, epoch #678, avg. train loss: 0.16311\n",
      "Step #61200, epoch #680, avg. train loss: 0.16513\n",
      "Step #61300, epoch #681, avg. train loss: 0.16345\n",
      "Step #61400, epoch #682, avg. train loss: 0.16654\n",
      "Step #61500, epoch #683, avg. train loss: 0.16418\n",
      "Step #61600, epoch #684, avg. train loss: 0.16499\n",
      "Step #61700, epoch #685, avg. train loss: 0.16370\n",
      "Step #61800, epoch #686, avg. train loss: 0.16466\n",
      "Step #61900, epoch #687, avg. train loss: 0.16638\n",
      "Step #62000, epoch #688, avg. train loss: 0.16358\n",
      "Step #62100, epoch #690, avg. train loss: 0.16457\n",
      "Step #62200, epoch #691, avg. train loss: 0.16422\n",
      "Step #62300, epoch #692, avg. train loss: 0.16446\n",
      "Step #62400, epoch #693, avg. train loss: 0.16202\n",
      "Step #62500, epoch #694, avg. train loss: 0.16504\n",
      "Step #62600, epoch #695, avg. train loss: 0.16454\n",
      "Step #62700, epoch #696, avg. train loss: 0.16723\n",
      "Step #62800, epoch #697, avg. train loss: 0.16132\n",
      "Step #62900, epoch #698, avg. train loss: 0.16709\n",
      "Step #63000, epoch #700, avg. train loss: 0.16633\n",
      "Step #63100, epoch #701, avg. train loss: 0.16414\n",
      "Step #63200, epoch #702, avg. train loss: 0.16260\n",
      "Step #63300, epoch #703, avg. train loss: 0.16827\n",
      "Step #63400, epoch #704, avg. train loss: 0.16460\n",
      "Step #63500, epoch #705, avg. train loss: 0.16403\n",
      "Step #63600, epoch #706, avg. train loss: 0.16827\n",
      "Step #63700, epoch #707, avg. train loss: 0.16312\n",
      "Step #63800, epoch #708, avg. train loss: 0.16548\n",
      "Step #63900, epoch #710, avg. train loss: 0.16616\n",
      "Step #64000, epoch #711, avg. train loss: 0.16306\n",
      "Step #64100, epoch #712, avg. train loss: 0.16589\n",
      "Step #64200, epoch #713, avg. train loss: 0.16489\n",
      "Step #64300, epoch #714, avg. train loss: 0.16490\n",
      "Step #64400, epoch #715, avg. train loss: 0.16598\n",
      "Step #64500, epoch #716, avg. train loss: 0.16433\n",
      "Step #64600, epoch #717, avg. train loss: 0.16176\n",
      "Step #64700, epoch #718, avg. train loss: 0.16644\n",
      "Step #64800, epoch #720, avg. train loss: 0.16545\n",
      "Step #64900, epoch #721, avg. train loss: 0.16419\n",
      "Step #65000, epoch #722, avg. train loss: 0.16621\n",
      "Step #65100, epoch #723, avg. train loss: 0.16459\n",
      "Step #65200, epoch #724, avg. train loss: 0.16045\n",
      "Step #65300, epoch #725, avg. train loss: 0.16579\n",
      "Step #65400, epoch #726, avg. train loss: 0.16124\n",
      "Step #65500, epoch #727, avg. train loss: 0.16692\n",
      "Step #65600, epoch #728, avg. train loss: 0.16319\n",
      "Step #65700, epoch #730, avg. train loss: 0.16623\n",
      "Step #65800, epoch #731, avg. train loss: 0.16518\n",
      "Step #65900, epoch #732, avg. train loss: 0.16392\n",
      "Step #66000, epoch #733, avg. train loss: 0.16368\n",
      "Step #66100, epoch #734, avg. train loss: 0.16551\n",
      "Step #66200, epoch #735, avg. train loss: 0.16435\n",
      "Step #66300, epoch #736, avg. train loss: 0.16468\n",
      "Step #66400, epoch #737, avg. train loss: 0.16380\n",
      "Step #66500, epoch #738, avg. train loss: 0.16472\n",
      "Step #66600, epoch #740, avg. train loss: 0.16488\n",
      "Step #66700, epoch #741, avg. train loss: 0.16448\n",
      "Step #66800, epoch #742, avg. train loss: 0.16451\n",
      "Step #66900, epoch #743, avg. train loss: 0.16423\n",
      "Step #67000, epoch #744, avg. train loss: 0.16287\n",
      "Step #67100, epoch #745, avg. train loss: 0.16522\n",
      "Step #67200, epoch #746, avg. train loss: 0.16542\n",
      "Step #67300, epoch #747, avg. train loss: 0.16330\n",
      "Step #67400, epoch #748, avg. train loss: 0.16625\n",
      "Step #67500, epoch #750, avg. train loss: 0.16574\n",
      "Step #67600, epoch #751, avg. train loss: 0.16492\n",
      "Step #67700, epoch #752, avg. train loss: 0.16476\n",
      "Step #67800, epoch #753, avg. train loss: 0.16502\n",
      "Step #67900, epoch #754, avg. train loss: 0.16298\n",
      "Step #68000, epoch #755, avg. train loss: 0.16607\n",
      "Step #68100, epoch #756, avg. train loss: 0.16347\n",
      "Step #68200, epoch #757, avg. train loss: 0.16488\n",
      "Step #68300, epoch #758, avg. train loss: 0.16508\n",
      "Step #68400, epoch #760, avg. train loss: 0.16348\n",
      "Step #68500, epoch #761, avg. train loss: 0.16401\n",
      "Step #68600, epoch #762, avg. train loss: 0.16573\n",
      "Step #68700, epoch #763, avg. train loss: 0.16547\n",
      "Step #68800, epoch #764, avg. train loss: 0.16332\n",
      "Step #68900, epoch #765, avg. train loss: 0.16260\n",
      "Step #69000, epoch #766, avg. train loss: 0.16668\n",
      "Step #69100, epoch #767, avg. train loss: 0.16521\n",
      "Step #69200, epoch #768, avg. train loss: 0.16408\n",
      "Step #69300, epoch #770, avg. train loss: 0.16430\n",
      "Step #69400, epoch #771, avg. train loss: 0.16576\n",
      "Step #69500, epoch #772, avg. train loss: 0.16418\n",
      "Step #69600, epoch #773, avg. train loss: 0.16453\n",
      "Step #69700, epoch #774, avg. train loss: 0.16458\n",
      "Step #69800, epoch #775, avg. train loss: 0.16292\n",
      "Step #69900, epoch #776, avg. train loss: 0.16310\n",
      "Step #70000, epoch #777, avg. train loss: 0.16336\n",
      "Step #70100, epoch #778, avg. train loss: 0.16594\n",
      "Step #70200, epoch #780, avg. train loss: 0.16698\n",
      "Step #70300, epoch #781, avg. train loss: 0.16400\n",
      "Step #70400, epoch #782, avg. train loss: 0.16428\n",
      "Step #70500, epoch #783, avg. train loss: 0.16172\n",
      "Step #70600, epoch #784, avg. train loss: 0.16720\n",
      "Step #70700, epoch #785, avg. train loss: 0.16342\n",
      "Step #70800, epoch #786, avg. train loss: 0.16362\n",
      "Step #70900, epoch #787, avg. train loss: 0.16377\n",
      "Step #71000, epoch #788, avg. train loss: 0.16341\n",
      "Step #71100, epoch #790, avg. train loss: 0.16331\n",
      "Step #71200, epoch #791, avg. train loss: 0.16430\n",
      "Step #71300, epoch #792, avg. train loss: 0.16719\n",
      "Step #71400, epoch #793, avg. train loss: 0.16261\n",
      "Step #71500, epoch #794, avg. train loss: 0.16540\n",
      "Step #71600, epoch #795, avg. train loss: 0.16706\n",
      "Step #71700, epoch #796, avg. train loss: 0.16522\n",
      "Step #71800, epoch #797, avg. train loss: 0.16213\n",
      "Step #71900, epoch #798, avg. train loss: 0.16273\n",
      "Step #72000, epoch #800, avg. train loss: 0.16473\n",
      "Step #72100, epoch #801, avg. train loss: 0.16554\n",
      "Step #72200, epoch #802, avg. train loss: 0.16757\n",
      "Step #72300, epoch #803, avg. train loss: 0.16040\n",
      "Step #72400, epoch #804, avg. train loss: 0.16855\n",
      "Step #72500, epoch #805, avg. train loss: 0.16541\n",
      "Step #72600, epoch #806, avg. train loss: 0.16635\n",
      "Step #72700, epoch #807, avg. train loss: 0.16162\n",
      "Step #72800, epoch #808, avg. train loss: 0.16618\n",
      "Step #72900, epoch #810, avg. train loss: 0.16515\n",
      "Step #73000, epoch #811, avg. train loss: 0.16393\n",
      "Step #73100, epoch #812, avg. train loss: 0.16538\n",
      "Step #73200, epoch #813, avg. train loss: 0.16347\n",
      "Step #73300, epoch #814, avg. train loss: 0.16608\n",
      "Step #73400, epoch #815, avg. train loss: 0.16439\n",
      "Step #73500, epoch #816, avg. train loss: 0.16334\n",
      "Step #73600, epoch #817, avg. train loss: 0.16055\n",
      "Step #73700, epoch #818, avg. train loss: 0.16767\n",
      "Step #73800, epoch #820, avg. train loss: 0.16652\n",
      "Step #73900, epoch #821, avg. train loss: 0.16326\n",
      "Step #74000, epoch #822, avg. train loss: 0.16203\n",
      "Step #74100, epoch #823, avg. train loss: 0.16571\n",
      "Step #74200, epoch #824, avg. train loss: 0.16462\n",
      "Step #74300, epoch #825, avg. train loss: 0.16577\n",
      "Step #74400, epoch #826, avg. train loss: 0.16499\n",
      "Step #74500, epoch #827, avg. train loss: 0.16732\n",
      "Step #74600, epoch #828, avg. train loss: 0.16119\n",
      "Step #74700, epoch #830, avg. train loss: 0.16585\n",
      "Step #74800, epoch #831, avg. train loss: 0.16487\n",
      "Step #74900, epoch #832, avg. train loss: 0.16420\n",
      "Step #75000, epoch #833, avg. train loss: 0.16810\n",
      "Step #75100, epoch #834, avg. train loss: 0.16380\n",
      "Step #75200, epoch #835, avg. train loss: 0.16399\n",
      "Step #75300, epoch #836, avg. train loss: 0.16539\n",
      "Step #75400, epoch #837, avg. train loss: 0.16481\n",
      "Step #75500, epoch #838, avg. train loss: 0.16266\n",
      "Step #75600, epoch #840, avg. train loss: 0.16292\n",
      "Step #75700, epoch #841, avg. train loss: 0.16532\n",
      "Step #75800, epoch #842, avg. train loss: 0.16236\n",
      "Step #75900, epoch #843, avg. train loss: 0.16621\n",
      "Step #76000, epoch #844, avg. train loss: 0.16261\n",
      "Step #76100, epoch #845, avg. train loss: 0.16638\n",
      "Step #76200, epoch #846, avg. train loss: 0.16333\n",
      "Step #76300, epoch #847, avg. train loss: 0.16415\n",
      "Step #76400, epoch #848, avg. train loss: 0.16469\n",
      "Step #76500, epoch #850, avg. train loss: 0.16430\n",
      "Step #76600, epoch #851, avg. train loss: 0.16541\n",
      "Step #76700, epoch #852, avg. train loss: 0.16203\n",
      "Step #76800, epoch #853, avg. train loss: 0.16485\n",
      "Step #76900, epoch #854, avg. train loss: 0.16437\n",
      "Step #77000, epoch #855, avg. train loss: 0.16367\n",
      "Step #77100, epoch #856, avg. train loss: 0.16442\n",
      "Step #77200, epoch #857, avg. train loss: 0.16449\n",
      "Step #77300, epoch #858, avg. train loss: 0.16272\n",
      "Step #77400, epoch #860, avg. train loss: 0.16478\n",
      "Step #77500, epoch #861, avg. train loss: 0.16443\n",
      "Step #77600, epoch #862, avg. train loss: 0.16417\n",
      "Step #77700, epoch #863, avg. train loss: 0.16394\n",
      "Step #77800, epoch #864, avg. train loss: 0.16420\n",
      "Step #77900, epoch #865, avg. train loss: 0.16328\n",
      "Step #78000, epoch #866, avg. train loss: 0.16457\n",
      "Step #78100, epoch #867, avg. train loss: 0.16495\n",
      "Step #78200, epoch #868, avg. train loss: 0.16427\n",
      "Step #78300, epoch #870, avg. train loss: 0.16343\n",
      "Step #78400, epoch #871, avg. train loss: 0.16219\n",
      "Step #78500, epoch #872, avg. train loss: 0.16505\n",
      "Step #78600, epoch #873, avg. train loss: 0.16496\n",
      "Step #78700, epoch #874, avg. train loss: 0.16470\n",
      "Step #78800, epoch #875, avg. train loss: 0.16294\n",
      "Step #78900, epoch #876, avg. train loss: 0.16644\n",
      "Step #79000, epoch #877, avg. train loss: 0.16436\n",
      "Step #79100, epoch #878, avg. train loss: 0.16377\n",
      "Step #79200, epoch #880, avg. train loss: 0.16249\n",
      "Step #79300, epoch #881, avg. train loss: 0.16411\n",
      "Step #79400, epoch #882, avg. train loss: 0.16241\n",
      "Step #79500, epoch #883, avg. train loss: 0.16449\n",
      "Step #79600, epoch #884, avg. train loss: 0.16614\n",
      "Step #79700, epoch #885, avg. train loss: 0.16164\n",
      "Step #79800, epoch #886, avg. train loss: 0.16347\n",
      "Step #79900, epoch #887, avg. train loss: 0.16875\n",
      "Step #80000, epoch #888, avg. train loss: 0.16557\n",
      "Step #80100, epoch #890, avg. train loss: 0.16278\n",
      "Step #80200, epoch #891, avg. train loss: 0.16541\n",
      "Step #80300, epoch #892, avg. train loss: 0.16374\n",
      "Step #80400, epoch #893, avg. train loss: 0.16487\n",
      "Step #80500, epoch #894, avg. train loss: 0.16278\n",
      "Step #80600, epoch #895, avg. train loss: 0.16465\n",
      "Step #80700, epoch #896, avg. train loss: 0.17051\n",
      "Step #80800, epoch #897, avg. train loss: 0.16173\n",
      "Step #80900, epoch #898, avg. train loss: 0.16270\n",
      "Step #81000, epoch #900, avg. train loss: 0.16495\n",
      "Step #81100, epoch #901, avg. train loss: 0.16370\n",
      "Step #81200, epoch #902, avg. train loss: 0.16489\n",
      "Step #81300, epoch #903, avg. train loss: 0.16274\n",
      "Step #81400, epoch #904, avg. train loss: 0.16559\n",
      "Step #81500, epoch #905, avg. train loss: 0.16651\n",
      "Step #81600, epoch #906, avg. train loss: 0.16855\n",
      "Step #81700, epoch #907, avg. train loss: 0.16302\n",
      "Step #81800, epoch #908, avg. train loss: 0.16260\n",
      "Step #81900, epoch #910, avg. train loss: 0.16511\n",
      "Step #82000, epoch #911, avg. train loss: 0.16369\n",
      "Step #82100, epoch #912, avg. train loss: 0.16336\n",
      "Step #82200, epoch #913, avg. train loss: 0.16718\n",
      "Step #82300, epoch #914, avg. train loss: 0.16490\n",
      "Step #82400, epoch #915, avg. train loss: 0.16228\n",
      "Step #82500, epoch #916, avg. train loss: 0.16517\n",
      "Step #82600, epoch #917, avg. train loss: 0.16587\n",
      "Step #82700, epoch #918, avg. train loss: 0.16171\n",
      "Step #82800, epoch #920, avg. train loss: 0.16659\n",
      "Step #82900, epoch #921, avg. train loss: 0.16611\n",
      "Step #83000, epoch #922, avg. train loss: 0.16509\n",
      "Step #83100, epoch #923, avg. train loss: 0.16369\n",
      "Step #83200, epoch #924, avg. train loss: 0.16467\n",
      "Step #83300, epoch #925, avg. train loss: 0.16513\n",
      "Step #83400, epoch #926, avg. train loss: 0.16430\n",
      "Step #83500, epoch #927, avg. train loss: 0.16673\n",
      "Step #83600, epoch #928, avg. train loss: 0.16383\n",
      "Step #83700, epoch #930, avg. train loss: 0.16509\n",
      "Step #83800, epoch #931, avg. train loss: 0.16452\n",
      "Step #83900, epoch #932, avg. train loss: 0.16617\n",
      "Step #84000, epoch #933, avg. train loss: 0.16473\n",
      "Step #84100, epoch #934, avg. train loss: 0.16693\n",
      "Step #84200, epoch #935, avg. train loss: 0.16425\n",
      "Step #84300, epoch #936, avg. train loss: 0.16683\n",
      "Step #84400, epoch #937, avg. train loss: 0.16105\n",
      "Step #84500, epoch #938, avg. train loss: 0.16652\n",
      "Step #84600, epoch #940, avg. train loss: 0.16588\n",
      "Step #84700, epoch #941, avg. train loss: 0.16486\n",
      "Step #84800, epoch #942, avg. train loss: 0.16560\n",
      "Step #84900, epoch #943, avg. train loss: 0.16253\n",
      "Step #85000, epoch #944, avg. train loss: 0.16823\n",
      "Step #85100, epoch #945, avg. train loss: 0.16514\n",
      "Step #85200, epoch #946, avg. train loss: 0.16328\n",
      "Step #85300, epoch #947, avg. train loss: 0.16457\n",
      "Step #85400, epoch #948, avg. train loss: 0.16033\n",
      "Step #85500, epoch #950, avg. train loss: 0.16807\n",
      "Step #85600, epoch #951, avg. train loss: 0.16427\n",
      "Step #85700, epoch #952, avg. train loss: 0.16265\n",
      "Step #85800, epoch #953, avg. train loss: 0.16567\n",
      "Step #85900, epoch #954, avg. train loss: 0.16242\n",
      "Step #86000, epoch #955, avg. train loss: 0.16672\n",
      "Step #86100, epoch #956, avg. train loss: 0.16360\n",
      "Step #86200, epoch #957, avg. train loss: 0.16246\n",
      "Step #86300, epoch #958, avg. train loss: 0.16467\n",
      "Step #86400, epoch #960, avg. train loss: 0.16293\n",
      "Step #86500, epoch #961, avg. train loss: 0.16447\n",
      "Step #86600, epoch #962, avg. train loss: 0.16446\n",
      "Step #86700, epoch #963, avg. train loss: 0.16617\n",
      "Step #86800, epoch #964, avg. train loss: 0.16543\n",
      "Step #86900, epoch #965, avg. train loss: 0.16197\n",
      "Step #87000, epoch #966, avg. train loss: 0.16713\n",
      "Step #87100, epoch #967, avg. train loss: 0.16229\n",
      "Step #87200, epoch #968, avg. train loss: 0.16570\n",
      "Step #87300, epoch #970, avg. train loss: 0.16380\n",
      "Step #87400, epoch #971, avg. train loss: 0.16483\n",
      "Step #87500, epoch #972, avg. train loss: 0.16444\n",
      "Step #87600, epoch #973, avg. train loss: 0.16409\n",
      "Step #87700, epoch #974, avg. train loss: 0.16308\n",
      "Step #87800, epoch #975, avg. train loss: 0.16329\n",
      "Step #87900, epoch #976, avg. train loss: 0.16820\n",
      "Step #88000, epoch #977, avg. train loss: 0.16108\n",
      "Step #88100, epoch #978, avg. train loss: 0.16463\n",
      "Step #88200, epoch #980, avg. train loss: 0.16179\n",
      "Step #88300, epoch #981, avg. train loss: 0.16633\n",
      "Step #88400, epoch #982, avg. train loss: 0.16198\n",
      "Step #88500, epoch #983, avg. train loss: 0.16452\n",
      "Step #88600, epoch #984, avg. train loss: 0.16354\n",
      "Step #88700, epoch #985, avg. train loss: 0.16581\n",
      "Step #88800, epoch #986, avg. train loss: 0.16474\n",
      "Step #88900, epoch #987, avg. train loss: 0.16708\n",
      "Step #89000, epoch #988, avg. train loss: 0.16144\n",
      "Step #89100, epoch #990, avg. train loss: 0.16796\n",
      "Step #89200, epoch #991, avg. train loss: 0.16526\n",
      "Step #89300, epoch #992, avg. train loss: 0.16297\n",
      "Step #89400, epoch #993, avg. train loss: 0.16557\n",
      "Step #89500, epoch #994, avg. train loss: 0.16547\n",
      "Step #89600, epoch #995, avg. train loss: 0.16169\n",
      "Step #89700, epoch #996, avg. train loss: 0.16677\n",
      "Step #89800, epoch #997, avg. train loss: 0.16567\n",
      "Step #89900, epoch #998, avg. train loss: 0.16515\n",
      "Step #90000, epoch #1000, avg. train loss: 0.16345\n",
      "Step #90100, epoch #1001, avg. train loss: 0.16442\n",
      "Step #90200, epoch #1002, avg. train loss: 0.16597\n",
      "Step #90300, epoch #1003, avg. train loss: 0.16260\n",
      "Step #90400, epoch #1004, avg. train loss: 0.16571\n",
      "Step #90500, epoch #1005, avg. train loss: 0.16345\n",
      "Step #90600, epoch #1006, avg. train loss: 0.16695\n",
      "Step #90700, epoch #1007, avg. train loss: 0.16352\n",
      "Step #90800, epoch #1008, avg. train loss: 0.16278\n",
      "Step #90900, epoch #1010, avg. train loss: 0.16591\n",
      "Step #91000, epoch #1011, avg. train loss: 0.16452\n",
      "Step #91100, epoch #1012, avg. train loss: 0.16471\n",
      "Step #91200, epoch #1013, avg. train loss: 0.16271\n",
      "Step #91300, epoch #1014, avg. train loss: 0.16772\n",
      "Step #91400, epoch #1015, avg. train loss: 0.16525\n",
      "Step #91500, epoch #1016, avg. train loss: 0.16342\n",
      "Step #91600, epoch #1017, avg. train loss: 0.16332\n",
      "Step #91700, epoch #1018, avg. train loss: 0.16508\n",
      "Step #91800, epoch #1020, avg. train loss: 0.16455\n",
      "Step #91900, epoch #1021, avg. train loss: 0.16547\n",
      "Step #92000, epoch #1022, avg. train loss: 0.16471\n",
      "Step #92100, epoch #1023, avg. train loss: 0.16288\n",
      "Step #92200, epoch #1024, avg. train loss: 0.16449\n",
      "Step #92300, epoch #1025, avg. train loss: 0.16606\n",
      "Step #92400, epoch #1026, avg. train loss: 0.16413\n",
      "Step #92500, epoch #1027, avg. train loss: 0.16689\n",
      "Step #92600, epoch #1028, avg. train loss: 0.16275\n",
      "Step #92700, epoch #1030, avg. train loss: 0.16598\n",
      "Step #92800, epoch #1031, avg. train loss: 0.16453\n",
      "Step #92900, epoch #1032, avg. train loss: 0.16267\n",
      "Step #93000, epoch #1033, avg. train loss: 0.16561\n",
      "Step #93100, epoch #1034, avg. train loss: 0.16366\n",
      "Step #93200, epoch #1035, avg. train loss: 0.16406\n",
      "Step #93300, epoch #1036, avg. train loss: 0.16427\n",
      "Step #93400, epoch #1037, avg. train loss: 0.16351\n",
      "Step #93500, epoch #1038, avg. train loss: 0.16445\n",
      "Step #93600, epoch #1040, avg. train loss: 0.16325\n",
      "Step #93700, epoch #1041, avg. train loss: 0.16460\n",
      "Step #93800, epoch #1042, avg. train loss: 0.16402\n",
      "Step #93900, epoch #1043, avg. train loss: 0.16453\n",
      "Step #94000, epoch #1044, avg. train loss: 0.16446\n",
      "Step #94100, epoch #1045, avg. train loss: 0.16147\n",
      "Step #94200, epoch #1046, avg. train loss: 0.16620\n",
      "Step #94300, epoch #1047, avg. train loss: 0.16504\n",
      "Step #94400, epoch #1048, avg. train loss: 0.16438\n",
      "Step #94500, epoch #1050, avg. train loss: 0.16207\n",
      "Step #94600, epoch #1051, avg. train loss: 0.16336\n",
      "Step #94700, epoch #1052, avg. train loss: 0.16609\n",
      "Step #94800, epoch #1053, avg. train loss: 0.16183\n",
      "Step #94900, epoch #1054, avg. train loss: 0.16420\n",
      "Step #95000, epoch #1055, avg. train loss: 0.16428\n",
      "Step #95100, epoch #1056, avg. train loss: 0.16476\n",
      "Step #95200, epoch #1057, avg. train loss: 0.16500\n",
      "Step #95300, epoch #1058, avg. train loss: 0.16561\n",
      "Step #95400, epoch #1060, avg. train loss: 0.16496\n",
      "Step #95500, epoch #1061, avg. train loss: 0.16417\n",
      "Step #95600, epoch #1062, avg. train loss: 0.16741\n",
      "Step #95700, epoch #1063, avg. train loss: 0.16259\n",
      "Step #95800, epoch #1064, avg. train loss: 0.16698\n",
      "Step #95900, epoch #1065, avg. train loss: 0.16537\n",
      "Step #96000, epoch #1066, avg. train loss: 0.15994\n",
      "Step #96100, epoch #1067, avg. train loss: 197.09698\n",
      "Step #96200, epoch #1068, avg. train loss: 0.16413\n",
      "Step #96300, epoch #1070, avg. train loss: 0.16761\n",
      "Step #96400, epoch #1071, avg. train loss: 0.16468\n",
      "Step #96500, epoch #1072, avg. train loss: 0.16195\n",
      "Step #96600, epoch #1073, avg. train loss: 0.16656\n",
      "Step #96700, epoch #1074, avg. train loss: 0.16127\n",
      "Step #96800, epoch #1075, avg. train loss: 0.16558\n",
      "Step #96900, epoch #1076, avg. train loss: 0.16434\n",
      "Step #97000, epoch #1077, avg. train loss: 0.16393\n",
      "Step #97100, epoch #1078, avg. train loss: 0.16684\n",
      "Step #97200, epoch #1080, avg. train loss: 0.16290\n",
      "Step #97300, epoch #1081, avg. train loss: 0.16757\n",
      "Step #97400, epoch #1082, avg. train loss: 0.16364\n",
      "Step #97500, epoch #1083, avg. train loss: 0.16162\n",
      "Step #97600, epoch #1084, avg. train loss: 0.16212\n",
      "Step #97700, epoch #1085, avg. train loss: 0.16730\n",
      "Step #97800, epoch #1086, avg. train loss: 0.16579\n",
      "Step #97900, epoch #1087, avg. train loss: 0.16083\n",
      "Step #98000, epoch #1088, avg. train loss: 0.16971\n",
      "Step #98100, epoch #1090, avg. train loss: 0.16437\n",
      "Step #98200, epoch #1091, avg. train loss: 0.16500\n",
      "Step #98300, epoch #1092, avg. train loss: 0.16471\n",
      "Step #98400, epoch #1093, avg. train loss: 0.16497\n",
      "Step #98500, epoch #1094, avg. train loss: 0.16618\n",
      "Step #98600, epoch #1095, avg. train loss: 0.16714\n",
      "Step #98700, epoch #1096, avg. train loss: 0.16447\n",
      "Step #98800, epoch #1097, avg. train loss: 0.16461\n",
      "Step #98900, epoch #1098, avg. train loss: 0.16196\n",
      "Step #99000, epoch #1100, avg. train loss: 0.16564\n",
      "Step #99100, epoch #1101, avg. train loss: 0.16494\n",
      "Step #99200, epoch #1102, avg. train loss: 0.16596\n",
      "Step #99300, epoch #1103, avg. train loss: 0.16461\n",
      "Step #99400, epoch #1104, avg. train loss: 0.16545\n",
      "Step #99500, epoch #1105, avg. train loss: 0.16335\n",
      "Step #99600, epoch #1106, avg. train loss: 0.16388\n",
      "Step #99700, epoch #1107, avg. train loss: 0.16589\n",
      "Step #99800, epoch #1108, avg. train loss: 0.16150\n",
      "Step #99900, epoch #1110, avg. train loss: 0.16443\n",
      "Step #100000, epoch #1111, avg. train loss: 0.16283\n",
      "ROC =  0.5\n",
      "dnn2\n",
      "Step #100, epoch #1, avg. train loss: 104993.61719\n",
      "Step #200, epoch #2, avg. train loss: 123812.11719\n",
      "Step #300, epoch #3, avg. train loss: 53537.15625\n",
      "Step #400, epoch #4, avg. train loss: 15.85832\n",
      "Step #500, epoch #5, avg. train loss: 63879.60156\n",
      "Step #600, epoch #6, avg. train loss: 0.19119\n",
      "Step #700, epoch #7, avg. train loss: 0.20689\n",
      "Step #800, epoch #8, avg. train loss: 16829.32422\n",
      "Step #900, epoch #10, avg. train loss: 0.21523\n",
      "Step #1000, epoch #11, avg. train loss: 14.00186\n",
      "Step #1100, epoch #12, avg. train loss: 2890.49805\n",
      "Step #1200, epoch #13, avg. train loss: 0.17093\n",
      "Step #1300, epoch #14, avg. train loss: 44.76760\n",
      "Step #1400, epoch #15, avg. train loss: 0.16937\n",
      "Step #1500, epoch #16, avg. train loss: 0.16504\n",
      "Step #1600, epoch #17, avg. train loss: 0.16798\n",
      "Step #1700, epoch #18, avg. train loss: 0.16538\n",
      "Step #1800, epoch #20, avg. train loss: 0.16293\n",
      "Step #1900, epoch #21, avg. train loss: 0.16626\n",
      "Step #2000, epoch #22, avg. train loss: 1.58142\n",
      "Step #2100, epoch #23, avg. train loss: 0.16816\n",
      "Step #2200, epoch #24, avg. train loss: 0.16399\n",
      "Step #2300, epoch #25, avg. train loss: 0.16260\n",
      "Step #2400, epoch #26, avg. train loss: 0.16749\n",
      "Step #2500, epoch #27, avg. train loss: 0.16286\n",
      "Step #2600, epoch #28, avg. train loss: 6.28352\n",
      "Step #2700, epoch #30, avg. train loss: 0.16298\n",
      "Step #2800, epoch #31, avg. train loss: 0.16330\n",
      "Step #2900, epoch #32, avg. train loss: 0.16417\n",
      "Step #3000, epoch #33, avg. train loss: 0.16579\n",
      "Step #3100, epoch #34, avg. train loss: 0.16304\n",
      "Step #3200, epoch #35, avg. train loss: 0.16362\n",
      "Step #3300, epoch #36, avg. train loss: 0.16450\n",
      "Step #3400, epoch #37, avg. train loss: 0.18388\n",
      "Step #3500, epoch #38, avg. train loss: 0.16796\n",
      "Step #3600, epoch #40, avg. train loss: 0.16463\n",
      "Step #3700, epoch #41, avg. train loss: 0.16449\n",
      "Step #3800, epoch #42, avg. train loss: 0.16173\n",
      "Step #3900, epoch #43, avg. train loss: 0.16598\n",
      "Step #4000, epoch #44, avg. train loss: 0.16263\n",
      "Step #4100, epoch #45, avg. train loss: 0.16816\n",
      "Step #4200, epoch #46, avg. train loss: 0.16189\n",
      "Step #4300, epoch #47, avg. train loss: 0.16287\n",
      "Step #4400, epoch #48, avg. train loss: 0.16666\n",
      "Step #4500, epoch #50, avg. train loss: 0.16409\n",
      "Step #4600, epoch #51, avg. train loss: 0.16484\n",
      "Step #4700, epoch #52, avg. train loss: 0.16298\n",
      "Step #4800, epoch #53, avg. train loss: 0.16289\n",
      "Step #4900, epoch #54, avg. train loss: 0.16537\n",
      "Step #5000, epoch #55, avg. train loss: 0.16508\n",
      "Step #5100, epoch #56, avg. train loss: 0.16141\n",
      "Step #5200, epoch #57, avg. train loss: 0.16739\n",
      "Step #5300, epoch #58, avg. train loss: 0.16364\n",
      "Step #5400, epoch #60, avg. train loss: 0.16365\n",
      "Step #5500, epoch #61, avg. train loss: 0.16557\n",
      "Step #5600, epoch #62, avg. train loss: 0.16266\n",
      "Step #5700, epoch #63, avg. train loss: 0.16541\n",
      "Step #5800, epoch #64, avg. train loss: 0.16461\n",
      "Step #5900, epoch #65, avg. train loss: 0.16296\n",
      "Step #6000, epoch #66, avg. train loss: 0.16672\n",
      "Step #6100, epoch #67, avg. train loss: 0.16378\n",
      "Step #6200, epoch #68, avg. train loss: 0.16341\n",
      "Step #6300, epoch #70, avg. train loss: 0.16349\n",
      "Step #6400, epoch #71, avg. train loss: 0.16278\n",
      "Step #6500, epoch #72, avg. train loss: 0.16607\n",
      "Step #6600, epoch #73, avg. train loss: 0.16474\n",
      "Step #6700, epoch #74, avg. train loss: 0.16606\n",
      "Step #6800, epoch #75, avg. train loss: 0.16427\n",
      "Step #6900, epoch #76, avg. train loss: 0.16399\n",
      "Step #7000, epoch #77, avg. train loss: 0.16157\n",
      "Step #7100, epoch #78, avg. train loss: 0.16717\n",
      "Step #7200, epoch #80, avg. train loss: 0.16404\n",
      "Step #7300, epoch #81, avg. train loss: 0.16478\n",
      "Step #7400, epoch #82, avg. train loss: 0.16569\n",
      "Step #7500, epoch #83, avg. train loss: 0.82393\n",
      "Step #7600, epoch #84, avg. train loss: 0.16611\n",
      "Step #7700, epoch #85, avg. train loss: 1.26473\n",
      "Step #7800, epoch #86, avg. train loss: 0.16398\n",
      "Step #7900, epoch #87, avg. train loss: 0.16264\n",
      "Step #8000, epoch #88, avg. train loss: 0.16512\n",
      "Step #8100, epoch #90, avg. train loss: 0.16210\n",
      "Step #8200, epoch #91, avg. train loss: 0.16850\n",
      "Step #8300, epoch #92, avg. train loss: 0.16639\n",
      "Step #8400, epoch #93, avg. train loss: 0.16081\n",
      "Step #8500, epoch #94, avg. train loss: 0.16426\n",
      "Step #8600, epoch #95, avg. train loss: 0.16526\n",
      "Step #8700, epoch #96, avg. train loss: 0.16512\n",
      "Step #8800, epoch #97, avg. train loss: 0.16579\n",
      "Step #8900, epoch #98, avg. train loss: 0.16243\n",
      "Step #9000, epoch #100, avg. train loss: 0.16456\n",
      "Step #9100, epoch #101, avg. train loss: 0.16419\n",
      "Step #9200, epoch #102, avg. train loss: 0.16602\n",
      "Step #9300, epoch #103, avg. train loss: 0.16162\n",
      "Step #9400, epoch #104, avg. train loss: 0.16564\n",
      "Step #9500, epoch #105, avg. train loss: 0.16292\n",
      "Step #9600, epoch #106, avg. train loss: 0.16817\n",
      "Step #9700, epoch #107, avg. train loss: 0.25401\n",
      "Step #9800, epoch #108, avg. train loss: 575.12732\n",
      "Step #9900, epoch #110, avg. train loss: 0.16248\n",
      "Step #10000, epoch #111, avg. train loss: 0.16476\n",
      "Step #10100, epoch #112, avg. train loss: 4266.07178\n",
      "Step #10200, epoch #113, avg. train loss: 0.16494\n",
      "Step #10300, epoch #114, avg. train loss: 0.16077\n",
      "Step #10400, epoch #115, avg. train loss: 0.16868\n",
      "Step #10500, epoch #116, avg. train loss: 0.16383\n",
      "Step #10600, epoch #117, avg. train loss: 0.16259\n",
      "Step #10700, epoch #118, avg. train loss: 0.16515\n",
      "Step #10800, epoch #120, avg. train loss: 0.34098\n",
      "Step #10900, epoch #121, avg. train loss: 0.16450\n",
      "Step #11000, epoch #122, avg. train loss: 0.16317\n",
      "Step #11100, epoch #123, avg. train loss: 0.16521\n",
      "Step #11200, epoch #124, avg. train loss: 0.16506\n",
      "Step #11300, epoch #125, avg. train loss: 0.16499\n",
      "Step #11400, epoch #126, avg. train loss: 0.16145\n",
      "Step #11500, epoch #127, avg. train loss: 0.16520\n",
      "Step #11600, epoch #128, avg. train loss: 0.16308\n",
      "Step #11700, epoch #130, avg. train loss: 0.16678\n",
      "Step #11800, epoch #131, avg. train loss: 0.16552\n",
      "Step #11900, epoch #132, avg. train loss: 0.16317\n",
      "Step #12000, epoch #133, avg. train loss: 0.16249\n",
      "Step #12100, epoch #134, avg. train loss: 0.16639\n",
      "Step #12200, epoch #135, avg. train loss: 0.16229\n",
      "Step #12300, epoch #136, avg. train loss: 0.16609\n",
      "Step #12400, epoch #137, avg. train loss: 0.16237\n",
      "Step #12500, epoch #138, avg. train loss: 0.16894\n",
      "Step #12600, epoch #140, avg. train loss: 0.16751\n",
      "Step #12700, epoch #141, avg. train loss: 0.16491\n",
      "Step #12800, epoch #142, avg. train loss: 0.16390\n",
      "Step #12900, epoch #143, avg. train loss: 0.16365\n",
      "Step #13000, epoch #144, avg. train loss: 0.16445\n",
      "Step #13100, epoch #145, avg. train loss: 0.16126\n",
      "Step #13200, epoch #146, avg. train loss: 0.16855\n",
      "Step #13300, epoch #147, avg. train loss: 0.16641\n",
      "Step #13400, epoch #148, avg. train loss: 0.16226\n",
      "Step #13500, epoch #150, avg. train loss: 0.16479\n",
      "Step #13600, epoch #151, avg. train loss: 0.16611\n",
      "Step #13700, epoch #152, avg. train loss: 0.16446\n",
      "Step #13800, epoch #153, avg. train loss: 0.16381\n",
      "Step #13900, epoch #154, avg. train loss: 0.16340\n",
      "Step #14000, epoch #155, avg. train loss: 0.16481\n",
      "Step #14100, epoch #156, avg. train loss: 0.16443\n",
      "Step #14200, epoch #157, avg. train loss: 0.16665\n",
      "Step #14300, epoch #158, avg. train loss: 0.16226\n",
      "Step #14400, epoch #160, avg. train loss: 0.16353\n",
      "Step #14500, epoch #161, avg. train loss: 0.16507\n",
      "Step #14600, epoch #162, avg. train loss: 0.16448\n",
      "Step #14700, epoch #163, avg. train loss: 0.16189\n",
      "Step #14800, epoch #164, avg. train loss: 0.16856\n",
      "Step #14900, epoch #165, avg. train loss: 0.16391\n",
      "Step #15000, epoch #166, avg. train loss: 0.16484\n",
      "Step #15100, epoch #167, avg. train loss: 0.16143\n",
      "Step #15200, epoch #168, avg. train loss: 0.16363\n",
      "Step #15300, epoch #170, avg. train loss: 0.16489\n",
      "Step #15400, epoch #171, avg. train loss: 0.16406\n",
      "Step #15500, epoch #172, avg. train loss: 0.16422\n",
      "Step #15600, epoch #173, avg. train loss: 0.16703\n",
      "Step #15700, epoch #174, avg. train loss: 0.16454\n",
      "Step #15800, epoch #175, avg. train loss: 0.16105\n",
      "Step #15900, epoch #176, avg. train loss: 0.16572\n",
      "Step #16000, epoch #177, avg. train loss: 0.16412\n",
      "Step #16100, epoch #178, avg. train loss: 0.16563\n",
      "Step #16200, epoch #180, avg. train loss: 0.16445\n",
      "Step #16300, epoch #181, avg. train loss: 0.16430\n",
      "Step #16400, epoch #182, avg. train loss: 0.16545\n",
      "Step #16500, epoch #183, avg. train loss: 0.16335\n",
      "Step #16600, epoch #184, avg. train loss: 0.16156\n",
      "Step #16700, epoch #185, avg. train loss: 0.16777\n",
      "Step #16800, epoch #186, avg. train loss: 0.16320\n",
      "Step #16900, epoch #187, avg. train loss: 0.16520\n",
      "Step #17000, epoch #188, avg. train loss: 0.16478\n",
      "Step #17100, epoch #190, avg. train loss: 0.16374\n",
      "Step #17200, epoch #191, avg. train loss: 0.16427\n",
      "Step #17300, epoch #192, avg. train loss: 0.16520\n",
      "Step #17400, epoch #193, avg. train loss: 0.16452\n",
      "Step #17500, epoch #194, avg. train loss: 0.16211\n",
      "Step #17600, epoch #195, avg. train loss: 0.16755\n",
      "Step #17700, epoch #196, avg. train loss: 0.16453\n",
      "Step #17800, epoch #197, avg. train loss: 0.16171\n",
      "Step #17900, epoch #198, avg. train loss: 0.16473\n",
      "Step #18000, epoch #200, avg. train loss: 0.16399\n",
      "Step #18100, epoch #201, avg. train loss: 0.16355\n",
      "Step #18200, epoch #202, avg. train loss: 0.16671\n",
      "Step #18300, epoch #203, avg. train loss: 0.16639\n",
      "Step #18400, epoch #204, avg. train loss: 0.16102\n",
      "Step #18500, epoch #205, avg. train loss: 0.16203\n",
      "Step #18600, epoch #206, avg. train loss: 0.16948\n",
      "Step #18700, epoch #207, avg. train loss: 0.16390\n",
      "Step #18800, epoch #208, avg. train loss: 0.16477\n",
      "Step #18900, epoch #210, avg. train loss: 0.16289\n",
      "Step #19000, epoch #211, avg. train loss: 0.16436\n",
      "Step #19100, epoch #212, avg. train loss: 0.16422\n",
      "Step #19200, epoch #213, avg. train loss: 0.16481\n",
      "Step #19300, epoch #214, avg. train loss: 0.16218\n",
      "Step #19400, epoch #215, avg. train loss: 0.16568\n",
      "Step #19500, epoch #216, avg. train loss: 0.16531\n",
      "Step #19600, epoch #217, avg. train loss: 0.16501\n",
      "Step #19700, epoch #218, avg. train loss: 0.16283\n",
      "Step #19800, epoch #220, avg. train loss: 0.16296\n",
      "Step #19900, epoch #221, avg. train loss: 0.16479\n",
      "Step #20000, epoch #222, avg. train loss: 0.16629\n",
      "Step #20100, epoch #223, avg. train loss: 0.16432\n",
      "Step #20200, epoch #224, avg. train loss: 0.16245\n",
      "Step #20300, epoch #225, avg. train loss: 0.16576\n",
      "Step #20400, epoch #226, avg. train loss: 0.16340\n",
      "Step #20500, epoch #227, avg. train loss: 0.16585\n",
      "Step #20600, epoch #228, avg. train loss: 0.16555\n",
      "Step #20700, epoch #230, avg. train loss: 0.16502\n",
      "Step #20800, epoch #231, avg. train loss: 0.16350\n",
      "Step #20900, epoch #232, avg. train loss: 0.16476\n",
      "Step #21000, epoch #233, avg. train loss: 0.16522\n",
      "Step #21100, epoch #234, avg. train loss: 0.16116\n",
      "Step #21200, epoch #235, avg. train loss: 0.16510\n",
      "Step #21300, epoch #236, avg. train loss: 0.16318\n",
      "Step #21400, epoch #237, avg. train loss: 0.16627\n",
      "Step #21500, epoch #238, avg. train loss: 0.16285\n",
      "Step #21600, epoch #240, avg. train loss: 0.16465\n",
      "Step #21700, epoch #241, avg. train loss: 0.16199\n",
      "Step #21800, epoch #242, avg. train loss: 0.16376\n",
      "Step #21900, epoch #243, avg. train loss: 0.16717\n",
      "Step #22000, epoch #244, avg. train loss: 0.16476\n",
      "Step #22100, epoch #245, avg. train loss: 0.16549\n",
      "Step #22200, epoch #246, avg. train loss: 0.16263\n",
      "Step #22300, epoch #247, avg. train loss: 0.16569\n",
      "Step #22400, epoch #248, avg. train loss: 0.16498\n",
      "Step #22500, epoch #250, avg. train loss: 0.16297\n",
      "Step #22600, epoch #251, avg. train loss: 0.16310\n",
      "Step #22700, epoch #252, avg. train loss: 0.16628\n",
      "Step #22800, epoch #253, avg. train loss: 0.16559\n",
      "Step #22900, epoch #254, avg. train loss: 0.16520\n",
      "Step #23000, epoch #255, avg. train loss: 0.16384\n",
      "Step #23100, epoch #256, avg. train loss: 0.16329\n",
      "Step #23200, epoch #257, avg. train loss: 0.16616\n",
      "Step #23300, epoch #258, avg. train loss: 0.16370\n",
      "Step #23400, epoch #260, avg. train loss: 0.16286\n",
      "Step #23500, epoch #261, avg. train loss: 0.16495\n",
      "Step #23600, epoch #262, avg. train loss: 0.16466\n",
      "Step #23700, epoch #263, avg. train loss: 0.16138\n",
      "Step #23800, epoch #264, avg. train loss: 0.16879\n",
      "Step #23900, epoch #265, avg. train loss: 0.16317\n",
      "Step #24000, epoch #266, avg. train loss: 0.16261\n",
      "Step #24100, epoch #267, avg. train loss: 0.16552\n",
      "Step #24200, epoch #268, avg. train loss: 0.16374\n",
      "Step #24300, epoch #270, avg. train loss: 0.16456\n",
      "Step #24400, epoch #271, avg. train loss: 0.16335\n",
      "Step #24500, epoch #272, avg. train loss: 0.16441\n",
      "Step #24600, epoch #273, avg. train loss: 0.16520\n",
      "Step #24700, epoch #274, avg. train loss: 0.16013\n",
      "Step #24800, epoch #275, avg. train loss: 0.16945\n",
      "Step #24900, epoch #276, avg. train loss: 0.16321\n",
      "Step #25000, epoch #277, avg. train loss: 0.16541\n",
      "Step #25100, epoch #278, avg. train loss: 0.16552\n",
      "Step #25200, epoch #280, avg. train loss: 0.16405\n",
      "Step #25300, epoch #281, avg. train loss: 0.16467\n",
      "Step #25400, epoch #282, avg. train loss: 0.16245\n",
      "Step #25500, epoch #283, avg. train loss: 0.16792\n",
      "Step #25600, epoch #284, avg. train loss: 0.16243\n",
      "Step #25700, epoch #285, avg. train loss: 0.16396\n",
      "Step #25800, epoch #286, avg. train loss: 0.16639\n",
      "Step #25900, epoch #287, avg. train loss: 0.16367\n",
      "Step #26000, epoch #288, avg. train loss: 0.16370\n",
      "Step #26100, epoch #290, avg. train loss: 0.16399\n",
      "Step #26200, epoch #291, avg. train loss: 0.16562\n",
      "Step #26300, epoch #292, avg. train loss: 0.16303\n",
      "Step #26400, epoch #293, avg. train loss: 0.16404\n",
      "Step #26500, epoch #294, avg. train loss: 0.16476\n",
      "Step #26600, epoch #295, avg. train loss: 0.16330\n",
      "Step #26700, epoch #296, avg. train loss: 0.16498\n",
      "Step #26800, epoch #297, avg. train loss: 0.16632\n",
      "Step #26900, epoch #298, avg. train loss: 0.16327\n",
      "Step #27000, epoch #300, avg. train loss: 0.16336\n",
      "Step #27100, epoch #301, avg. train loss: 0.16476\n",
      "Step #27200, epoch #302, avg. train loss: 0.16278\n",
      "Step #27300, epoch #303, avg. train loss: 0.16424\n",
      "Step #27400, epoch #304, avg. train loss: 0.16768\n",
      "Step #27500, epoch #305, avg. train loss: 0.16327\n",
      "Step #27600, epoch #306, avg. train loss: 0.16607\n",
      "Step #27700, epoch #307, avg. train loss: 0.16254\n",
      "Step #27800, epoch #308, avg. train loss: 0.16328\n",
      "Step #27900, epoch #310, avg. train loss: 0.16462\n",
      "Step #28000, epoch #311, avg. train loss: 0.16401\n",
      "Step #28100, epoch #312, avg. train loss: 161.88254\n",
      "Step #28200, epoch #313, avg. train loss: 0.16583\n",
      "Step #28300, epoch #314, avg. train loss: 0.16329\n",
      "Step #28400, epoch #315, avg. train loss: 0.16658\n",
      "Step #28500, epoch #316, avg. train loss: 0.16661\n",
      "Step #28600, epoch #317, avg. train loss: 0.16421\n",
      "Step #28700, epoch #318, avg. train loss: 0.16677\n",
      "Step #28800, epoch #320, avg. train loss: 0.16472\n",
      "Step #28900, epoch #321, avg. train loss: 0.16508\n",
      "Step #29000, epoch #322, avg. train loss: 0.16273\n",
      "Step #29100, epoch #323, avg. train loss: 0.16689\n",
      "Step #29200, epoch #324, avg. train loss: 0.16566\n",
      "Step #29300, epoch #325, avg. train loss: 0.16478\n",
      "Step #29400, epoch #326, avg. train loss: 0.16769\n",
      "Step #29500, epoch #327, avg. train loss: 0.16266\n",
      "Step #29600, epoch #328, avg. train loss: 0.16380\n",
      "Step #29700, epoch #330, avg. train loss: 0.16815\n",
      "Step #29800, epoch #331, avg. train loss: 0.16422\n",
      "Step #29900, epoch #332, avg. train loss: 0.16533\n",
      "Step #30000, epoch #333, avg. train loss: 0.16125\n",
      "Step #30100, epoch #334, avg. train loss: 0.16617\n",
      "Step #30200, epoch #335, avg. train loss: 0.16514\n",
      "Step #30300, epoch #336, avg. train loss: 0.16321\n",
      "Step #30400, epoch #337, avg. train loss: 0.16517\n",
      "Step #30500, epoch #338, avg. train loss: 0.16250\n",
      "Step #30600, epoch #340, avg. train loss: 0.16569\n",
      "Step #30700, epoch #341, avg. train loss: 0.16477\n",
      "Step #30800, epoch #342, avg. train loss: 0.16299\n",
      "Step #30900, epoch #343, avg. train loss: 0.16450\n",
      "Step #31000, epoch #344, avg. train loss: 0.16472\n",
      "Step #31100, epoch #345, avg. train loss: 0.16573\n",
      "Step #31200, epoch #346, avg. train loss: 0.16558\n",
      "Step #31300, epoch #347, avg. train loss: 0.16198\n",
      "Step #31400, epoch #348, avg. train loss: 0.16410\n",
      "Step #31500, epoch #350, avg. train loss: 0.16501\n",
      "Step #31600, epoch #351, avg. train loss: 0.16572\n",
      "Step #31700, epoch #352, avg. train loss: 0.16349\n",
      "Step #31800, epoch #353, avg. train loss: 0.16479\n",
      "Step #31900, epoch #354, avg. train loss: 0.16412\n",
      "Step #32000, epoch #355, avg. train loss: 0.16770\n",
      "Step #32100, epoch #356, avg. train loss: 0.16296\n",
      "Step #32200, epoch #357, avg. train loss: 0.16685\n",
      "Step #32300, epoch #358, avg. train loss: 0.16479\n",
      "Step #32400, epoch #360, avg. train loss: 0.16494\n",
      "Step #32500, epoch #361, avg. train loss: 0.16439\n",
      "Step #32600, epoch #362, avg. train loss: 0.16341\n",
      "Step #32700, epoch #363, avg. train loss: 0.16373\n",
      "Step #32800, epoch #364, avg. train loss: 0.16544\n",
      "Step #32900, epoch #365, avg. train loss: 0.16450\n",
      "Step #33000, epoch #366, avg. train loss: 0.16664\n",
      "Step #33100, epoch #367, avg. train loss: 0.16248\n",
      "Step #33200, epoch #368, avg. train loss: 0.16637\n",
      "Step #33300, epoch #370, avg. train loss: 0.16373\n",
      "Step #33400, epoch #371, avg. train loss: 0.16312\n",
      "Step #33500, epoch #372, avg. train loss: 0.16389\n",
      "Step #33600, epoch #373, avg. train loss: 0.16547\n",
      "Step #33700, epoch #374, avg. train loss: 0.16170\n",
      "Step #33800, epoch #375, avg. train loss: 0.16799\n",
      "Step #33900, epoch #376, avg. train loss: 0.16455\n",
      "Step #34000, epoch #377, avg. train loss: 0.16313\n",
      "Step #34100, epoch #378, avg. train loss: 0.16739\n",
      "Step #34200, epoch #380, avg. train loss: 0.16214\n",
      "Step #34300, epoch #381, avg. train loss: 0.16581\n",
      "Step #34400, epoch #382, avg. train loss: 0.16301\n",
      "Step #34500, epoch #383, avg. train loss: 0.16589\n",
      "Step #34600, epoch #384, avg. train loss: 0.16462\n",
      "Step #34700, epoch #385, avg. train loss: 0.15941\n",
      "Step #34800, epoch #386, avg. train loss: 0.16598\n",
      "Step #34900, epoch #387, avg. train loss: 0.16487\n",
      "Step #35000, epoch #388, avg. train loss: 0.16343\n",
      "Step #35100, epoch #390, avg. train loss: 0.16309\n",
      "Step #35200, epoch #391, avg. train loss: 0.16460\n",
      "Step #35300, epoch #392, avg. train loss: 0.16221\n",
      "Step #35400, epoch #393, avg. train loss: 0.16805\n",
      "Step #35500, epoch #394, avg. train loss: 0.16523\n",
      "Step #35600, epoch #395, avg. train loss: 0.16023\n",
      "Step #35700, epoch #396, avg. train loss: 0.16663\n",
      "Step #35800, epoch #397, avg. train loss: 0.16015\n",
      "Step #35900, epoch #398, avg. train loss: 0.16810\n",
      "Step #36000, epoch #400, avg. train loss: 0.16409\n",
      "Step #36100, epoch #401, avg. train loss: 0.16540\n",
      "Step #36200, epoch #402, avg. train loss: 0.16613\n",
      "Step #36300, epoch #403, avg. train loss: 0.16478\n",
      "Step #36400, epoch #404, avg. train loss: 0.16522\n",
      "Step #36500, epoch #405, avg. train loss: 0.16732\n",
      "Step #36600, epoch #406, avg. train loss: 0.16049\n",
      "Step #36700, epoch #407, avg. train loss: 0.16673\n",
      "Step #36800, epoch #408, avg. train loss: 0.16535\n",
      "Step #36900, epoch #410, avg. train loss: 0.16276\n",
      "Step #37000, epoch #411, avg. train loss: 0.16598\n",
      "Step #37100, epoch #412, avg. train loss: 0.16345\n",
      "Step #37200, epoch #413, avg. train loss: 0.16303\n",
      "Step #37300, epoch #414, avg. train loss: 0.16563\n",
      "Step #37400, epoch #415, avg. train loss: 0.15991\n",
      "Step #37500, epoch #416, avg. train loss: 0.16744\n",
      "Step #37600, epoch #417, avg. train loss: 0.16439\n",
      "Step #37700, epoch #418, avg. train loss: 0.16328\n",
      "Step #37800, epoch #420, avg. train loss: 0.16425\n",
      "Step #37900, epoch #421, avg. train loss: 0.16491\n",
      "Step #38000, epoch #422, avg. train loss: 0.16417\n",
      "Step #38100, epoch #423, avg. train loss: 0.16206\n",
      "Step #38200, epoch #424, avg. train loss: 0.16427\n",
      "Step #38300, epoch #425, avg. train loss: 0.16734\n",
      "Step #38400, epoch #426, avg. train loss: 0.16413\n",
      "Step #38500, epoch #427, avg. train loss: 0.16240\n",
      "Step #38600, epoch #428, avg. train loss: 0.16488\n",
      "Step #38700, epoch #430, avg. train loss: 0.16651\n",
      "Step #38800, epoch #431, avg. train loss: 0.16629\n",
      "Step #38900, epoch #432, avg. train loss: 0.16038\n",
      "Step #39000, epoch #433, avg. train loss: 0.16315\n",
      "Step #39100, epoch #434, avg. train loss: 0.16663\n",
      "Step #39200, epoch #435, avg. train loss: 0.16848\n",
      "Step #39300, epoch #436, avg. train loss: 0.16371\n",
      "Step #39400, epoch #437, avg. train loss: 0.16544\n",
      "Step #39500, epoch #438, avg. train loss: 0.16284\n",
      "Step #39600, epoch #440, avg. train loss: 0.16319\n",
      "Step #39700, epoch #441, avg. train loss: 0.16440\n",
      "Step #39800, epoch #442, avg. train loss: 0.16522\n",
      "Step #39900, epoch #443, avg. train loss: 0.16424\n",
      "Step #40000, epoch #444, avg. train loss: 0.16796\n",
      "Step #40100, epoch #445, avg. train loss: 0.16262\n",
      "Step #40200, epoch #446, avg. train loss: 0.16471\n",
      "Step #40300, epoch #447, avg. train loss: 0.16404\n",
      "Step #40400, epoch #448, avg. train loss: 0.16631\n",
      "Step #40500, epoch #450, avg. train loss: 0.16525\n",
      "Step #40600, epoch #451, avg. train loss: 0.16635\n",
      "Step #40700, epoch #452, avg. train loss: 0.16015\n",
      "Step #40800, epoch #453, avg. train loss: 0.16683\n",
      "Step #40900, epoch #454, avg. train loss: 0.16055\n",
      "Step #41000, epoch #455, avg. train loss: 0.16584\n",
      "Step #41100, epoch #456, avg. train loss: 0.16380\n",
      "Step #41200, epoch #457, avg. train loss: 0.16313\n",
      "Step #41300, epoch #458, avg. train loss: 0.16866\n",
      "Step #41400, epoch #460, avg. train loss: 0.16407\n",
      "Step #41500, epoch #461, avg. train loss: 0.16451\n",
      "Step #41600, epoch #462, avg. train loss: 0.16450\n",
      "Step #41700, epoch #463, avg. train loss: 0.16358\n",
      "Step #41800, epoch #464, avg. train loss: 0.16270\n",
      "Step #41900, epoch #465, avg. train loss: 0.16504\n",
      "Step #42000, epoch #466, avg. train loss: 0.16299\n",
      "Step #42100, epoch #467, avg. train loss: 0.16744\n",
      "Step #42200, epoch #468, avg. train loss: 0.16584\n",
      "Step #42300, epoch #470, avg. train loss: 0.16206\n",
      "Step #42400, epoch #471, avg. train loss: 0.16516\n",
      "Step #42500, epoch #472, avg. train loss: 0.16543\n",
      "Step #42600, epoch #473, avg. train loss: 0.16462\n",
      "Step #42700, epoch #474, avg. train loss: 0.16386\n",
      "Step #42800, epoch #475, avg. train loss: 0.16245\n",
      "Step #42900, epoch #476, avg. train loss: 0.16473\n",
      "Step #43000, epoch #477, avg. train loss: 0.16586\n",
      "Step #43100, epoch #478, avg. train loss: 0.16265\n",
      "Step #43200, epoch #480, avg. train loss: 0.16659\n",
      "Step #43300, epoch #481, avg. train loss: 0.16436\n",
      "Step #43400, epoch #482, avg. train loss: 0.16888\n",
      "Step #43500, epoch #483, avg. train loss: 0.16189\n",
      "Step #43600, epoch #484, avg. train loss: 0.16408\n",
      "Step #43700, epoch #485, avg. train loss: 0.16660\n",
      "Step #43800, epoch #486, avg. train loss: 0.16207\n",
      "Step #43900, epoch #487, avg. train loss: 0.16503\n",
      "Step #44000, epoch #488, avg. train loss: 0.16494\n",
      "Step #44100, epoch #490, avg. train loss: 0.16299\n",
      "Step #44200, epoch #491, avg. train loss: 0.16416\n",
      "Step #44300, epoch #492, avg. train loss: 0.16221\n",
      "Step #44400, epoch #493, avg. train loss: 0.16736\n",
      "Step #44500, epoch #494, avg. train loss: 0.16337\n",
      "Step #44600, epoch #495, avg. train loss: 0.16503\n",
      "Step #44700, epoch #496, avg. train loss: 0.16550\n",
      "Step #44800, epoch #497, avg. train loss: 0.16725\n",
      "Step #44900, epoch #498, avg. train loss: 0.16337\n",
      "Step #45000, epoch #500, avg. train loss: 0.16250\n",
      "Step #45100, epoch #501, avg. train loss: 0.16468\n",
      "Step #45200, epoch #502, avg. train loss: 0.16401\n",
      "Step #45300, epoch #503, avg. train loss: 0.16645\n",
      "Step #45400, epoch #504, avg. train loss: 0.16204\n",
      "Step #45500, epoch #505, avg. train loss: 0.16375\n",
      "Step #45600, epoch #506, avg. train loss: 0.16526\n",
      "Step #45700, epoch #507, avg. train loss: 0.16306\n",
      "Step #45800, epoch #508, avg. train loss: 0.16249\n",
      "Step #45900, epoch #510, avg. train loss: 0.16824\n",
      "Step #46000, epoch #511, avg. train loss: 0.16336\n",
      "Step #46100, epoch #512, avg. train loss: 0.16628\n",
      "Step #46200, epoch #513, avg. train loss: 0.16337\n",
      "Step #46300, epoch #514, avg. train loss: 0.16369\n",
      "Step #46400, epoch #515, avg. train loss: 0.16511\n",
      "Step #46500, epoch #516, avg. train loss: 0.16731\n",
      "Step #46600, epoch #517, avg. train loss: 0.16232\n",
      "Step #46700, epoch #518, avg. train loss: 0.16258\n",
      "Step #46800, epoch #520, avg. train loss: 0.16542\n",
      "Step #46900, epoch #521, avg. train loss: 0.16300\n",
      "Step #47000, epoch #522, avg. train loss: 0.16408\n",
      "Step #47100, epoch #523, avg. train loss: 0.16529\n",
      "Step #47200, epoch #524, avg. train loss: 0.16454\n",
      "Step #47300, epoch #525, avg. train loss: 0.16526\n",
      "Step #47400, epoch #526, avg. train loss: 0.16556\n",
      "Step #47500, epoch #527, avg. train loss: 0.16248\n",
      "Step #47600, epoch #528, avg. train loss: 0.16337\n",
      "Step #47700, epoch #530, avg. train loss: 0.16785\n",
      "Step #47800, epoch #531, avg. train loss: 0.16513\n",
      "Step #47900, epoch #532, avg. train loss: 0.16244\n",
      "Step #48000, epoch #533, avg. train loss: 0.16690\n",
      "Step #48100, epoch #534, avg. train loss: 0.16409\n",
      "Step #48200, epoch #535, avg. train loss: 0.16389\n",
      "Step #48300, epoch #536, avg. train loss: 0.16710\n",
      "Step #48400, epoch #537, avg. train loss: 0.16287\n",
      "Step #48500, epoch #538, avg. train loss: 0.16594\n",
      "Step #48600, epoch #540, avg. train loss: 0.16366\n",
      "Step #48700, epoch #541, avg. train loss: 0.16404\n",
      "Step #48800, epoch #542, avg. train loss: 0.16320\n",
      "Step #48900, epoch #543, avg. train loss: 0.16424\n",
      "Step #49000, epoch #544, avg. train loss: 0.16429\n",
      "Step #49100, epoch #545, avg. train loss: 0.16514\n",
      "Step #49200, epoch #546, avg. train loss: 0.16525\n",
      "Step #49300, epoch #547, avg. train loss: 0.16461\n",
      "Step #49400, epoch #548, avg. train loss: 0.16615\n",
      "Step #49500, epoch #550, avg. train loss: 0.16374\n",
      "Step #49600, epoch #551, avg. train loss: 0.16449\n",
      "Step #49700, epoch #552, avg. train loss: 0.16406\n",
      "Step #49800, epoch #553, avg. train loss: 0.16876\n",
      "Step #49900, epoch #554, avg. train loss: 0.15931\n",
      "Step #50000, epoch #555, avg. train loss: 0.16559\n",
      "Step #50100, epoch #556, avg. train loss: 0.16580\n",
      "Step #50200, epoch #557, avg. train loss: 0.16469\n",
      "Step #50300, epoch #558, avg. train loss: 0.16288\n",
      "Step #50400, epoch #560, avg. train loss: 0.16375\n",
      "Step #50500, epoch #561, avg. train loss: 0.16361\n",
      "Step #50600, epoch #562, avg. train loss: 0.16487\n",
      "Step #50700, epoch #563, avg. train loss: 0.16514\n",
      "Step #50800, epoch #564, avg. train loss: 0.16159\n",
      "Step #50900, epoch #565, avg. train loss: 0.16519\n",
      "Step #51000, epoch #566, avg. train loss: 0.16567\n",
      "Step #51100, epoch #567, avg. train loss: 0.16359\n",
      "Step #51200, epoch #568, avg. train loss: 0.16497\n",
      "Step #51300, epoch #570, avg. train loss: 0.16222\n",
      "Step #51400, epoch #571, avg. train loss: 0.16486\n",
      "Step #51500, epoch #572, avg. train loss: 0.16306\n",
      "Step #51600, epoch #573, avg. train loss: 0.16427\n",
      "Step #51700, epoch #574, avg. train loss: 0.16539\n",
      "Step #51800, epoch #575, avg. train loss: 0.16397\n",
      "Step #51900, epoch #576, avg. train loss: 0.16171\n",
      "Step #52000, epoch #577, avg. train loss: 0.16670\n",
      "Step #52100, epoch #578, avg. train loss: 0.16448\n",
      "Step #52200, epoch #580, avg. train loss: 0.16699\n",
      "Step #52300, epoch #581, avg. train loss: 0.16569\n",
      "Step #52400, epoch #582, avg. train loss: 0.16586\n",
      "Step #52500, epoch #583, avg. train loss: 0.16514\n",
      "Step #52600, epoch #584, avg. train loss: 0.16310\n",
      "Step #52700, epoch #585, avg. train loss: 0.16562\n",
      "Step #52800, epoch #586, avg. train loss: 0.16193\n",
      "Step #52900, epoch #587, avg. train loss: 0.16682\n",
      "Step #53000, epoch #588, avg. train loss: 0.16736\n",
      "Step #53100, epoch #590, avg. train loss: 0.16525\n",
      "Step #53200, epoch #591, avg. train loss: 0.16450\n",
      "Step #53300, epoch #592, avg. train loss: 0.16375\n",
      "Step #53400, epoch #593, avg. train loss: 0.16517\n",
      "Step #53500, epoch #594, avg. train loss: 0.16605\n",
      "Step #53600, epoch #595, avg. train loss: 0.16271\n",
      "Step #53700, epoch #596, avg. train loss: 0.16172\n",
      "Step #53800, epoch #597, avg. train loss: 0.16580\n",
      "Step #53900, epoch #598, avg. train loss: 0.16140\n",
      "Step #54000, epoch #600, avg. train loss: 0.16429\n",
      "Step #54100, epoch #601, avg. train loss: 0.16555\n",
      "Step #54200, epoch #602, avg. train loss: 0.16440\n",
      "Step #54300, epoch #603, avg. train loss: 0.16632\n",
      "Step #54400, epoch #604, avg. train loss: 0.16208\n",
      "Step #54500, epoch #605, avg. train loss: 0.16479\n",
      "Step #54600, epoch #606, avg. train loss: 0.16403\n",
      "Step #54700, epoch #607, avg. train loss: 0.16463\n",
      "Step #54800, epoch #608, avg. train loss: 0.16262\n",
      "Step #54900, epoch #610, avg. train loss: 0.16431\n",
      "Step #55000, epoch #611, avg. train loss: 0.16394\n",
      "Step #55100, epoch #612, avg. train loss: 0.16353\n",
      "Step #55200, epoch #613, avg. train loss: 0.16193\n",
      "Step #55300, epoch #614, avg. train loss: 0.16653\n",
      "Step #55400, epoch #615, avg. train loss: 0.16396\n",
      "Step #55500, epoch #616, avg. train loss: 0.16442\n",
      "Step #55600, epoch #617, avg. train loss: 0.16513\n",
      "Step #55700, epoch #618, avg. train loss: 0.16275\n",
      "Step #55800, epoch #620, avg. train loss: 0.16455\n",
      "Step #55900, epoch #621, avg. train loss: 0.16418\n",
      "Step #56000, epoch #622, avg. train loss: 0.16542\n",
      "Step #56100, epoch #623, avg. train loss: 0.16256\n",
      "Step #56200, epoch #624, avg. train loss: 0.16410\n",
      "Step #56300, epoch #625, avg. train loss: 0.16588\n",
      "Step #56400, epoch #626, avg. train loss: 0.16176\n",
      "Step #56500, epoch #627, avg. train loss: 0.16913\n",
      "Step #56600, epoch #628, avg. train loss: 0.16551\n",
      "Step #56700, epoch #630, avg. train loss: 0.16483\n",
      "Step #56800, epoch #631, avg. train loss: 0.16496\n",
      "Step #56900, epoch #632, avg. train loss: 0.16377\n",
      "Step #57000, epoch #633, avg. train loss: 0.16267\n",
      "Step #57100, epoch #634, avg. train loss: 0.16354\n",
      "Step #57200, epoch #635, avg. train loss: 0.16762\n",
      "Step #57300, epoch #636, avg. train loss: 0.16265\n",
      "Step #57400, epoch #637, avg. train loss: 0.16702\n",
      "Step #57500, epoch #638, avg. train loss: 0.16505\n",
      "Step #57600, epoch #640, avg. train loss: 0.16619\n",
      "Step #57700, epoch #641, avg. train loss: 0.16275\n",
      "Step #57800, epoch #642, avg. train loss: 0.16431\n",
      "Step #57900, epoch #643, avg. train loss: 0.16423\n",
      "Step #58000, epoch #644, avg. train loss: 0.16186\n",
      "Step #58100, epoch #645, avg. train loss: 0.16272\n",
      "Step #58200, epoch #646, avg. train loss: 0.16708\n",
      "Step #58300, epoch #647, avg. train loss: 0.16361\n",
      "Step #58400, epoch #648, avg. train loss: 0.16499\n",
      "Step #58500, epoch #650, avg. train loss: 0.16516\n",
      "Step #58600, epoch #651, avg. train loss: 0.16544\n",
      "Step #58700, epoch #652, avg. train loss: 0.16376\n",
      "Step #58800, epoch #653, avg. train loss: 0.16678\n",
      "Step #58900, epoch #654, avg. train loss: 0.16520\n",
      "Step #59000, epoch #655, avg. train loss: 0.16405\n",
      "Step #59100, epoch #656, avg. train loss: 0.16318\n",
      "Step #59200, epoch #657, avg. train loss: 0.16616\n",
      "Step #59300, epoch #658, avg. train loss: 0.16309\n",
      "Step #59400, epoch #660, avg. train loss: 0.16757\n",
      "Step #59500, epoch #661, avg. train loss: 0.16459\n",
      "Step #59600, epoch #662, avg. train loss: 0.16860\n",
      "Step #59700, epoch #663, avg. train loss: 0.16368\n",
      "Step #59800, epoch #664, avg. train loss: 0.16449\n",
      "Step #59900, epoch #665, avg. train loss: 0.16504\n",
      "Step #60000, epoch #666, avg. train loss: 0.16497\n",
      "Step #60100, epoch #667, avg. train loss: 0.16393\n",
      "Step #60200, epoch #668, avg. train loss: 0.16690\n",
      "Step #60300, epoch #670, avg. train loss: 0.16318\n",
      "Step #60400, epoch #671, avg. train loss: 0.16320\n",
      "Step #60500, epoch #672, avg. train loss: 0.16566\n",
      "Step #60600, epoch #673, avg. train loss: 0.16307\n",
      "Step #60700, epoch #674, avg. train loss: 0.16546\n",
      "Step #60800, epoch #675, avg. train loss: 0.16124\n",
      "Step #60900, epoch #676, avg. train loss: 0.16563\n",
      "Step #61000, epoch #677, avg. train loss: 0.16839\n",
      "Step #61100, epoch #678, avg. train loss: 0.16311\n",
      "Step #61200, epoch #680, avg. train loss: 0.16513\n",
      "Step #61300, epoch #681, avg. train loss: 0.16345\n",
      "Step #61400, epoch #682, avg. train loss: 0.16654\n",
      "Step #61500, epoch #683, avg. train loss: 0.16418\n",
      "Step #61600, epoch #684, avg. train loss: 0.16499\n",
      "Step #61700, epoch #685, avg. train loss: 0.16370\n",
      "Step #61800, epoch #686, avg. train loss: 0.16466\n",
      "Step #61900, epoch #687, avg. train loss: 0.16638\n",
      "Step #62000, epoch #688, avg. train loss: 0.16358\n",
      "Step #62100, epoch #690, avg. train loss: 0.16457\n",
      "Step #62200, epoch #691, avg. train loss: 0.16422\n",
      "Step #62300, epoch #692, avg. train loss: 0.16446\n",
      "Step #62400, epoch #693, avg. train loss: 0.16202\n",
      "Step #62500, epoch #694, avg. train loss: 0.16504\n",
      "Step #62600, epoch #695, avg. train loss: 0.16454\n",
      "Step #62700, epoch #696, avg. train loss: 0.16723\n",
      "Step #62800, epoch #697, avg. train loss: 0.16132\n",
      "Step #62900, epoch #698, avg. train loss: 0.16709\n",
      "Step #63000, epoch #700, avg. train loss: 0.16633\n",
      "Step #63100, epoch #701, avg. train loss: 0.16413\n",
      "Step #63200, epoch #702, avg. train loss: 0.16260\n",
      "Step #63300, epoch #703, avg. train loss: 0.16827\n",
      "Step #63400, epoch #704, avg. train loss: 0.16460\n",
      "Step #63500, epoch #705, avg. train loss: 0.16403\n",
      "Step #63600, epoch #706, avg. train loss: 0.16827\n",
      "Step #63700, epoch #707, avg. train loss: 0.16312\n",
      "Step #63800, epoch #708, avg. train loss: 0.16548\n",
      "Step #63900, epoch #710, avg. train loss: 0.16616\n",
      "Step #64000, epoch #711, avg. train loss: 0.16306\n",
      "Step #64100, epoch #712, avg. train loss: 0.16589\n",
      "Step #64200, epoch #713, avg. train loss: 0.16489\n",
      "Step #64300, epoch #714, avg. train loss: 0.16490\n",
      "Step #64400, epoch #715, avg. train loss: 0.16598\n",
      "Step #64500, epoch #716, avg. train loss: 0.16433\n",
      "Step #64600, epoch #717, avg. train loss: 0.16176\n",
      "Step #64700, epoch #718, avg. train loss: 0.16644\n",
      "Step #64800, epoch #720, avg. train loss: 0.16545\n",
      "Step #64900, epoch #721, avg. train loss: 0.16419\n",
      "Step #65000, epoch #722, avg. train loss: 0.16621\n",
      "Step #65100, epoch #723, avg. train loss: 0.16459\n",
      "Step #65200, epoch #724, avg. train loss: 0.16045\n",
      "Step #65300, epoch #725, avg. train loss: 0.16579\n",
      "Step #65400, epoch #726, avg. train loss: 0.16124\n",
      "Step #65500, epoch #727, avg. train loss: 0.16692\n",
      "Step #65600, epoch #728, avg. train loss: 0.16319\n",
      "Step #65700, epoch #730, avg. train loss: 0.16623\n",
      "Step #65800, epoch #731, avg. train loss: 0.16518\n",
      "Step #65900, epoch #732, avg. train loss: 0.16392\n",
      "Step #66000, epoch #733, avg. train loss: 0.16368\n",
      "Step #66100, epoch #734, avg. train loss: 0.16551\n",
      "Step #66200, epoch #735, avg. train loss: 0.16435\n",
      "Step #66300, epoch #736, avg. train loss: 0.16468\n",
      "Step #66400, epoch #737, avg. train loss: 0.16380\n",
      "Step #66500, epoch #738, avg. train loss: 0.16472\n",
      "Step #66600, epoch #740, avg. train loss: 0.16488\n",
      "Step #66700, epoch #741, avg. train loss: 0.16448\n",
      "Step #66800, epoch #742, avg. train loss: 0.16451\n",
      "Step #66900, epoch #743, avg. train loss: 0.16423\n",
      "Step #67000, epoch #744, avg. train loss: 0.16287\n",
      "Step #67100, epoch #745, avg. train loss: 0.16522\n",
      "Step #67200, epoch #746, avg. train loss: 0.16542\n",
      "Step #67300, epoch #747, avg. train loss: 0.16330\n",
      "Step #67400, epoch #748, avg. train loss: 0.16625\n",
      "Step #67500, epoch #750, avg. train loss: 0.16574\n",
      "Step #67600, epoch #751, avg. train loss: 0.16492\n",
      "Step #67700, epoch #752, avg. train loss: 0.16476\n",
      "Step #67800, epoch #753, avg. train loss: 0.16502\n",
      "Step #67900, epoch #754, avg. train loss: 0.16298\n",
      "Step #68000, epoch #755, avg. train loss: 0.16607\n",
      "Step #68100, epoch #756, avg. train loss: 0.16347\n",
      "Step #68200, epoch #757, avg. train loss: 0.16488\n",
      "Step #68300, epoch #758, avg. train loss: 0.16508\n",
      "Step #68400, epoch #760, avg. train loss: 0.16348\n",
      "Step #68500, epoch #761, avg. train loss: 0.16401\n",
      "Step #68600, epoch #762, avg. train loss: 0.16573\n",
      "Step #68700, epoch #763, avg. train loss: 0.16547\n",
      "Step #68800, epoch #764, avg. train loss: 0.16332\n",
      "Step #68900, epoch #765, avg. train loss: 0.16260\n",
      "Step #69000, epoch #766, avg. train loss: 0.16668\n",
      "Step #69100, epoch #767, avg. train loss: 0.16521\n",
      "Step #69200, epoch #768, avg. train loss: 0.16408\n",
      "Step #69300, epoch #770, avg. train loss: 0.16430\n",
      "Step #69400, epoch #771, avg. train loss: 0.16576\n",
      "Step #69500, epoch #772, avg. train loss: 0.16418\n",
      "Step #69600, epoch #773, avg. train loss: 0.16453\n",
      "Step #69700, epoch #774, avg. train loss: 0.16458\n",
      "Step #69800, epoch #775, avg. train loss: 0.16292\n",
      "Step #69900, epoch #776, avg. train loss: 0.16310\n",
      "Step #70000, epoch #777, avg. train loss: 0.16336\n",
      "Step #70100, epoch #778, avg. train loss: 0.16594\n",
      "Step #70200, epoch #780, avg. train loss: 0.16698\n",
      "Step #70300, epoch #781, avg. train loss: 0.16400\n",
      "Step #70400, epoch #782, avg. train loss: 0.16428\n",
      "Step #70500, epoch #783, avg. train loss: 0.16172\n",
      "Step #70600, epoch #784, avg. train loss: 0.16720\n",
      "Step #70700, epoch #785, avg. train loss: 0.16342\n",
      "Step #70800, epoch #786, avg. train loss: 0.16362\n",
      "Step #70900, epoch #787, avg. train loss: 0.16377\n",
      "Step #71000, epoch #788, avg. train loss: 0.16341\n",
      "Step #71100, epoch #790, avg. train loss: 0.16331\n",
      "Step #71200, epoch #791, avg. train loss: 0.16430\n",
      "Step #71300, epoch #792, avg. train loss: 0.16719\n",
      "Step #71400, epoch #793, avg. train loss: 0.16261\n",
      "Step #71500, epoch #794, avg. train loss: 0.16540\n",
      "Step #71600, epoch #795, avg. train loss: 0.16706\n",
      "Step #71700, epoch #796, avg. train loss: 0.16522\n",
      "Step #71800, epoch #797, avg. train loss: 0.16213\n",
      "Step #71900, epoch #798, avg. train loss: 0.16273\n",
      "Step #72000, epoch #800, avg. train loss: 0.16473\n",
      "Step #72100, epoch #801, avg. train loss: 0.16554\n",
      "Step #72200, epoch #802, avg. train loss: 0.16757\n",
      "Step #72300, epoch #803, avg. train loss: 0.16040\n",
      "Step #72400, epoch #804, avg. train loss: 0.16855\n",
      "Step #72500, epoch #805, avg. train loss: 0.16541\n",
      "Step #72600, epoch #806, avg. train loss: 0.16635\n",
      "Step #72700, epoch #807, avg. train loss: 0.16162\n",
      "Step #72800, epoch #808, avg. train loss: 0.16618\n",
      "Step #72900, epoch #810, avg. train loss: 0.16515\n",
      "Step #73000, epoch #811, avg. train loss: 0.16393\n",
      "Step #73100, epoch #812, avg. train loss: 0.16538\n",
      "Step #73200, epoch #813, avg. train loss: 0.16347\n",
      "Step #73300, epoch #814, avg. train loss: 0.16608\n",
      "Step #73400, epoch #815, avg. train loss: 0.16439\n",
      "Step #73500, epoch #816, avg. train loss: 0.16334\n",
      "Step #73600, epoch #817, avg. train loss: 0.16055\n",
      "Step #73700, epoch #818, avg. train loss: 0.16767\n",
      "Step #73800, epoch #820, avg. train loss: 0.16652\n",
      "Step #73900, epoch #821, avg. train loss: 0.16326\n",
      "Step #74000, epoch #822, avg. train loss: 0.16203\n",
      "Step #74100, epoch #823, avg. train loss: 0.16571\n",
      "Step #74200, epoch #824, avg. train loss: 0.16462\n",
      "Step #74300, epoch #825, avg. train loss: 0.16577\n",
      "Step #74400, epoch #826, avg. train loss: 0.16499\n",
      "Step #74500, epoch #827, avg. train loss: 0.16732\n",
      "Step #74600, epoch #828, avg. train loss: 0.16119\n",
      "Step #74700, epoch #830, avg. train loss: 0.16585\n",
      "Step #74800, epoch #831, avg. train loss: 0.16487\n",
      "Step #74900, epoch #832, avg. train loss: 0.16420\n",
      "Step #75000, epoch #833, avg. train loss: 0.16810\n",
      "Step #75100, epoch #834, avg. train loss: 0.16380\n",
      "Step #75200, epoch #835, avg. train loss: 0.16399\n",
      "Step #75300, epoch #836, avg. train loss: 0.16539\n",
      "Step #75400, epoch #837, avg. train loss: 0.16481\n",
      "Step #75500, epoch #838, avg. train loss: 0.16266\n",
      "Step #75600, epoch #840, avg. train loss: 0.16292\n",
      "Step #75700, epoch #841, avg. train loss: 0.16532\n",
      "Step #75800, epoch #842, avg. train loss: 0.16236\n",
      "Step #75900, epoch #843, avg. train loss: 0.16621\n",
      "Step #76000, epoch #844, avg. train loss: 0.16261\n",
      "Step #76100, epoch #845, avg. train loss: 0.16638\n",
      "Step #76200, epoch #846, avg. train loss: 0.16333\n",
      "Step #76300, epoch #847, avg. train loss: 0.16415\n",
      "Step #76400, epoch #848, avg. train loss: 0.16469\n",
      "Step #76500, epoch #850, avg. train loss: 0.16430\n",
      "Step #76600, epoch #851, avg. train loss: 0.16541\n",
      "Step #76700, epoch #852, avg. train loss: 0.16203\n",
      "Step #76800, epoch #853, avg. train loss: 0.16485\n",
      "Step #76900, epoch #854, avg. train loss: 0.16437\n",
      "Step #77000, epoch #855, avg. train loss: 0.16367\n",
      "Step #77100, epoch #856, avg. train loss: 0.16442\n",
      "Step #77200, epoch #857, avg. train loss: 0.16449\n",
      "Step #77300, epoch #858, avg. train loss: 0.16272\n",
      "Step #77400, epoch #860, avg. train loss: 0.16478\n",
      "Step #77500, epoch #861, avg. train loss: 0.16443\n",
      "Step #77600, epoch #862, avg. train loss: 0.16417\n",
      "Step #77700, epoch #863, avg. train loss: 0.16394\n",
      "Step #77800, epoch #864, avg. train loss: 0.16420\n",
      "Step #77900, epoch #865, avg. train loss: 0.16328\n",
      "Step #78000, epoch #866, avg. train loss: 0.16457\n",
      "Step #78100, epoch #867, avg. train loss: 0.16495\n",
      "Step #78200, epoch #868, avg. train loss: 0.16427\n",
      "Step #78300, epoch #870, avg. train loss: 0.16343\n",
      "Step #78400, epoch #871, avg. train loss: 0.16219\n",
      "Step #78500, epoch #872, avg. train loss: 0.16505\n",
      "Step #78600, epoch #873, avg. train loss: 0.16496\n",
      "Step #78700, epoch #874, avg. train loss: 0.16470\n",
      "Step #78800, epoch #875, avg. train loss: 0.16294\n",
      "Step #78900, epoch #876, avg. train loss: 0.16644\n",
      "Step #79000, epoch #877, avg. train loss: 0.16436\n",
      "Step #79100, epoch #878, avg. train loss: 0.16377\n",
      "Step #79200, epoch #880, avg. train loss: 0.16249\n",
      "Step #79300, epoch #881, avg. train loss: 0.16411\n",
      "Step #79400, epoch #882, avg. train loss: 0.16241\n",
      "Step #79500, epoch #883, avg. train loss: 0.16449\n",
      "Step #79600, epoch #884, avg. train loss: 0.16614\n",
      "Step #79700, epoch #885, avg. train loss: 0.16164\n",
      "Step #79800, epoch #886, avg. train loss: 0.16347\n",
      "Step #79900, epoch #887, avg. train loss: 0.16875\n",
      "Step #80000, epoch #888, avg. train loss: 0.16557\n",
      "Step #80100, epoch #890, avg. train loss: 0.16278\n",
      "Step #80200, epoch #891, avg. train loss: 0.16541\n",
      "Step #80300, epoch #892, avg. train loss: 0.16374\n",
      "Step #80400, epoch #893, avg. train loss: 0.16487\n",
      "Step #80500, epoch #894, avg. train loss: 0.16278\n",
      "Step #80600, epoch #895, avg. train loss: 0.16465\n",
      "Step #80700, epoch #896, avg. train loss: 0.17051\n",
      "Step #80800, epoch #897, avg. train loss: 0.16173\n",
      "Step #80900, epoch #898, avg. train loss: 0.16270\n",
      "Step #81000, epoch #900, avg. train loss: 0.16495\n",
      "Step #81100, epoch #901, avg. train loss: 0.16370\n",
      "Step #81200, epoch #902, avg. train loss: 0.16489\n",
      "Step #81300, epoch #903, avg. train loss: 0.16274\n",
      "Step #81400, epoch #904, avg. train loss: 0.16559\n",
      "Step #81500, epoch #905, avg. train loss: 0.16651\n",
      "Step #81600, epoch #906, avg. train loss: 0.16855\n",
      "Step #81700, epoch #907, avg. train loss: 0.16302\n",
      "Step #81800, epoch #908, avg. train loss: 0.16260\n",
      "Step #81900, epoch #910, avg. train loss: 0.16511\n",
      "Step #82000, epoch #911, avg. train loss: 0.16369\n",
      "Step #82100, epoch #912, avg. train loss: 0.16336\n",
      "Step #82200, epoch #913, avg. train loss: 0.16718\n",
      "Step #82300, epoch #914, avg. train loss: 0.16490\n",
      "Step #82400, epoch #915, avg. train loss: 0.16228\n",
      "Step #82500, epoch #916, avg. train loss: 0.16517\n",
      "Step #82600, epoch #917, avg. train loss: 0.16587\n",
      "Step #82700, epoch #918, avg. train loss: 0.16171\n",
      "Step #82800, epoch #920, avg. train loss: 0.16659\n",
      "Step #82900, epoch #921, avg. train loss: 0.16611\n",
      "Step #83000, epoch #922, avg. train loss: 0.16509\n",
      "Step #83100, epoch #923, avg. train loss: 0.16369\n",
      "Step #83200, epoch #924, avg. train loss: 0.16467\n",
      "Step #83300, epoch #925, avg. train loss: 0.16513\n",
      "Step #83400, epoch #926, avg. train loss: 0.16430\n",
      "Step #83500, epoch #927, avg. train loss: 0.16673\n",
      "Step #83600, epoch #928, avg. train loss: 0.16383\n",
      "Step #83700, epoch #930, avg. train loss: 0.16509\n",
      "Step #83800, epoch #931, avg. train loss: 0.16452\n",
      "Step #83900, epoch #932, avg. train loss: 0.16617\n",
      "Step #84000, epoch #933, avg. train loss: 0.16473\n",
      "Step #84100, epoch #934, avg. train loss: 0.16693\n",
      "Step #84200, epoch #935, avg. train loss: 0.16425\n",
      "Step #84300, epoch #936, avg. train loss: 0.16683\n",
      "Step #84400, epoch #937, avg. train loss: 0.16105\n",
      "Step #84500, epoch #938, avg. train loss: 0.16652\n",
      "Step #84600, epoch #940, avg. train loss: 0.16588\n",
      "Step #84700, epoch #941, avg. train loss: 0.16486\n",
      "Step #84800, epoch #942, avg. train loss: 0.16560\n",
      "Step #84900, epoch #943, avg. train loss: 0.16253\n",
      "Step #85000, epoch #944, avg. train loss: 0.16823\n",
      "Step #85100, epoch #945, avg. train loss: 0.16514\n",
      "Step #85200, epoch #946, avg. train loss: 0.16328\n",
      "Step #85300, epoch #947, avg. train loss: 0.16457\n",
      "Step #85400, epoch #948, avg. train loss: 0.16033\n",
      "Step #85500, epoch #950, avg. train loss: 0.16807\n",
      "Step #85600, epoch #951, avg. train loss: 0.16426\n",
      "Step #85700, epoch #952, avg. train loss: 0.16265\n",
      "Step #85800, epoch #953, avg. train loss: 0.16567\n",
      "Step #85900, epoch #954, avg. train loss: 0.16242\n",
      "Step #86000, epoch #955, avg. train loss: 0.16672\n",
      "Step #86100, epoch #956, avg. train loss: 0.16360\n",
      "Step #86200, epoch #957, avg. train loss: 0.16246\n",
      "Step #86300, epoch #958, avg. train loss: 0.16466\n",
      "Step #86400, epoch #960, avg. train loss: 0.16293\n",
      "Step #86500, epoch #961, avg. train loss: 0.16447\n",
      "Step #86600, epoch #962, avg. train loss: 0.16446\n",
      "Step #86700, epoch #963, avg. train loss: 0.16617\n",
      "Step #86800, epoch #964, avg. train loss: 0.16543\n",
      "Step #86900, epoch #965, avg. train loss: 0.16197\n",
      "Step #87000, epoch #966, avg. train loss: 0.16713\n",
      "Step #87100, epoch #967, avg. train loss: 0.16229\n",
      "Step #87200, epoch #968, avg. train loss: 0.16570\n",
      "Step #87300, epoch #970, avg. train loss: 0.16380\n",
      "Step #87400, epoch #971, avg. train loss: 0.16483\n",
      "Step #87500, epoch #972, avg. train loss: 0.16444\n",
      "Step #87600, epoch #973, avg. train loss: 0.16409\n",
      "Step #87700, epoch #974, avg. train loss: 0.16308\n",
      "Step #87800, epoch #975, avg. train loss: 0.16329\n",
      "Step #87900, epoch #976, avg. train loss: 0.16820\n",
      "Step #88000, epoch #977, avg. train loss: 0.16108\n",
      "Step #88100, epoch #978, avg. train loss: 0.16463\n",
      "Step #88200, epoch #980, avg. train loss: 0.16179\n",
      "Step #88300, epoch #981, avg. train loss: 0.16633\n",
      "Step #88400, epoch #982, avg. train loss: 0.16198\n",
      "Step #88500, epoch #983, avg. train loss: 0.16452\n",
      "Step #88600, epoch #984, avg. train loss: 0.16354\n",
      "Step #88700, epoch #985, avg. train loss: 0.16581\n",
      "Step #88800, epoch #986, avg. train loss: 0.16474\n",
      "Step #88900, epoch #987, avg. train loss: 0.16707\n",
      "Step #89000, epoch #988, avg. train loss: 0.16144\n",
      "Step #89100, epoch #990, avg. train loss: 0.16796\n",
      "Step #89200, epoch #991, avg. train loss: 0.16526\n",
      "Step #89300, epoch #992, avg. train loss: 0.16297\n",
      "Step #89400, epoch #993, avg. train loss: 0.16557\n",
      "Step #89500, epoch #994, avg. train loss: 0.16547\n",
      "Step #89600, epoch #995, avg. train loss: 0.16169\n",
      "Step #89700, epoch #996, avg. train loss: 0.16677\n",
      "Step #89800, epoch #997, avg. train loss: 0.16567\n",
      "Step #89900, epoch #998, avg. train loss: 0.16515\n",
      "Step #90000, epoch #1000, avg. train loss: 0.16345\n",
      "Step #90100, epoch #1001, avg. train loss: 0.16442\n",
      "Step #90200, epoch #1002, avg. train loss: 0.16597\n",
      "Step #90300, epoch #1003, avg. train loss: 0.16260\n",
      "Step #90400, epoch #1004, avg. train loss: 0.16571\n",
      "Step #90500, epoch #1005, avg. train loss: 0.16345\n",
      "Step #90600, epoch #1006, avg. train loss: 0.16695\n",
      "Step #90700, epoch #1007, avg. train loss: 0.16352\n",
      "Step #90800, epoch #1008, avg. train loss: 0.16278\n",
      "Step #90900, epoch #1010, avg. train loss: 0.16591\n",
      "Step #91000, epoch #1011, avg. train loss: 0.16452\n",
      "Step #91100, epoch #1012, avg. train loss: 0.16471\n",
      "Step #91200, epoch #1013, avg. train loss: 0.16271\n",
      "Step #91300, epoch #1014, avg. train loss: 0.16772\n",
      "Step #91400, epoch #1015, avg. train loss: 0.16525\n",
      "Step #91500, epoch #1016, avg. train loss: 0.16342\n",
      "Step #91600, epoch #1017, avg. train loss: 0.16332\n",
      "Step #91700, epoch #1018, avg. train loss: 0.16508\n",
      "Step #91800, epoch #1020, avg. train loss: 0.16455\n",
      "Step #91900, epoch #1021, avg. train loss: 0.16547\n",
      "Step #92000, epoch #1022, avg. train loss: 0.16471\n",
      "Step #92100, epoch #1023, avg. train loss: 0.16288\n",
      "Step #92200, epoch #1024, avg. train loss: 0.16448\n",
      "Step #92300, epoch #1025, avg. train loss: 0.16606\n",
      "Step #92400, epoch #1026, avg. train loss: 0.16413\n",
      "Step #92500, epoch #1027, avg. train loss: 0.16689\n",
      "Step #92600, epoch #1028, avg. train loss: 0.16275\n",
      "Step #92700, epoch #1030, avg. train loss: 0.16598\n",
      "Step #92800, epoch #1031, avg. train loss: 0.16453\n",
      "Step #92900, epoch #1032, avg. train loss: 0.16267\n",
      "Step #93000, epoch #1033, avg. train loss: 0.16561\n",
      "Step #93100, epoch #1034, avg. train loss: 0.16366\n",
      "Step #93200, epoch #1035, avg. train loss: 0.16406\n",
      "Step #93300, epoch #1036, avg. train loss: 0.16427\n",
      "Step #93400, epoch #1037, avg. train loss: 0.16351\n",
      "Step #93500, epoch #1038, avg. train loss: 0.16445\n",
      "Step #93600, epoch #1040, avg. train loss: 0.16325\n",
      "Step #93700, epoch #1041, avg. train loss: 0.16460\n",
      "Step #93800, epoch #1042, avg. train loss: 0.16402\n",
      "Step #93900, epoch #1043, avg. train loss: 0.16453\n",
      "Step #94000, epoch #1044, avg. train loss: 0.16446\n",
      "Step #94100, epoch #1045, avg. train loss: 0.16147\n",
      "Step #94200, epoch #1046, avg. train loss: 0.16620\n",
      "Step #94300, epoch #1047, avg. train loss: 0.16504\n",
      "Step #94400, epoch #1048, avg. train loss: 0.16438\n",
      "Step #94500, epoch #1050, avg. train loss: 0.16207\n",
      "Step #94600, epoch #1051, avg. train loss: 0.16336\n",
      "Step #94700, epoch #1052, avg. train loss: 0.16609\n",
      "Step #94800, epoch #1053, avg. train loss: 0.16183\n",
      "Step #94900, epoch #1054, avg. train loss: 0.16420\n",
      "Step #95000, epoch #1055, avg. train loss: 0.16428\n",
      "Step #95100, epoch #1056, avg. train loss: 0.16476\n",
      "Step #95200, epoch #1057, avg. train loss: 0.16500\n",
      "Step #95300, epoch #1058, avg. train loss: 0.16561\n",
      "Step #95400, epoch #1060, avg. train loss: 0.16496\n",
      "Step #95500, epoch #1061, avg. train loss: 0.16417\n",
      "Step #95600, epoch #1062, avg. train loss: 0.16741\n",
      "Step #95700, epoch #1063, avg. train loss: 0.16259\n",
      "Step #95800, epoch #1064, avg. train loss: 0.16698\n",
      "Step #95900, epoch #1065, avg. train loss: 0.16537\n",
      "Step #96000, epoch #1066, avg. train loss: 0.15994\n",
      "Step #96100, epoch #1067, avg. train loss: 0.16721\n",
      "Step #96200, epoch #1068, avg. train loss: 0.16413\n",
      "Step #96300, epoch #1070, avg. train loss: 0.16761\n",
      "Step #96400, epoch #1071, avg. train loss: 0.16468\n",
      "Step #96500, epoch #1072, avg. train loss: 0.16195\n",
      "Step #96600, epoch #1073, avg. train loss: 0.16656\n",
      "Step #96700, epoch #1074, avg. train loss: 0.16126\n",
      "Step #96800, epoch #1075, avg. train loss: 0.16558\n",
      "Step #96900, epoch #1076, avg. train loss: 0.16434\n",
      "Step #97000, epoch #1077, avg. train loss: 0.16393\n",
      "Step #97100, epoch #1078, avg. train loss: 0.16684\n",
      "Step #97200, epoch #1080, avg. train loss: 0.16290\n",
      "Step #97300, epoch #1081, avg. train loss: 0.16757\n",
      "Step #97400, epoch #1082, avg. train loss: 0.16364\n",
      "Step #97500, epoch #1083, avg. train loss: 0.16162\n",
      "Step #97600, epoch #1084, avg. train loss: 0.16212\n",
      "Step #97700, epoch #1085, avg. train loss: 0.16730\n",
      "Step #97800, epoch #1086, avg. train loss: 0.16579\n",
      "Step #97900, epoch #1087, avg. train loss: 0.16083\n",
      "Step #98000, epoch #1088, avg. train loss: 0.16971\n",
      "Step #98100, epoch #1090, avg. train loss: 0.16437\n",
      "Step #98200, epoch #1091, avg. train loss: 0.16500\n",
      "Step #98300, epoch #1092, avg. train loss: 0.16471\n",
      "Step #98400, epoch #1093, avg. train loss: 0.16497\n",
      "Step #98500, epoch #1094, avg. train loss: 0.16618\n",
      "Step #98600, epoch #1095, avg. train loss: 0.16714\n",
      "Step #98700, epoch #1096, avg. train loss: 0.16447\n",
      "Step #98800, epoch #1097, avg. train loss: 0.16461\n",
      "Step #98900, epoch #1098, avg. train loss: 0.16196\n",
      "Step #99000, epoch #1100, avg. train loss: 0.16564\n",
      "Step #99100, epoch #1101, avg. train loss: 0.16494\n",
      "Step #99200, epoch #1102, avg. train loss: 0.16596\n",
      "Step #99300, epoch #1103, avg. train loss: 0.16461\n",
      "Step #99400, epoch #1104, avg. train loss: 0.16545\n",
      "Step #99500, epoch #1105, avg. train loss: 0.16335\n",
      "Step #99600, epoch #1106, avg. train loss: 0.16388\n",
      "Step #99700, epoch #1107, avg. train loss: 0.16589\n",
      "Step #99800, epoch #1108, avg. train loss: 0.16150\n",
      "Step #99900, epoch #1110, avg. train loss: 0.16443\n",
      "Step #100000, epoch #1111, avg. train loss: 0.16283\n",
      "ROC =  0.5\n",
      "dnn3\n",
      "Step #100, epoch #1, avg. train loss: 131.69965\n",
      "Step #200, epoch #2, avg. train loss: 0.22365\n",
      "Step #300, epoch #3, avg. train loss: 0.17929\n",
      "Step #400, epoch #4, avg. train loss: 0.18967\n",
      "Step #500, epoch #5, avg. train loss: 0.16559\n",
      "Step #600, epoch #6, avg. train loss: 0.17086\n",
      "Step #700, epoch #7, avg. train loss: 0.16695\n",
      "Step #800, epoch #8, avg. train loss: 0.16911\n",
      "Step #900, epoch #10, avg. train loss: 0.26452\n",
      "Step #1000, epoch #11, avg. train loss: 0.21033\n",
      "Step #1100, epoch #12, avg. train loss: 0.16136\n",
      "Step #1200, epoch #13, avg. train loss: 0.16576\n",
      "Step #1300, epoch #14, avg. train loss: 0.16406\n",
      "Step #1400, epoch #15, avg. train loss: 286.01575\n",
      "Step #1500, epoch #16, avg. train loss: 0.17244\n",
      "Step #1600, epoch #17, avg. train loss: 0.16610\n",
      "Step #1700, epoch #18, avg. train loss: 0.16473\n",
      "Step #1800, epoch #20, avg. train loss: 0.16218\n",
      "Step #1900, epoch #21, avg. train loss: 0.16639\n",
      "Step #2000, epoch #22, avg. train loss: 0.16382\n",
      "Step #2100, epoch #23, avg. train loss: 0.16610\n",
      "Step #2200, epoch #24, avg. train loss: 0.16307\n",
      "Step #2300, epoch #25, avg. train loss: 0.16233\n",
      "Step #2400, epoch #26, avg. train loss: 0.16744\n",
      "Step #2500, epoch #27, avg. train loss: 0.16270\n",
      "Step #2600, epoch #28, avg. train loss: 0.16495\n",
      "Step #2700, epoch #30, avg. train loss: 0.16226\n",
      "Step #2800, epoch #31, avg. train loss: 0.16314\n",
      "Step #2900, epoch #32, avg. train loss: 0.16411\n",
      "Step #3000, epoch #33, avg. train loss: 0.16574\n",
      "Step #3100, epoch #34, avg. train loss: 0.16302\n",
      "Step #3200, epoch #35, avg. train loss: 0.16360\n",
      "Step #3300, epoch #36, avg. train loss: 0.16452\n",
      "Step #3400, epoch #37, avg. train loss: 0.16249\n",
      "Step #3500, epoch #38, avg. train loss: 0.16450\n",
      "Step #3600, epoch #40, avg. train loss: 0.16465\n",
      "Step #3700, epoch #41, avg. train loss: 0.16451\n",
      "Step #3800, epoch #42, avg. train loss: 0.16176\n",
      "Step #3900, epoch #43, avg. train loss: 0.16592\n",
      "Step #4000, epoch #44, avg. train loss: 0.16263\n",
      "Step #4100, epoch #45, avg. train loss: 0.16819\n",
      "Step #4200, epoch #46, avg. train loss: 0.16188\n",
      "Step #4300, epoch #47, avg. train loss: 0.16288\n",
      "Step #4400, epoch #48, avg. train loss: 0.16669\n",
      "Step #4500, epoch #50, avg. train loss: 0.16409\n",
      "Step #4600, epoch #51, avg. train loss: 0.16484\n",
      "Step #4700, epoch #52, avg. train loss: 0.16299\n",
      "Step #4800, epoch #53, avg. train loss: 0.16289\n",
      "Step #4900, epoch #54, avg. train loss: 0.16538\n",
      "Step #5000, epoch #55, avg. train loss: 0.16509\n",
      "Step #5100, epoch #56, avg. train loss: 0.16140\n",
      "Step #5200, epoch #57, avg. train loss: 0.16739\n",
      "Step #5300, epoch #58, avg. train loss: 0.16364\n",
      "Step #5400, epoch #60, avg. train loss: 0.16367\n",
      "Step #5500, epoch #61, avg. train loss: 0.16557\n",
      "Step #5600, epoch #62, avg. train loss: 0.16266\n",
      "Step #5700, epoch #63, avg. train loss: 0.16542\n",
      "Step #5800, epoch #64, avg. train loss: 0.16461\n",
      "Step #5900, epoch #65, avg. train loss: 0.16296\n",
      "Step #6000, epoch #66, avg. train loss: 0.16673\n",
      "Step #6100, epoch #67, avg. train loss: 0.16379\n",
      "Step #6200, epoch #68, avg. train loss: 0.16341\n",
      "Step #6300, epoch #70, avg. train loss: 0.16350\n",
      "Step #6400, epoch #71, avg. train loss: 0.16278\n",
      "Step #6500, epoch #72, avg. train loss: 0.16608\n",
      "Step #6600, epoch #73, avg. train loss: 0.16475\n",
      "Step #6700, epoch #74, avg. train loss: 0.16607\n",
      "Step #6800, epoch #75, avg. train loss: 0.16428\n",
      "Step #6900, epoch #76, avg. train loss: 0.16400\n",
      "Step #7000, epoch #77, avg. train loss: 0.16158\n",
      "Step #7100, epoch #78, avg. train loss: 0.16718\n",
      "Step #7200, epoch #80, avg. train loss: 0.16405\n",
      "Step #7300, epoch #81, avg. train loss: 0.16479\n",
      "Step #7400, epoch #82, avg. train loss: 0.16600\n",
      "Step #7500, epoch #83, avg. train loss: 0.16429\n",
      "Step #7600, epoch #84, avg. train loss: 0.16633\n",
      "Step #7700, epoch #85, avg. train loss: 0.16373\n",
      "Step #7800, epoch #86, avg. train loss: 0.16408\n",
      "Step #7900, epoch #87, avg. train loss: 0.16275\n",
      "Step #8000, epoch #88, avg. train loss: 0.16524\n",
      "Step #8100, epoch #90, avg. train loss: 0.16222\n",
      "Step #8200, epoch #91, avg. train loss: 0.16460\n",
      "Step #8300, epoch #92, avg. train loss: 0.16642\n",
      "Step #8400, epoch #93, avg. train loss: 0.16084\n",
      "Step #8500, epoch #94, avg. train loss: 0.16429\n",
      "Step #8600, epoch #95, avg. train loss: 0.16529\n",
      "Step #8700, epoch #96, avg. train loss: 0.16515\n",
      "Step #8800, epoch #97, avg. train loss: 0.16582\n",
      "Step #8900, epoch #98, avg. train loss: 0.16246\n",
      "Step #9000, epoch #100, avg. train loss: 0.16458\n",
      "Step #9100, epoch #101, avg. train loss: 0.16373\n",
      "Step #9200, epoch #102, avg. train loss: 0.16603\n",
      "Step #9300, epoch #103, avg. train loss: 0.16162\n",
      "Step #9400, epoch #104, avg. train loss: 0.16565\n",
      "Step #9500, epoch #105, avg. train loss: 0.16293\n",
      "Step #9600, epoch #106, avg. train loss: 0.16717\n",
      "Step #9700, epoch #107, avg. train loss: 0.16331\n",
      "Step #9800, epoch #108, avg. train loss: 0.16706\n",
      "Step #9900, epoch #110, avg. train loss: 0.16249\n",
      "Step #10000, epoch #111, avg. train loss: 0.16477\n",
      "Step #10100, epoch #112, avg. train loss: 0.16663\n",
      "Step #10200, epoch #113, avg. train loss: 0.16495\n",
      "Step #10300, epoch #114, avg. train loss: 0.16077\n",
      "Step #10400, epoch #115, avg. train loss: 0.16869\n",
      "Step #10500, epoch #116, avg. train loss: 0.16383\n",
      "Step #10600, epoch #117, avg. train loss: 0.16259\n",
      "Step #10700, epoch #118, avg. train loss: 0.16515\n",
      "Step #10800, epoch #120, avg. train loss: 0.16548\n",
      "Step #10900, epoch #121, avg. train loss: 0.16450\n",
      "Step #11000, epoch #122, avg. train loss: 0.16317\n",
      "Step #11100, epoch #123, avg. train loss: 0.16522\n",
      "Step #11200, epoch #124, avg. train loss: 0.16506\n",
      "Step #11300, epoch #125, avg. train loss: 0.16499\n",
      "Step #11400, epoch #126, avg. train loss: 0.16145\n",
      "Step #11500, epoch #127, avg. train loss: 0.16520\n",
      "Step #11600, epoch #128, avg. train loss: 0.16309\n",
      "Step #11700, epoch #130, avg. train loss: 0.16678\n",
      "Step #11800, epoch #131, avg. train loss: 0.16552\n",
      "Step #11900, epoch #132, avg. train loss: 0.16317\n",
      "Step #12000, epoch #133, avg. train loss: 0.16249\n",
      "Step #12100, epoch #134, avg. train loss: 0.16639\n",
      "Step #12200, epoch #135, avg. train loss: 0.16229\n",
      "Step #12300, epoch #136, avg. train loss: 0.16609\n",
      "Step #12400, epoch #137, avg. train loss: 0.16237\n",
      "Step #12500, epoch #138, avg. train loss: 0.16894\n",
      "Step #12600, epoch #140, avg. train loss: 0.16536\n",
      "Step #12700, epoch #141, avg. train loss: 0.16491\n",
      "Step #12800, epoch #142, avg. train loss: 0.16390\n",
      "Step #12900, epoch #143, avg. train loss: 0.16365\n",
      "Step #13000, epoch #144, avg. train loss: 0.16445\n",
      "Step #13100, epoch #145, avg. train loss: 0.16126\n",
      "Step #13200, epoch #146, avg. train loss: 0.16855\n",
      "Step #13300, epoch #147, avg. train loss: 0.16641\n",
      "Step #13400, epoch #148, avg. train loss: 0.16226\n",
      "Step #13500, epoch #150, avg. train loss: 0.16479\n",
      "Step #13600, epoch #151, avg. train loss: 0.16611\n",
      "Step #13700, epoch #152, avg. train loss: 0.16446\n",
      "Step #13800, epoch #153, avg. train loss: 0.16381\n",
      "Step #13900, epoch #154, avg. train loss: 0.16340\n",
      "Step #14000, epoch #155, avg. train loss: 0.16481\n",
      "Step #14100, epoch #156, avg. train loss: 0.16443\n",
      "Step #14200, epoch #157, avg. train loss: 0.16665\n",
      "Step #14300, epoch #158, avg. train loss: 0.16226\n",
      "Step #14400, epoch #160, avg. train loss: 0.16353\n",
      "Step #14500, epoch #161, avg. train loss: 0.16507\n",
      "Step #14600, epoch #162, avg. train loss: 0.16448\n",
      "Step #14700, epoch #163, avg. train loss: 0.16189\n",
      "Step #14800, epoch #164, avg. train loss: 0.40619\n",
      "Step #14900, epoch #165, avg. train loss: 0.16391\n",
      "Step #15000, epoch #166, avg. train loss: 0.19141\n",
      "Step #15100, epoch #167, avg. train loss: 0.16143\n",
      "Step #15200, epoch #168, avg. train loss: 0.16363\n",
      "Step #15300, epoch #170, avg. train loss: 0.16489\n",
      "Step #15400, epoch #171, avg. train loss: 0.16406\n",
      "Step #15500, epoch #172, avg. train loss: 0.16422\n",
      "Step #15600, epoch #173, avg. train loss: 0.16703\n",
      "Step #15700, epoch #174, avg. train loss: 0.16454\n",
      "Step #15800, epoch #175, avg. train loss: 0.16105\n",
      "Step #15900, epoch #176, avg. train loss: 0.16572\n",
      "Step #16000, epoch #177, avg. train loss: 0.16412\n",
      "Step #16100, epoch #178, avg. train loss: 0.16563\n",
      "Step #16200, epoch #180, avg. train loss: 0.16445\n",
      "Step #16300, epoch #181, avg. train loss: 0.16430\n",
      "Step #16400, epoch #182, avg. train loss: 0.16545\n",
      "Step #16500, epoch #183, avg. train loss: 0.16335\n",
      "Step #16600, epoch #184, avg. train loss: 0.16156\n",
      "Step #16700, epoch #185, avg. train loss: 0.16777\n",
      "Step #16800, epoch #186, avg. train loss: 0.16320\n",
      "Step #16900, epoch #187, avg. train loss: 0.16521\n",
      "Step #17000, epoch #188, avg. train loss: 0.16478\n",
      "Step #17100, epoch #190, avg. train loss: 0.16374\n",
      "Step #17200, epoch #191, avg. train loss: 0.16427\n",
      "Step #17300, epoch #192, avg. train loss: 0.16521\n",
      "Step #17400, epoch #193, avg. train loss: 0.16452\n",
      "Step #17500, epoch #194, avg. train loss: 0.16211\n",
      "Step #17600, epoch #195, avg. train loss: 0.16755\n",
      "Step #17700, epoch #196, avg. train loss: 0.16454\n",
      "Step #17800, epoch #197, avg. train loss: 0.16171\n",
      "Step #17900, epoch #198, avg. train loss: 0.16473\n",
      "Step #18000, epoch #200, avg. train loss: 0.16399\n",
      "Step #18100, epoch #201, avg. train loss: 0.16355\n",
      "Step #18200, epoch #202, avg. train loss: 0.16671\n",
      "Step #18300, epoch #203, avg. train loss: 0.16639\n",
      "Step #18400, epoch #204, avg. train loss: 0.16102\n",
      "Step #18500, epoch #205, avg. train loss: 0.16203\n",
      "Step #18600, epoch #206, avg. train loss: 0.16948\n",
      "Step #18700, epoch #207, avg. train loss: 0.16390\n",
      "Step #18800, epoch #208, avg. train loss: 0.16477\n",
      "Step #18900, epoch #210, avg. train loss: 0.16289\n",
      "Step #19000, epoch #211, avg. train loss: 0.16436\n",
      "Step #19100, epoch #212, avg. train loss: 0.16422\n",
      "Step #19200, epoch #213, avg. train loss: 0.16481\n",
      "Step #19300, epoch #214, avg. train loss: 0.16218\n",
      "Step #19400, epoch #215, avg. train loss: 0.16569\n",
      "Step #19500, epoch #216, avg. train loss: 0.16531\n",
      "Step #19600, epoch #217, avg. train loss: 0.16501\n",
      "Step #19700, epoch #218, avg. train loss: 0.16283\n",
      "Step #19800, epoch #220, avg. train loss: 0.16296\n",
      "Step #19900, epoch #221, avg. train loss: 0.16479\n",
      "Step #20000, epoch #222, avg. train loss: 0.16629\n",
      "Step #20100, epoch #223, avg. train loss: 0.16432\n",
      "Step #20200, epoch #224, avg. train loss: 0.16245\n",
      "Step #20300, epoch #225, avg. train loss: 0.16576\n",
      "Step #20400, epoch #226, avg. train loss: 0.16340\n",
      "Step #20500, epoch #227, avg. train loss: 0.16586\n",
      "Step #20600, epoch #228, avg. train loss: 0.16555\n",
      "Step #20700, epoch #230, avg. train loss: 0.16502\n",
      "Step #20800, epoch #231, avg. train loss: 0.16350\n",
      "Step #20900, epoch #232, avg. train loss: 0.16476\n",
      "Step #21000, epoch #233, avg. train loss: 0.16522\n",
      "Step #21100, epoch #234, avg. train loss: 0.16116\n",
      "Step #21200, epoch #235, avg. train loss: 0.16510\n",
      "Step #21300, epoch #236, avg. train loss: 0.16318\n",
      "Step #21400, epoch #237, avg. train loss: 0.16627\n",
      "Step #21500, epoch #238, avg. train loss: 0.16285\n",
      "Step #21600, epoch #240, avg. train loss: 0.16465\n",
      "Step #21700, epoch #241, avg. train loss: 0.16199\n",
      "Step #21800, epoch #242, avg. train loss: 0.16377\n",
      "Step #21900, epoch #243, avg. train loss: 0.16717\n",
      "Step #22000, epoch #244, avg. train loss: 0.16476\n",
      "Step #22100, epoch #245, avg. train loss: 0.16549\n",
      "Step #22200, epoch #246, avg. train loss: 0.16263\n",
      "Step #22300, epoch #247, avg. train loss: 0.16569\n",
      "Step #22400, epoch #248, avg. train loss: 0.16498\n",
      "Step #22500, epoch #250, avg. train loss: 0.16297\n",
      "Step #22600, epoch #251, avg. train loss: 0.16310\n",
      "Step #22700, epoch #252, avg. train loss: 0.16628\n",
      "Step #22800, epoch #253, avg. train loss: 0.16559\n",
      "Step #22900, epoch #254, avg. train loss: 0.16520\n",
      "Step #23000, epoch #255, avg. train loss: 0.16384\n",
      "Step #23100, epoch #256, avg. train loss: 0.16329\n",
      "Step #23200, epoch #257, avg. train loss: 0.16616\n",
      "Step #23300, epoch #258, avg. train loss: 0.16370\n",
      "Step #23400, epoch #260, avg. train loss: 0.16286\n",
      "Step #23500, epoch #261, avg. train loss: 0.16495\n",
      "Step #23600, epoch #262, avg. train loss: 0.16466\n",
      "Step #23700, epoch #263, avg. train loss: 0.16138\n",
      "Step #23800, epoch #264, avg. train loss: 0.16879\n",
      "Step #23900, epoch #265, avg. train loss: 0.16317\n",
      "Step #24000, epoch #266, avg. train loss: 0.16261\n",
      "Step #24100, epoch #267, avg. train loss: 0.16553\n",
      "Step #24200, epoch #268, avg. train loss: 0.16374\n",
      "Step #24300, epoch #270, avg. train loss: 0.16457\n",
      "Step #24400, epoch #271, avg. train loss: 0.16335\n",
      "Step #24500, epoch #272, avg. train loss: 0.16441\n",
      "Step #24600, epoch #273, avg. train loss: 0.16520\n",
      "Step #24700, epoch #274, avg. train loss: 0.16013\n",
      "Step #24800, epoch #275, avg. train loss: 0.16945\n",
      "Step #24900, epoch #276, avg. train loss: 0.16321\n",
      "Step #25000, epoch #277, avg. train loss: 0.16541\n",
      "Step #25100, epoch #278, avg. train loss: 0.16552\n",
      "Step #25200, epoch #280, avg. train loss: 0.16405\n",
      "Step #25300, epoch #281, avg. train loss: 0.16467\n",
      "Step #25400, epoch #282, avg. train loss: 0.16245\n",
      "Step #25500, epoch #283, avg. train loss: 0.16792\n",
      "Step #25600, epoch #284, avg. train loss: 0.16243\n",
      "Step #25700, epoch #285, avg. train loss: 0.16396\n",
      "Step #25800, epoch #286, avg. train loss: 0.16639\n",
      "Step #25900, epoch #287, avg. train loss: 0.16367\n",
      "Step #26000, epoch #288, avg. train loss: 0.16370\n",
      "Step #26100, epoch #290, avg. train loss: 0.16399\n",
      "Step #26200, epoch #291, avg. train loss: 0.16562\n",
      "Step #26300, epoch #292, avg. train loss: 0.16303\n",
      "Step #26400, epoch #293, avg. train loss: 0.16404\n",
      "Step #26500, epoch #294, avg. train loss: 0.16476\n",
      "Step #26600, epoch #295, avg. train loss: 0.16330\n",
      "Step #26700, epoch #296, avg. train loss: 0.16499\n",
      "Step #26800, epoch #297, avg. train loss: 0.16632\n",
      "Step #26900, epoch #298, avg. train loss: 0.16327\n",
      "Step #27000, epoch #300, avg. train loss: 0.16336\n",
      "Step #27100, epoch #301, avg. train loss: 0.16476\n",
      "Step #27200, epoch #302, avg. train loss: 0.16278\n",
      "Step #27300, epoch #303, avg. train loss: 0.16424\n",
      "Step #27400, epoch #304, avg. train loss: 0.16768\n",
      "Step #27500, epoch #305, avg. train loss: 0.16327\n",
      "Step #27600, epoch #306, avg. train loss: 0.16607\n",
      "Step #27700, epoch #307, avg. train loss: 0.16254\n",
      "Step #27800, epoch #308, avg. train loss: 0.16328\n",
      "Step #27900, epoch #310, avg. train loss: 0.16462\n",
      "Step #28000, epoch #311, avg. train loss: 0.16401\n",
      "Step #28100, epoch #312, avg. train loss: 0.16266\n",
      "Step #28200, epoch #313, avg. train loss: 0.16583\n",
      "Step #28300, epoch #314, avg. train loss: 0.16329\n",
      "Step #28400, epoch #315, avg. train loss: 0.16658\n",
      "Step #28500, epoch #316, avg. train loss: 0.16661\n",
      "Step #28600, epoch #317, avg. train loss: 0.16421\n",
      "Step #28700, epoch #318, avg. train loss: 0.16677\n",
      "Step #28800, epoch #320, avg. train loss: 0.16472\n",
      "Step #28900, epoch #321, avg. train loss: 0.16508\n",
      "Step #29000, epoch #322, avg. train loss: 0.16273\n",
      "Step #29100, epoch #323, avg. train loss: 0.16689\n",
      "Step #29200, epoch #324, avg. train loss: 0.16566\n",
      "Step #29300, epoch #325, avg. train loss: 0.16478\n",
      "Step #29400, epoch #326, avg. train loss: 0.16769\n",
      "Step #29500, epoch #327, avg. train loss: 0.16266\n",
      "Step #29600, epoch #328, avg. train loss: 0.16380\n",
      "Step #29700, epoch #330, avg. train loss: 0.16815\n",
      "Step #29800, epoch #331, avg. train loss: 0.16422\n",
      "Step #29900, epoch #332, avg. train loss: 0.16534\n",
      "Step #30000, epoch #333, avg. train loss: 0.16125\n",
      "Step #30100, epoch #334, avg. train loss: 0.16617\n",
      "Step #30200, epoch #335, avg. train loss: 0.16514\n",
      "Step #30300, epoch #336, avg. train loss: 0.16321\n",
      "Step #30400, epoch #337, avg. train loss: 0.16517\n",
      "Step #30500, epoch #338, avg. train loss: 0.16250\n",
      "Step #30600, epoch #340, avg. train loss: 0.16569\n",
      "Step #30700, epoch #341, avg. train loss: 0.16477\n",
      "Step #30800, epoch #342, avg. train loss: 0.16299\n",
      "Step #30900, epoch #343, avg. train loss: 0.16450\n",
      "Step #31000, epoch #344, avg. train loss: 0.16472\n",
      "Step #31100, epoch #345, avg. train loss: 0.16573\n",
      "Step #31200, epoch #346, avg. train loss: 0.16558\n",
      "Step #31300, epoch #347, avg. train loss: 0.16198\n",
      "Step #31400, epoch #348, avg. train loss: 0.16410\n",
      "Step #31500, epoch #350, avg. train loss: 0.16501\n",
      "Step #31600, epoch #351, avg. train loss: 0.16572\n",
      "Step #31700, epoch #352, avg. train loss: 0.16349\n",
      "Step #31800, epoch #353, avg. train loss: 0.16479\n",
      "Step #31900, epoch #354, avg. train loss: 0.16412\n",
      "Step #32000, epoch #355, avg. train loss: 0.16809\n",
      "Step #32100, epoch #356, avg. train loss: 0.16296\n",
      "Step #32200, epoch #357, avg. train loss: 0.16685\n",
      "Step #32300, epoch #358, avg. train loss: 0.16479\n",
      "Step #32400, epoch #360, avg. train loss: 0.16494\n",
      "Step #32500, epoch #361, avg. train loss: 0.16439\n",
      "Step #32600, epoch #362, avg. train loss: 0.16341\n",
      "Step #32700, epoch #363, avg. train loss: 0.16373\n",
      "Step #32800, epoch #364, avg. train loss: 0.16544\n",
      "Step #32900, epoch #365, avg. train loss: 0.16450\n",
      "Step #33000, epoch #366, avg. train loss: 0.16664\n",
      "Step #33100, epoch #367, avg. train loss: 0.16248\n",
      "Step #33200, epoch #368, avg. train loss: 0.16637\n",
      "Step #33300, epoch #370, avg. train loss: 0.16373\n",
      "Step #33400, epoch #371, avg. train loss: 0.16312\n",
      "Step #33500, epoch #372, avg. train loss: 0.16389\n",
      "Step #33600, epoch #373, avg. train loss: 0.16547\n",
      "Step #33700, epoch #374, avg. train loss: 0.16170\n",
      "Step #33800, epoch #375, avg. train loss: 0.16799\n",
      "Step #33900, epoch #376, avg. train loss: 0.16455\n",
      "Step #34000, epoch #377, avg. train loss: 0.16313\n",
      "Step #34100, epoch #378, avg. train loss: 0.16739\n",
      "Step #34200, epoch #380, avg. train loss: 0.16214\n",
      "Step #34300, epoch #381, avg. train loss: 0.16581\n",
      "Step #34400, epoch #382, avg. train loss: 0.16301\n",
      "Step #34500, epoch #383, avg. train loss: 0.16589\n",
      "Step #34600, epoch #384, avg. train loss: 0.16462\n",
      "Step #34700, epoch #385, avg. train loss: 0.15941\n",
      "Step #34800, epoch #386, avg. train loss: 0.16598\n",
      "Step #34900, epoch #387, avg. train loss: 0.16487\n",
      "Step #35000, epoch #388, avg. train loss: 0.16343\n",
      "Step #35100, epoch #390, avg. train loss: 0.16309\n",
      "Step #35200, epoch #391, avg. train loss: 0.16460\n",
      "Step #35300, epoch #392, avg. train loss: 0.16221\n",
      "Step #35400, epoch #393, avg. train loss: 0.16805\n",
      "Step #35500, epoch #394, avg. train loss: 0.16523\n",
      "Step #35600, epoch #395, avg. train loss: 0.16023\n",
      "Step #35700, epoch #396, avg. train loss: 0.16663\n",
      "Step #35800, epoch #397, avg. train loss: 0.16015\n",
      "Step #35900, epoch #398, avg. train loss: 0.16810\n",
      "Step #36000, epoch #400, avg. train loss: 0.16409\n",
      "Step #36100, epoch #401, avg. train loss: 0.16540\n",
      "Step #36200, epoch #402, avg. train loss: 0.16613\n",
      "Step #36300, epoch #403, avg. train loss: 0.16478\n",
      "Step #36400, epoch #404, avg. train loss: 0.16522\n",
      "Step #36500, epoch #405, avg. train loss: 0.16732\n",
      "Step #36600, epoch #406, avg. train loss: 0.16049\n",
      "Step #36700, epoch #407, avg. train loss: 0.16673\n",
      "Step #36800, epoch #408, avg. train loss: 0.16535\n",
      "Step #36900, epoch #410, avg. train loss: 0.16276\n",
      "Step #37000, epoch #411, avg. train loss: 0.16598\n",
      "Step #37100, epoch #412, avg. train loss: 0.16345\n",
      "Step #37200, epoch #413, avg. train loss: 0.16303\n",
      "Step #37300, epoch #414, avg. train loss: 0.16563\n",
      "Step #37400, epoch #415, avg. train loss: 0.15991\n",
      "Step #37500, epoch #416, avg. train loss: 0.16744\n",
      "Step #37600, epoch #417, avg. train loss: 0.16439\n",
      "Step #37700, epoch #418, avg. train loss: 0.16328\n",
      "Step #37800, epoch #420, avg. train loss: 0.16425\n",
      "Step #37900, epoch #421, avg. train loss: 0.16491\n",
      "Step #38000, epoch #422, avg. train loss: 0.16417\n",
      "Step #38100, epoch #423, avg. train loss: 0.16206\n",
      "Step #38200, epoch #424, avg. train loss: 0.16427\n",
      "Step #38300, epoch #425, avg. train loss: 0.16734\n",
      "Step #38400, epoch #426, avg. train loss: 0.16413\n",
      "Step #38500, epoch #427, avg. train loss: 0.16240\n",
      "Step #38600, epoch #428, avg. train loss: 0.16488\n",
      "Step #38700, epoch #430, avg. train loss: 0.16651\n",
      "Step #38800, epoch #431, avg. train loss: 0.16629\n",
      "Step #38900, epoch #432, avg. train loss: 0.16038\n",
      "Step #39000, epoch #433, avg. train loss: 0.16315\n",
      "Step #39100, epoch #434, avg. train loss: 0.16663\n",
      "Step #39200, epoch #435, avg. train loss: 0.16848\n",
      "Step #39300, epoch #436, avg. train loss: 0.16371\n",
      "Step #39400, epoch #437, avg. train loss: 0.16544\n",
      "Step #39500, epoch #438, avg. train loss: 0.16284\n",
      "Step #39600, epoch #440, avg. train loss: 0.16319\n",
      "Step #39700, epoch #441, avg. train loss: 0.16440\n",
      "Step #39800, epoch #442, avg. train loss: 0.16522\n",
      "Step #39900, epoch #443, avg. train loss: 0.16955\n",
      "Step #40000, epoch #444, avg. train loss: 0.16796\n",
      "Step #40100, epoch #445, avg. train loss: 0.16262\n",
      "Step #40200, epoch #446, avg. train loss: 0.16471\n",
      "Step #40300, epoch #447, avg. train loss: 0.16404\n",
      "Step #40400, epoch #448, avg. train loss: 0.16631\n",
      "Step #40500, epoch #450, avg. train loss: 0.16526\n",
      "Step #40600, epoch #451, avg. train loss: 0.16635\n",
      "Step #40700, epoch #452, avg. train loss: 0.16015\n",
      "Step #40800, epoch #453, avg. train loss: 0.16683\n",
      "Step #40900, epoch #454, avg. train loss: 0.16055\n",
      "Step #41000, epoch #455, avg. train loss: 0.16584\n",
      "Step #41100, epoch #456, avg. train loss: 0.17551\n",
      "Step #41200, epoch #457, avg. train loss: 0.16313\n",
      "Step #41300, epoch #458, avg. train loss: 0.16866\n",
      "Step #41400, epoch #460, avg. train loss: 0.16407\n",
      "Step #41500, epoch #461, avg. train loss: 0.16451\n",
      "Step #41600, epoch #462, avg. train loss: 0.16450\n",
      "Step #41700, epoch #463, avg. train loss: 0.16358\n",
      "Step #41800, epoch #464, avg. train loss: 0.16270\n",
      "Step #41900, epoch #465, avg. train loss: 0.16504\n",
      "Step #42000, epoch #466, avg. train loss: 0.16299\n",
      "Step #42100, epoch #467, avg. train loss: 0.16744\n",
      "Step #42200, epoch #468, avg. train loss: 0.16584\n",
      "Step #42300, epoch #470, avg. train loss: 0.16206\n",
      "Step #42400, epoch #471, avg. train loss: 0.16516\n",
      "Step #42500, epoch #472, avg. train loss: 0.16543\n",
      "Step #42600, epoch #473, avg. train loss: 0.16462\n",
      "Step #42700, epoch #474, avg. train loss: 0.16386\n",
      "Step #42800, epoch #475, avg. train loss: 0.16245\n",
      "Step #42900, epoch #476, avg. train loss: 0.16473\n",
      "Step #43000, epoch #477, avg. train loss: 0.16586\n",
      "Step #43100, epoch #478, avg. train loss: 0.16265\n",
      "Step #43200, epoch #480, avg. train loss: 0.16659\n",
      "Step #43300, epoch #481, avg. train loss: 0.16436\n",
      "Step #43400, epoch #482, avg. train loss: 0.16888\n",
      "Step #43500, epoch #483, avg. train loss: 0.16189\n",
      "Step #43600, epoch #484, avg. train loss: 0.16408\n",
      "Step #43700, epoch #485, avg. train loss: 0.16660\n",
      "Step #43800, epoch #486, avg. train loss: 0.16207\n",
      "Step #43900, epoch #487, avg. train loss: 0.16503\n",
      "Step #44000, epoch #488, avg. train loss: 0.16494\n",
      "Step #44100, epoch #490, avg. train loss: 0.16299\n",
      "Step #44200, epoch #491, avg. train loss: 0.16416\n",
      "Step #44300, epoch #492, avg. train loss: 0.16221\n",
      "Step #44400, epoch #493, avg. train loss: 0.16736\n",
      "Step #44500, epoch #494, avg. train loss: 0.16337\n",
      "Step #44600, epoch #495, avg. train loss: 0.16503\n",
      "Step #44700, epoch #496, avg. train loss: 0.16550\n",
      "Step #44800, epoch #497, avg. train loss: 0.16725\n",
      "Step #44900, epoch #498, avg. train loss: 0.16337\n",
      "Step #45000, epoch #500, avg. train loss: 0.16250\n",
      "Step #45100, epoch #501, avg. train loss: 0.16468\n",
      "Step #45200, epoch #502, avg. train loss: 0.16401\n",
      "Step #45300, epoch #503, avg. train loss: 0.16645\n",
      "Step #45400, epoch #504, avg. train loss: 0.16204\n",
      "Step #45500, epoch #505, avg. train loss: 0.16375\n",
      "Step #45600, epoch #506, avg. train loss: 0.16526\n",
      "Step #45700, epoch #507, avg. train loss: 0.16306\n",
      "Step #45800, epoch #508, avg. train loss: 0.16249\n",
      "Step #45900, epoch #510, avg. train loss: 0.16824\n",
      "Step #46000, epoch #511, avg. train loss: 0.16336\n",
      "Step #46100, epoch #512, avg. train loss: 0.16628\n",
      "Step #46200, epoch #513, avg. train loss: 0.16337\n",
      "Step #46300, epoch #514, avg. train loss: 0.16369\n",
      "Step #46400, epoch #515, avg. train loss: 0.16511\n",
      "Step #46500, epoch #516, avg. train loss: 0.16731\n",
      "Step #46600, epoch #517, avg. train loss: 0.16232\n",
      "Step #46700, epoch #518, avg. train loss: 0.16258\n",
      "Step #46800, epoch #520, avg. train loss: 0.16542\n",
      "Step #46900, epoch #521, avg. train loss: 0.16300\n",
      "Step #47000, epoch #522, avg. train loss: 0.16408\n",
      "Step #47100, epoch #523, avg. train loss: 0.16529\n",
      "Step #47200, epoch #524, avg. train loss: 0.16454\n",
      "Step #47300, epoch #525, avg. train loss: 0.16526\n",
      "Step #47400, epoch #526, avg. train loss: 0.16556\n",
      "Step #47500, epoch #527, avg. train loss: 0.16248\n",
      "Step #47600, epoch #528, avg. train loss: 0.16338\n",
      "Step #47700, epoch #530, avg. train loss: 0.16785\n",
      "Step #47800, epoch #531, avg. train loss: 0.16513\n",
      "Step #47900, epoch #532, avg. train loss: 0.16244\n",
      "Step #48000, epoch #533, avg. train loss: 0.16690\n",
      "Step #48100, epoch #534, avg. train loss: 0.16409\n",
      "Step #48200, epoch #535, avg. train loss: 0.16389\n",
      "Step #48300, epoch #536, avg. train loss: 0.16710\n",
      "Step #48400, epoch #537, avg. train loss: 0.16287\n",
      "Step #48500, epoch #538, avg. train loss: 0.16594\n",
      "Step #48600, epoch #540, avg. train loss: 0.16366\n",
      "Step #48700, epoch #541, avg. train loss: 0.16404\n",
      "Step #48800, epoch #542, avg. train loss: 0.16320\n",
      "Step #48900, epoch #543, avg. train loss: 0.16424\n",
      "Step #49000, epoch #544, avg. train loss: 0.16429\n",
      "Step #49100, epoch #545, avg. train loss: 0.16514\n",
      "Step #49200, epoch #546, avg. train loss: 0.16525\n",
      "Step #49300, epoch #547, avg. train loss: 0.16461\n",
      "Step #49400, epoch #548, avg. train loss: 0.16615\n",
      "Step #49500, epoch #550, avg. train loss: 0.16374\n",
      "Step #49600, epoch #551, avg. train loss: 0.16449\n",
      "Step #49700, epoch #552, avg. train loss: 0.16406\n",
      "Step #49800, epoch #553, avg. train loss: 0.16876\n",
      "Step #49900, epoch #554, avg. train loss: 0.15931\n",
      "Step #50000, epoch #555, avg. train loss: 0.16559\n",
      "Step #50100, epoch #556, avg. train loss: 0.16580\n",
      "Step #50200, epoch #557, avg. train loss: 0.16469\n",
      "Step #50300, epoch #558, avg. train loss: 0.16288\n",
      "Step #50400, epoch #560, avg. train loss: 0.16375\n",
      "Step #50500, epoch #561, avg. train loss: 0.16361\n",
      "Step #50600, epoch #562, avg. train loss: 0.16487\n",
      "Step #50700, epoch #563, avg. train loss: 0.16514\n",
      "Step #50800, epoch #564, avg. train loss: 0.16159\n",
      "Step #50900, epoch #565, avg. train loss: 0.16519\n",
      "Step #51000, epoch #566, avg. train loss: 0.16567\n",
      "Step #51100, epoch #567, avg. train loss: 0.16359\n",
      "Step #51200, epoch #568, avg. train loss: 0.16497\n",
      "Step #51300, epoch #570, avg. train loss: 0.16222\n",
      "Step #51400, epoch #571, avg. train loss: 0.16486\n",
      "Step #51500, epoch #572, avg. train loss: 0.16306\n",
      "Step #51600, epoch #573, avg. train loss: 0.16427\n",
      "Step #51700, epoch #574, avg. train loss: 0.16539\n",
      "Step #51800, epoch #575, avg. train loss: 0.16397\n",
      "Step #51900, epoch #576, avg. train loss: 0.16171\n",
      "Step #52000, epoch #577, avg. train loss: 0.16670\n",
      "Step #52100, epoch #578, avg. train loss: 0.16448\n",
      "Step #52200, epoch #580, avg. train loss: 0.16700\n",
      "Step #52300, epoch #581, avg. train loss: 0.16569\n",
      "Step #52400, epoch #582, avg. train loss: 0.16586\n",
      "Step #52500, epoch #583, avg. train loss: 0.16514\n",
      "Step #52600, epoch #584, avg. train loss: 0.16311\n",
      "Step #52700, epoch #585, avg. train loss: 0.16562\n",
      "Step #52800, epoch #586, avg. train loss: 0.16193\n",
      "Step #52900, epoch #587, avg. train loss: 0.16682\n",
      "Step #53000, epoch #588, avg. train loss: 0.16736\n",
      "Step #53100, epoch #590, avg. train loss: 0.16525\n",
      "Step #53200, epoch #591, avg. train loss: 0.16450\n",
      "Step #53300, epoch #592, avg. train loss: 0.16375\n",
      "Step #53400, epoch #593, avg. train loss: 0.16517\n",
      "Step #53500, epoch #594, avg. train loss: 0.16605\n",
      "Step #53600, epoch #595, avg. train loss: 0.16271\n",
      "Step #53700, epoch #596, avg. train loss: 0.16172\n",
      "Step #53800, epoch #597, avg. train loss: 0.16580\n",
      "Step #53900, epoch #598, avg. train loss: 0.16140\n",
      "Step #54000, epoch #600, avg. train loss: 0.16429\n",
      "Step #54100, epoch #601, avg. train loss: 0.16555\n",
      "Step #54200, epoch #602, avg. train loss: 0.16440\n",
      "Step #54300, epoch #603, avg. train loss: 0.16632\n",
      "Step #54400, epoch #604, avg. train loss: 0.16208\n",
      "Step #54500, epoch #605, avg. train loss: 0.16479\n",
      "Step #54600, epoch #606, avg. train loss: 0.16403\n",
      "Step #54700, epoch #607, avg. train loss: 0.16463\n",
      "Step #54800, epoch #608, avg. train loss: 0.16262\n",
      "Step #54900, epoch #610, avg. train loss: 0.16431\n",
      "Step #55000, epoch #611, avg. train loss: 0.16394\n",
      "Step #55100, epoch #612, avg. train loss: 0.16353\n",
      "Step #55200, epoch #613, avg. train loss: 0.16193\n",
      "Step #55300, epoch #614, avg. train loss: 0.16653\n",
      "Step #55400, epoch #615, avg. train loss: 0.16396\n",
      "Step #55500, epoch #616, avg. train loss: 0.16442\n",
      "Step #55600, epoch #617, avg. train loss: 0.16513\n",
      "Step #55700, epoch #618, avg. train loss: 0.16275\n",
      "Step #55800, epoch #620, avg. train loss: 0.16455\n",
      "Step #55900, epoch #621, avg. train loss: 0.16418\n",
      "Step #56000, epoch #622, avg. train loss: 0.16542\n",
      "Step #56100, epoch #623, avg. train loss: 0.16256\n",
      "Step #56200, epoch #624, avg. train loss: 0.16410\n",
      "Step #56300, epoch #625, avg. train loss: 0.16588\n",
      "Step #56400, epoch #626, avg. train loss: 0.16176\n",
      "Step #56500, epoch #627, avg. train loss: 0.16913\n",
      "Step #56600, epoch #628, avg. train loss: 0.16551\n",
      "Step #56700, epoch #630, avg. train loss: 0.16483\n",
      "Step #56800, epoch #631, avg. train loss: 0.16496\n",
      "Step #56900, epoch #632, avg. train loss: 0.16377\n",
      "Step #57000, epoch #633, avg. train loss: 0.16267\n",
      "Step #57100, epoch #634, avg. train loss: 0.16354\n",
      "Step #57200, epoch #635, avg. train loss: 0.16763\n",
      "Step #57300, epoch #636, avg. train loss: 0.16265\n",
      "Step #57400, epoch #637, avg. train loss: 0.16702\n",
      "Step #57500, epoch #638, avg. train loss: 0.16505\n",
      "Step #57600, epoch #640, avg. train loss: 0.16619\n",
      "Step #57700, epoch #641, avg. train loss: 0.16275\n",
      "Step #57800, epoch #642, avg. train loss: 0.16431\n",
      "Step #57900, epoch #643, avg. train loss: 0.16423\n",
      "Step #58000, epoch #644, avg. train loss: 0.16186\n",
      "Step #58100, epoch #645, avg. train loss: 0.16272\n",
      "Step #58200, epoch #646, avg. train loss: 0.16708\n",
      "Step #58300, epoch #647, avg. train loss: 0.16361\n",
      "Step #58400, epoch #648, avg. train loss: 0.16499\n",
      "Step #58500, epoch #650, avg. train loss: 0.16516\n",
      "Step #58600, epoch #651, avg. train loss: 0.16545\n",
      "Step #58700, epoch #652, avg. train loss: 0.16377\n",
      "Step #58800, epoch #653, avg. train loss: 0.16678\n",
      "Step #58900, epoch #654, avg. train loss: 0.16520\n",
      "Step #59000, epoch #655, avg. train loss: 0.16405\n",
      "Step #59100, epoch #656, avg. train loss: 0.16318\n",
      "Step #59200, epoch #657, avg. train loss: 0.16616\n",
      "Step #59300, epoch #658, avg. train loss: 0.16309\n",
      "Step #59400, epoch #660, avg. train loss: 0.16757\n",
      "Step #59500, epoch #661, avg. train loss: 0.16459\n",
      "Step #59600, epoch #662, avg. train loss: 0.16860\n",
      "Step #59700, epoch #663, avg. train loss: 0.16368\n",
      "Step #59800, epoch #664, avg. train loss: 0.16449\n",
      "Step #59900, epoch #665, avg. train loss: 0.16504\n",
      "Step #60000, epoch #666, avg. train loss: 0.16497\n",
      "Step #60100, epoch #667, avg. train loss: 0.16393\n",
      "Step #60200, epoch #668, avg. train loss: 0.16690\n",
      "Step #60300, epoch #670, avg. train loss: 0.16318\n",
      "Step #60400, epoch #671, avg. train loss: 0.16320\n",
      "Step #60500, epoch #672, avg. train loss: 0.16566\n",
      "Step #60600, epoch #673, avg. train loss: 0.16307\n",
      "Step #60700, epoch #674, avg. train loss: 0.16546\n",
      "Step #60800, epoch #675, avg. train loss: 0.16124\n",
      "Step #60900, epoch #676, avg. train loss: 0.16563\n",
      "Step #61000, epoch #677, avg. train loss: 0.16839\n",
      "Step #61100, epoch #678, avg. train loss: 0.16311\n",
      "Step #61200, epoch #680, avg. train loss: 0.16513\n",
      "Step #61300, epoch #681, avg. train loss: 0.16345\n",
      "Step #61400, epoch #682, avg. train loss: 0.16654\n",
      "Step #61500, epoch #683, avg. train loss: 0.16418\n",
      "Step #61600, epoch #684, avg. train loss: 0.16499\n",
      "Step #61700, epoch #685, avg. train loss: 0.16370\n",
      "Step #61800, epoch #686, avg. train loss: 0.16466\n",
      "Step #61900, epoch #687, avg. train loss: 0.16638\n",
      "Step #62000, epoch #688, avg. train loss: 0.16358\n",
      "Step #62100, epoch #690, avg. train loss: 0.16457\n",
      "Step #62200, epoch #691, avg. train loss: 0.16422\n",
      "Step #62300, epoch #692, avg. train loss: 0.16446\n",
      "Step #62400, epoch #693, avg. train loss: 0.16202\n",
      "Step #62500, epoch #694, avg. train loss: 0.16504\n",
      "Step #62600, epoch #695, avg. train loss: 0.16454\n",
      "Step #62700, epoch #696, avg. train loss: 0.16723\n",
      "Step #62800, epoch #697, avg. train loss: 0.16132\n",
      "Step #62900, epoch #698, avg. train loss: 0.16709\n",
      "Step #63000, epoch #700, avg. train loss: 0.16633\n",
      "Step #63100, epoch #701, avg. train loss: 0.16414\n",
      "Step #63200, epoch #702, avg. train loss: 0.16260\n",
      "Step #63300, epoch #703, avg. train loss: 0.16827\n",
      "Step #63400, epoch #704, avg. train loss: 0.16460\n",
      "Step #63500, epoch #705, avg. train loss: 0.16403\n",
      "Step #63600, epoch #706, avg. train loss: 0.16827\n",
      "Step #63700, epoch #707, avg. train loss: 0.16312\n",
      "Step #63800, epoch #708, avg. train loss: 0.16548\n",
      "Step #63900, epoch #710, avg. train loss: 0.16616\n",
      "Step #64000, epoch #711, avg. train loss: 0.16306\n",
      "Step #64100, epoch #712, avg. train loss: 0.16589\n",
      "Step #64200, epoch #713, avg. train loss: 0.16489\n",
      "Step #64300, epoch #714, avg. train loss: 0.16490\n",
      "Step #64400, epoch #715, avg. train loss: 0.16598\n",
      "Step #64500, epoch #716, avg. train loss: 0.16433\n",
      "Step #64600, epoch #717, avg. train loss: 0.16176\n",
      "Step #64700, epoch #718, avg. train loss: 0.16644\n",
      "Step #64800, epoch #720, avg. train loss: 0.16545\n",
      "Step #64900, epoch #721, avg. train loss: 0.16419\n",
      "Step #65000, epoch #722, avg. train loss: 0.16621\n",
      "Step #65100, epoch #723, avg. train loss: 0.16459\n",
      "Step #65200, epoch #724, avg. train loss: 0.16045\n",
      "Step #65300, epoch #725, avg. train loss: 0.16579\n",
      "Step #65400, epoch #726, avg. train loss: 0.16124\n",
      "Step #65500, epoch #727, avg. train loss: 0.16692\n",
      "Step #65600, epoch #728, avg. train loss: 0.16319\n",
      "Step #65700, epoch #730, avg. train loss: 0.16623\n",
      "Step #65800, epoch #731, avg. train loss: 0.16518\n",
      "Step #65900, epoch #732, avg. train loss: 0.16392\n",
      "Step #66000, epoch #733, avg. train loss: 0.16368\n",
      "Step #66100, epoch #734, avg. train loss: 0.16551\n",
      "Step #66200, epoch #735, avg. train loss: 0.16435\n",
      "Step #66300, epoch #736, avg. train loss: 0.16468\n",
      "Step #66400, epoch #737, avg. train loss: 0.16380\n",
      "Step #66500, epoch #738, avg. train loss: 0.16472\n",
      "Step #66600, epoch #740, avg. train loss: 0.16488\n",
      "Step #66700, epoch #741, avg. train loss: 0.16448\n",
      "Step #66800, epoch #742, avg. train loss: 0.16451\n",
      "Step #66900, epoch #743, avg. train loss: 0.16423\n",
      "Step #67000, epoch #744, avg. train loss: 0.16287\n",
      "Step #67100, epoch #745, avg. train loss: 0.16522\n",
      "Step #67200, epoch #746, avg. train loss: 0.16542\n",
      "Step #67300, epoch #747, avg. train loss: 0.16330\n",
      "Step #67400, epoch #748, avg. train loss: 0.16625\n",
      "Step #67500, epoch #750, avg. train loss: 0.16574\n",
      "Step #67600, epoch #751, avg. train loss: 0.16492\n",
      "Step #67700, epoch #752, avg. train loss: 0.16476\n",
      "Step #67800, epoch #753, avg. train loss: 0.16502\n",
      "Step #67900, epoch #754, avg. train loss: 0.16298\n",
      "Step #68000, epoch #755, avg. train loss: 0.16607\n",
      "Step #68100, epoch #756, avg. train loss: 0.16347\n",
      "Step #68200, epoch #757, avg. train loss: 0.16488\n",
      "Step #68300, epoch #758, avg. train loss: 0.16508\n",
      "Step #68400, epoch #760, avg. train loss: 0.16348\n",
      "Step #68500, epoch #761, avg. train loss: 0.16401\n",
      "Step #68600, epoch #762, avg. train loss: 0.16573\n",
      "Step #68700, epoch #763, avg. train loss: 0.16547\n",
      "Step #68800, epoch #764, avg. train loss: 0.16332\n",
      "Step #68900, epoch #765, avg. train loss: 0.16260\n",
      "Step #69000, epoch #766, avg. train loss: 0.16668\n",
      "Step #69100, epoch #767, avg. train loss: 0.16521\n",
      "Step #69200, epoch #768, avg. train loss: 0.16408\n",
      "Step #69300, epoch #770, avg. train loss: 0.16430\n",
      "Step #69400, epoch #771, avg. train loss: 0.16576\n",
      "Step #69500, epoch #772, avg. train loss: 0.16418\n",
      "Step #69600, epoch #773, avg. train loss: 0.16453\n",
      "Step #69700, epoch #774, avg. train loss: 0.16458\n",
      "Step #69800, epoch #775, avg. train loss: 0.16292\n",
      "Step #69900, epoch #776, avg. train loss: 0.16310\n",
      "Step #70000, epoch #777, avg. train loss: 0.16336\n",
      "Step #70100, epoch #778, avg. train loss: 0.16594\n",
      "Step #70200, epoch #780, avg. train loss: 0.16698\n",
      "Step #70300, epoch #781, avg. train loss: 0.16400\n",
      "Step #70400, epoch #782, avg. train loss: 0.16428\n",
      "Step #70500, epoch #783, avg. train loss: 0.16172\n",
      "Step #70600, epoch #784, avg. train loss: 0.16720\n",
      "Step #70700, epoch #785, avg. train loss: 0.16342\n",
      "Step #70800, epoch #786, avg. train loss: 0.16362\n",
      "Step #70900, epoch #787, avg. train loss: 0.16377\n",
      "Step #71000, epoch #788, avg. train loss: 0.16341\n",
      "Step #71100, epoch #790, avg. train loss: 0.16331\n",
      "Step #71200, epoch #791, avg. train loss: 0.16430\n",
      "Step #71300, epoch #792, avg. train loss: 0.16719\n",
      "Step #71400, epoch #793, avg. train loss: 0.16261\n",
      "Step #71500, epoch #794, avg. train loss: 0.16540\n",
      "Step #71600, epoch #795, avg. train loss: 0.16706\n",
      "Step #71700, epoch #796, avg. train loss: 0.16522\n",
      "Step #71800, epoch #797, avg. train loss: 0.16213\n",
      "Step #71900, epoch #798, avg. train loss: 0.16273\n",
      "Step #72000, epoch #800, avg. train loss: 0.16473\n",
      "Step #72100, epoch #801, avg. train loss: 0.16554\n",
      "Step #72200, epoch #802, avg. train loss: 0.16757\n",
      "Step #72300, epoch #803, avg. train loss: 0.16040\n",
      "Step #72400, epoch #804, avg. train loss: 0.16855\n",
      "Step #72500, epoch #805, avg. train loss: 0.16541\n",
      "Step #72600, epoch #806, avg. train loss: 0.16635\n",
      "Step #72700, epoch #807, avg. train loss: 0.16162\n",
      "Step #72800, epoch #808, avg. train loss: 0.16618\n",
      "Step #72900, epoch #810, avg. train loss: 0.16515\n",
      "Step #73000, epoch #811, avg. train loss: 0.16393\n",
      "Step #73100, epoch #812, avg. train loss: 0.16538\n",
      "Step #73200, epoch #813, avg. train loss: 0.16347\n",
      "Step #73300, epoch #814, avg. train loss: 0.16608\n",
      "Step #73400, epoch #815, avg. train loss: 0.16439\n",
      "Step #73500, epoch #816, avg. train loss: 0.16334\n",
      "Step #73600, epoch #817, avg. train loss: 0.16055\n",
      "Step #73700, epoch #818, avg. train loss: 0.16767\n",
      "Step #73800, epoch #820, avg. train loss: 0.16652\n",
      "Step #73900, epoch #821, avg. train loss: 0.16326\n",
      "Step #74000, epoch #822, avg. train loss: 0.16203\n",
      "Step #74100, epoch #823, avg. train loss: 0.16571\n",
      "Step #74200, epoch #824, avg. train loss: 0.16462\n",
      "Step #74300, epoch #825, avg. train loss: 0.16577\n",
      "Step #74400, epoch #826, avg. train loss: 0.16499\n",
      "Step #74500, epoch #827, avg. train loss: 0.16732\n",
      "Step #74600, epoch #828, avg. train loss: 0.16119\n",
      "Step #74700, epoch #830, avg. train loss: 0.16585\n",
      "Step #74800, epoch #831, avg. train loss: 0.16487\n",
      "Step #74900, epoch #832, avg. train loss: 0.16420\n",
      "Step #75000, epoch #833, avg. train loss: 0.16810\n",
      "Step #75100, epoch #834, avg. train loss: 0.16380\n",
      "Step #75200, epoch #835, avg. train loss: 0.16399\n",
      "Step #75300, epoch #836, avg. train loss: 0.16539\n",
      "Step #75400, epoch #837, avg. train loss: 0.16481\n",
      "Step #75500, epoch #838, avg. train loss: 0.16266\n",
      "Step #75600, epoch #840, avg. train loss: 0.16292\n",
      "Step #75700, epoch #841, avg. train loss: 0.16532\n",
      "Step #75800, epoch #842, avg. train loss: 0.16236\n",
      "Step #75900, epoch #843, avg. train loss: 0.16621\n",
      "Step #76000, epoch #844, avg. train loss: 0.16261\n",
      "Step #76100, epoch #845, avg. train loss: 0.16638\n",
      "Step #76200, epoch #846, avg. train loss: 0.16333\n",
      "Step #76300, epoch #847, avg. train loss: 0.16415\n",
      "Step #76400, epoch #848, avg. train loss: 0.16469\n",
      "Step #76500, epoch #850, avg. train loss: 0.16430\n",
      "Step #76600, epoch #851, avg. train loss: 0.16541\n",
      "Step #76700, epoch #852, avg. train loss: 0.16203\n",
      "Step #76800, epoch #853, avg. train loss: 0.16485\n",
      "Step #76900, epoch #854, avg. train loss: 0.16437\n",
      "Step #77000, epoch #855, avg. train loss: 0.16367\n",
      "Step #77100, epoch #856, avg. train loss: 0.16442\n",
      "Step #77200, epoch #857, avg. train loss: 0.16449\n",
      "Step #77300, epoch #858, avg. train loss: 0.16272\n",
      "Step #77400, epoch #860, avg. train loss: 0.16478\n",
      "Step #77500, epoch #861, avg. train loss: 0.16443\n",
      "Step #77600, epoch #862, avg. train loss: 0.16417\n",
      "Step #77700, epoch #863, avg. train loss: 0.16394\n",
      "Step #77800, epoch #864, avg. train loss: 0.16420\n",
      "Step #77900, epoch #865, avg. train loss: 0.16328\n",
      "Step #78000, epoch #866, avg. train loss: 0.16457\n",
      "Step #78100, epoch #867, avg. train loss: 0.16495\n",
      "Step #78200, epoch #868, avg. train loss: 0.16427\n",
      "Step #78300, epoch #870, avg. train loss: 0.16343\n",
      "Step #78400, epoch #871, avg. train loss: 0.16219\n",
      "Step #78500, epoch #872, avg. train loss: 0.16505\n",
      "Step #78600, epoch #873, avg. train loss: 0.16496\n",
      "Step #78700, epoch #874, avg. train loss: 0.16470\n",
      "Step #78800, epoch #875, avg. train loss: 0.16294\n",
      "Step #78900, epoch #876, avg. train loss: 0.16644\n",
      "Step #79000, epoch #877, avg. train loss: 0.16436\n",
      "Step #79100, epoch #878, avg. train loss: 0.16377\n",
      "Step #79200, epoch #880, avg. train loss: 0.16249\n",
      "Step #79300, epoch #881, avg. train loss: 0.16411\n",
      "Step #79400, epoch #882, avg. train loss: 0.16241\n",
      "Step #79500, epoch #883, avg. train loss: 0.16449\n",
      "Step #79600, epoch #884, avg. train loss: 0.16614\n",
      "Step #79700, epoch #885, avg. train loss: 0.16164\n",
      "Step #79800, epoch #886, avg. train loss: 0.16347\n",
      "Step #79900, epoch #887, avg. train loss: 0.16875\n",
      "Step #80000, epoch #888, avg. train loss: 0.16557\n",
      "Step #80100, epoch #890, avg. train loss: 0.16278\n",
      "Step #80200, epoch #891, avg. train loss: 0.16541\n",
      "Step #80300, epoch #892, avg. train loss: 0.16374\n",
      "Step #80400, epoch #893, avg. train loss: 0.16487\n",
      "Step #80500, epoch #894, avg. train loss: 0.16278\n",
      "Step #80600, epoch #895, avg. train loss: 0.16465\n",
      "Step #80700, epoch #896, avg. train loss: 0.17051\n",
      "Step #80800, epoch #897, avg. train loss: 0.16173\n",
      "Step #80900, epoch #898, avg. train loss: 0.16270\n",
      "Step #81000, epoch #900, avg. train loss: 0.16495\n",
      "Step #81100, epoch #901, avg. train loss: 0.16370\n",
      "Step #81200, epoch #902, avg. train loss: 0.16489\n",
      "Step #81300, epoch #903, avg. train loss: 0.16274\n",
      "Step #81400, epoch #904, avg. train loss: 0.16559\n",
      "Step #81500, epoch #905, avg. train loss: 0.16651\n",
      "Step #81600, epoch #906, avg. train loss: 0.16855\n",
      "Step #81700, epoch #907, avg. train loss: 0.16302\n",
      "Step #81800, epoch #908, avg. train loss: 0.16260\n",
      "Step #81900, epoch #910, avg. train loss: 0.16511\n",
      "Step #82000, epoch #911, avg. train loss: 0.16369\n",
      "Step #82100, epoch #912, avg. train loss: 0.16336\n",
      "Step #82200, epoch #913, avg. train loss: 0.16718\n",
      "Step #82300, epoch #914, avg. train loss: 0.16490\n",
      "Step #82400, epoch #915, avg. train loss: 0.16228\n",
      "Step #82500, epoch #916, avg. train loss: 0.16517\n",
      "Step #82600, epoch #917, avg. train loss: 0.16587\n",
      "Step #82700, epoch #918, avg. train loss: 0.16171\n",
      "Step #82800, epoch #920, avg. train loss: 0.16659\n",
      "Step #82900, epoch #921, avg. train loss: 0.16611\n",
      "Step #83000, epoch #922, avg. train loss: 0.16509\n",
      "Step #83100, epoch #923, avg. train loss: 0.16369\n",
      "Step #83200, epoch #924, avg. train loss: 0.16467\n",
      "Step #83300, epoch #925, avg. train loss: 0.16513\n",
      "Step #83400, epoch #926, avg. train loss: 0.16430\n",
      "Step #83500, epoch #927, avg. train loss: 0.16673\n",
      "Step #83600, epoch #928, avg. train loss: 0.16383\n",
      "Step #83700, epoch #930, avg. train loss: 0.16509\n",
      "Step #83800, epoch #931, avg. train loss: 0.16452\n",
      "Step #83900, epoch #932, avg. train loss: 0.16617\n",
      "Step #84000, epoch #933, avg. train loss: 0.16473\n",
      "Step #84100, epoch #934, avg. train loss: 0.16693\n",
      "Step #84200, epoch #935, avg. train loss: 0.16425\n",
      "Step #84300, epoch #936, avg. train loss: 0.16683\n",
      "Step #84400, epoch #937, avg. train loss: 0.16105\n",
      "Step #84500, epoch #938, avg. train loss: 0.16652\n",
      "Step #84600, epoch #940, avg. train loss: 0.16588\n",
      "Step #84700, epoch #941, avg. train loss: 0.16486\n",
      "Step #84800, epoch #942, avg. train loss: 0.16560\n",
      "Step #84900, epoch #943, avg. train loss: 0.16253\n",
      "Step #85000, epoch #944, avg. train loss: 0.16823\n",
      "Step #85100, epoch #945, avg. train loss: 0.16514\n",
      "Step #85200, epoch #946, avg. train loss: 0.16328\n",
      "Step #85300, epoch #947, avg. train loss: 0.16457\n",
      "Step #85400, epoch #948, avg. train loss: 0.16033\n",
      "Step #85500, epoch #950, avg. train loss: 0.16807\n",
      "Step #85600, epoch #951, avg. train loss: 0.16427\n",
      "Step #85700, epoch #952, avg. train loss: 0.16265\n",
      "Step #85800, epoch #953, avg. train loss: 0.16567\n",
      "Step #85900, epoch #954, avg. train loss: 0.16242\n",
      "Step #86000, epoch #955, avg. train loss: 0.16672\n",
      "Step #86100, epoch #956, avg. train loss: 0.16360\n",
      "Step #86200, epoch #957, avg. train loss: 0.16246\n",
      "Step #86300, epoch #958, avg. train loss: 0.16467\n",
      "Step #86400, epoch #960, avg. train loss: 0.16293\n",
      "Step #86500, epoch #961, avg. train loss: 0.16447\n",
      "Step #86600, epoch #962, avg. train loss: 0.16446\n",
      "Step #86700, epoch #963, avg. train loss: 0.16617\n",
      "Step #86800, epoch #964, avg. train loss: 0.16543\n",
      "Step #86900, epoch #965, avg. train loss: 0.16197\n",
      "Step #87000, epoch #966, avg. train loss: 0.16714\n",
      "Step #87100, epoch #967, avg. train loss: 0.16229\n",
      "Step #87200, epoch #968, avg. train loss: 0.16570\n",
      "Step #87300, epoch #970, avg. train loss: 0.16380\n",
      "Step #87400, epoch #971, avg. train loss: 0.16483\n",
      "Step #87500, epoch #972, avg. train loss: 0.16444\n",
      "Step #87600, epoch #973, avg. train loss: 0.16409\n",
      "Step #87700, epoch #974, avg. train loss: 0.16308\n",
      "Step #87800, epoch #975, avg. train loss: 0.16329\n",
      "Step #87900, epoch #976, avg. train loss: 0.16820\n",
      "Step #88000, epoch #977, avg. train loss: 0.16108\n",
      "Step #88100, epoch #978, avg. train loss: 0.16463\n",
      "Step #88200, epoch #980, avg. train loss: 0.16179\n",
      "Step #88300, epoch #981, avg. train loss: 0.16633\n",
      "Step #88400, epoch #982, avg. train loss: 0.16198\n",
      "Step #88500, epoch #983, avg. train loss: 0.16452\n",
      "Step #88600, epoch #984, avg. train loss: 0.16354\n",
      "Step #88700, epoch #985, avg. train loss: 0.16581\n",
      "Step #88800, epoch #986, avg. train loss: 0.16474\n",
      "Step #88900, epoch #987, avg. train loss: 0.16708\n",
      "Step #89000, epoch #988, avg. train loss: 0.16144\n",
      "Step #89100, epoch #990, avg. train loss: 0.16796\n",
      "Step #89200, epoch #991, avg. train loss: 0.16526\n",
      "Step #89300, epoch #992, avg. train loss: 0.16297\n",
      "Step #89400, epoch #993, avg. train loss: 0.16557\n",
      "Step #89500, epoch #994, avg. train loss: 0.16547\n",
      "Step #89600, epoch #995, avg. train loss: 0.16169\n",
      "Step #89700, epoch #996, avg. train loss: 0.16677\n",
      "Step #89800, epoch #997, avg. train loss: 0.16567\n",
      "Step #89900, epoch #998, avg. train loss: 0.16515\n",
      "Step #90000, epoch #1000, avg. train loss: 0.16345\n",
      "Step #90100, epoch #1001, avg. train loss: 0.16442\n",
      "Step #90200, epoch #1002, avg. train loss: 0.16597\n",
      "Step #90300, epoch #1003, avg. train loss: 0.16260\n",
      "Step #90400, epoch #1004, avg. train loss: 0.16571\n",
      "Step #90500, epoch #1005, avg. train loss: 0.16345\n",
      "Step #90600, epoch #1006, avg. train loss: 0.16695\n",
      "Step #90700, epoch #1007, avg. train loss: 0.16352\n",
      "Step #90800, epoch #1008, avg. train loss: 0.16278\n",
      "Step #90900, epoch #1010, avg. train loss: 0.16591\n",
      "Step #91000, epoch #1011, avg. train loss: 0.16452\n",
      "Step #91100, epoch #1012, avg. train loss: 0.16471\n",
      "Step #91200, epoch #1013, avg. train loss: 0.16271\n",
      "Step #91300, epoch #1014, avg. train loss: 0.16772\n",
      "Step #91400, epoch #1015, avg. train loss: 0.16525\n",
      "Step #91500, epoch #1016, avg. train loss: 0.16342\n",
      "Step #91600, epoch #1017, avg. train loss: 0.16332\n",
      "Step #91700, epoch #1018, avg. train loss: 0.16508\n",
      "Step #91800, epoch #1020, avg. train loss: 0.16455\n",
      "Step #91900, epoch #1021, avg. train loss: 0.16547\n",
      "Step #92000, epoch #1022, avg. train loss: 0.16471\n",
      "Step #92100, epoch #1023, avg. train loss: 0.16288\n",
      "Step #92200, epoch #1024, avg. train loss: 0.16449\n",
      "Step #92300, epoch #1025, avg. train loss: 0.16606\n",
      "Step #92400, epoch #1026, avg. train loss: 0.16413\n",
      "Step #92500, epoch #1027, avg. train loss: 0.16689\n",
      "Step #92600, epoch #1028, avg. train loss: 0.16275\n",
      "Step #92700, epoch #1030, avg. train loss: 0.16598\n",
      "Step #92800, epoch #1031, avg. train loss: 0.16453\n",
      "Step #92900, epoch #1032, avg. train loss: 0.16267\n",
      "Step #93000, epoch #1033, avg. train loss: 0.16561\n",
      "Step #93100, epoch #1034, avg. train loss: 0.16366\n",
      "Step #93200, epoch #1035, avg. train loss: 0.16406\n",
      "Step #93300, epoch #1036, avg. train loss: 0.16427\n",
      "Step #93400, epoch #1037, avg. train loss: 0.16351\n",
      "Step #93500, epoch #1038, avg. train loss: 0.16445\n",
      "Step #93600, epoch #1040, avg. train loss: 0.16325\n",
      "Step #93700, epoch #1041, avg. train loss: 0.16460\n",
      "Step #93800, epoch #1042, avg. train loss: 0.16402\n",
      "Step #93900, epoch #1043, avg. train loss: 0.16453\n",
      "Step #94000, epoch #1044, avg. train loss: 0.16446\n",
      "Step #94100, epoch #1045, avg. train loss: 0.16147\n",
      "Step #94200, epoch #1046, avg. train loss: 0.16620\n",
      "Step #94300, epoch #1047, avg. train loss: 0.16504\n",
      "Step #94400, epoch #1048, avg. train loss: 0.16438\n",
      "Step #94500, epoch #1050, avg. train loss: 0.16207\n",
      "Step #94600, epoch #1051, avg. train loss: 0.16336\n",
      "Step #94700, epoch #1052, avg. train loss: 0.16609\n",
      "Step #94800, epoch #1053, avg. train loss: 0.16183\n",
      "Step #94900, epoch #1054, avg. train loss: 0.16420\n",
      "Step #95000, epoch #1055, avg. train loss: 0.16428\n",
      "Step #95100, epoch #1056, avg. train loss: 0.16476\n",
      "Step #95200, epoch #1057, avg. train loss: 0.16500\n",
      "Step #95300, epoch #1058, avg. train loss: 0.16561\n",
      "Step #95400, epoch #1060, avg. train loss: 0.16496\n",
      "Step #95500, epoch #1061, avg. train loss: 0.16417\n",
      "Step #95600, epoch #1062, avg. train loss: 0.16741\n",
      "Step #95700, epoch #1063, avg. train loss: 0.16259\n",
      "Step #95800, epoch #1064, avg. train loss: 0.16698\n",
      "Step #95900, epoch #1065, avg. train loss: 0.16537\n",
      "Step #96000, epoch #1066, avg. train loss: 0.15994\n",
      "Step #96100, epoch #1067, avg. train loss: 0.16721\n",
      "Step #96200, epoch #1068, avg. train loss: 0.16413\n",
      "Step #96300, epoch #1070, avg. train loss: 0.16761\n",
      "Step #96400, epoch #1071, avg. train loss: 0.16468\n",
      "Step #96500, epoch #1072, avg. train loss: 0.16195\n",
      "Step #96600, epoch #1073, avg. train loss: 0.16656\n",
      "Step #96700, epoch #1074, avg. train loss: 0.16127\n",
      "Step #96800, epoch #1075, avg. train loss: 0.16558\n",
      "Step #96900, epoch #1076, avg. train loss: 0.16434\n",
      "Step #97000, epoch #1077, avg. train loss: 0.16393\n",
      "Step #97100, epoch #1078, avg. train loss: 0.16684\n",
      "Step #97200, epoch #1080, avg. train loss: 0.16290\n",
      "Step #97300, epoch #1081, avg. train loss: 0.16757\n",
      "Step #97400, epoch #1082, avg. train loss: 0.16364\n",
      "Step #97500, epoch #1083, avg. train loss: 0.16162\n",
      "Step #97600, epoch #1084, avg. train loss: 0.16212\n",
      "Step #97700, epoch #1085, avg. train loss: 0.16730\n",
      "Step #97800, epoch #1086, avg. train loss: 0.16579\n",
      "Step #97900, epoch #1087, avg. train loss: 0.16083\n",
      "Step #98000, epoch #1088, avg. train loss: 0.16971\n",
      "Step #98100, epoch #1090, avg. train loss: 0.16437\n",
      "Step #98200, epoch #1091, avg. train loss: 0.16500\n",
      "Step #98300, epoch #1092, avg. train loss: 0.16471\n",
      "Step #98400, epoch #1093, avg. train loss: 0.16497\n",
      "Step #98500, epoch #1094, avg. train loss: 0.16618\n",
      "Step #98600, epoch #1095, avg. train loss: 0.16714\n",
      "Step #98700, epoch #1096, avg. train loss: 0.16447\n",
      "Step #98800, epoch #1097, avg. train loss: 0.16461\n",
      "Step #98900, epoch #1098, avg. train loss: 0.16196\n",
      "Step #99000, epoch #1100, avg. train loss: 0.16564\n",
      "Step #99100, epoch #1101, avg. train loss: 0.16494\n",
      "Step #99200, epoch #1102, avg. train loss: 0.16596\n",
      "Step #99300, epoch #1103, avg. train loss: 0.16461\n",
      "Step #99400, epoch #1104, avg. train loss: 0.16545\n",
      "Step #99500, epoch #1105, avg. train loss: 0.16335\n",
      "Step #99600, epoch #1106, avg. train loss: 0.16388\n",
      "Step #99700, epoch #1107, avg. train loss: 0.16589\n",
      "Step #99800, epoch #1108, avg. train loss: 0.16150\n",
      "Step #99900, epoch #1110, avg. train loss: 0.16443\n",
      "Step #100000, epoch #1111, avg. train loss: 0.16283\n",
      "ROC =  0.5\n",
      "dnn4\n",
      "Step #100, epoch #1, avg. train loss: 45315.46875\n",
      "Step #200, epoch #2, avg. train loss: 0.38222\n",
      "Step #300, epoch #3, avg. train loss: 0.38160\n",
      "Step #400, epoch #4, avg. train loss: 8.85850\n",
      "Step #500, epoch #5, avg. train loss: 0.28793\n",
      "Step #600, epoch #6, avg. train loss: 1.06968\n",
      "Step #700, epoch #7, avg. train loss: 0.20867\n",
      "Step #800, epoch #8, avg. train loss: 0.20065\n",
      "Step #900, epoch #10, avg. train loss: 0.19011\n",
      "Step #1000, epoch #11, avg. train loss: 0.18712\n",
      "Step #1100, epoch #12, avg. train loss: 0.17918\n",
      "Step #1200, epoch #13, avg. train loss: 0.18605\n",
      "Step #1300, epoch #14, avg. train loss: 0.18154\n",
      "Step #1400, epoch #15, avg. train loss: 0.18376\n",
      "Step #1500, epoch #16, avg. train loss: 0.18086\n",
      "Step #1600, epoch #17, avg. train loss: 0.18627\n",
      "Step #1700, epoch #18, avg. train loss: 0.17956\n",
      "Step #1800, epoch #20, avg. train loss: 0.17984\n",
      "Step #1900, epoch #21, avg. train loss: 0.18000\n",
      "Step #2000, epoch #22, avg. train loss: 0.17889\n",
      "Step #2100, epoch #23, avg. train loss: 0.17885\n",
      "Step #2200, epoch #24, avg. train loss: 0.17819\n",
      "Step #2300, epoch #25, avg. train loss: 0.17511\n",
      "Step #2400, epoch #26, avg. train loss: 0.18051\n",
      "Step #2500, epoch #27, avg. train loss: 0.17413\n",
      "Step #2600, epoch #28, avg. train loss: 0.17838\n",
      "Step #2700, epoch #30, avg. train loss: 0.17408\n",
      "Step #2800, epoch #31, avg. train loss: 0.17438\n",
      "Step #2900, epoch #32, avg. train loss: 0.17585\n",
      "Step #3000, epoch #33, avg. train loss: 0.17521\n",
      "Step #3100, epoch #34, avg. train loss: 0.17551\n",
      "Step #3200, epoch #35, avg. train loss: 0.17464\n",
      "Step #3300, epoch #36, avg. train loss: 0.17435\n",
      "Step #3400, epoch #37, avg. train loss: 0.17425\n",
      "Step #3500, epoch #38, avg. train loss: 0.17472\n",
      "Step #3600, epoch #40, avg. train loss: 0.17472\n",
      "Step #3700, epoch #41, avg. train loss: 0.17218\n",
      "Step #3800, epoch #42, avg. train loss: 0.17317\n",
      "Step #3900, epoch #43, avg. train loss: 0.17390\n",
      "Step #4000, epoch #44, avg. train loss: 0.17173\n",
      "Step #4100, epoch #45, avg. train loss: 0.17478\n",
      "Step #4200, epoch #46, avg. train loss: 0.17191\n",
      "Step #4300, epoch #47, avg. train loss: 0.17197\n",
      "Step #4400, epoch #48, avg. train loss: 0.17422\n",
      "Step #4500, epoch #50, avg. train loss: 0.17300\n",
      "Step #4600, epoch #51, avg. train loss: 0.17621\n",
      "Step #4700, epoch #52, avg. train loss: 0.17367\n",
      "Step #4800, epoch #53, avg. train loss: 0.17205\n",
      "Step #4900, epoch #54, avg. train loss: 0.17508\n",
      "Step #5000, epoch #55, avg. train loss: 0.17230\n",
      "Step #5100, epoch #56, avg. train loss: 0.16956\n",
      "Step #5200, epoch #57, avg. train loss: 0.17452\n",
      "Step #5300, epoch #58, avg. train loss: 0.17199\n",
      "Step #5400, epoch #60, avg. train loss: 0.17314\n",
      "Step #5500, epoch #61, avg. train loss: 0.17205\n",
      "Step #5600, epoch #62, avg. train loss: 0.17005\n",
      "Step #5700, epoch #63, avg. train loss: 0.17352\n",
      "Step #5800, epoch #64, avg. train loss: 0.17240\n",
      "Step #5900, epoch #65, avg. train loss: 0.17053\n",
      "Step #6000, epoch #66, avg. train loss: 0.17434\n",
      "Step #6100, epoch #67, avg. train loss: 0.17121\n",
      "Step #6200, epoch #68, avg. train loss: 0.17044\n",
      "Step #6300, epoch #70, avg. train loss: 0.17245\n",
      "Step #6400, epoch #71, avg. train loss: 0.17007\n",
      "Step #6500, epoch #72, avg. train loss: 0.17293\n",
      "Step #6600, epoch #73, avg. train loss: 0.17095\n",
      "Step #6700, epoch #74, avg. train loss: 0.17360\n",
      "Step #6800, epoch #75, avg. train loss: 0.17040\n",
      "Step #6900, epoch #76, avg. train loss: 0.17071\n",
      "Step #7000, epoch #77, avg. train loss: 0.16882\n",
      "Step #7100, epoch #78, avg. train loss: 0.17357\n",
      "Step #7200, epoch #80, avg. train loss: 0.17456\n",
      "Step #7300, epoch #81, avg. train loss: 0.17121\n",
      "Step #7400, epoch #82, avg. train loss: 0.17103\n",
      "Step #7500, epoch #83, avg. train loss: 0.16987\n",
      "Step #7600, epoch #84, avg. train loss: 0.17423\n",
      "Step #7700, epoch #85, avg. train loss: 0.17071\n",
      "Step #7800, epoch #86, avg. train loss: 0.17020\n",
      "Step #7900, epoch #87, avg. train loss: 0.16845\n",
      "Step #8000, epoch #88, avg. train loss: 0.17137\n",
      "Step #8100, epoch #90, avg. train loss: 0.16963\n",
      "Step #8200, epoch #91, avg. train loss: 0.17043\n",
      "Step #8300, epoch #92, avg. train loss: 0.17154\n",
      "Step #8400, epoch #93, avg. train loss: 0.16678\n",
      "Step #8500, epoch #94, avg. train loss: 0.16968\n",
      "Step #8600, epoch #95, avg. train loss: 0.17054\n",
      "Step #8700, epoch #96, avg. train loss: 0.16964\n",
      "Step #8800, epoch #97, avg. train loss: 0.17088\n",
      "Step #8900, epoch #98, avg. train loss: 0.16725\n",
      "Step #9000, epoch #100, avg. train loss: 0.17013\n",
      "Step #9100, epoch #101, avg. train loss: 0.16836\n",
      "Step #9200, epoch #102, avg. train loss: 0.17142\n",
      "Step #9300, epoch #103, avg. train loss: 0.16509\n",
      "Step #9400, epoch #104, avg. train loss: 0.16956\n",
      "Step #9500, epoch #105, avg. train loss: 0.16965\n",
      "Step #9600, epoch #106, avg. train loss: 0.17063\n",
      "Step #9700, epoch #107, avg. train loss: 0.16906\n",
      "Step #9800, epoch #108, avg. train loss: 0.17135\n",
      "Step #9900, epoch #110, avg. train loss: 0.16654\n",
      "Step #10000, epoch #111, avg. train loss: 0.16905\n",
      "ROC =  0.499982862039\n",
      "All done.\n"
     ]
    }
   ],
   "source": [
    "# note there's TensorFlowDNNClassifier & TensorFlowDNNRegressor\n",
    "\n",
    "names = [\"dnn0\",\n",
    "        \"dnn1\",\n",
    "        \"dnn2\",\n",
    "        \"dnn3\",\n",
    "        \"dnn4\"]\n",
    "\n",
    "dnn0 = skflow.TensorFlowDNNClassifier(\n",
    "    hidden_units=[370, 100, 10], \n",
    "    n_classes=2, \n",
    "    batch_size=512, \n",
    "    steps=10000, \n",
    "    learning_rate=0.01)\n",
    "\n",
    "dnn1 = skflow.TensorFlowDNNClassifier(\n",
    "        hidden_units=[10, 100, 10], # [1000, 500, 100, 10]\n",
    "        n_classes=2,\n",
    "        batch_size=512,\n",
    "        optimizer=\"Adam\",\n",
    "        steps=100000,\n",
    "        dropout=0.5,\n",
    "        learning_rate=0.01,\n",
    "        continue_training=False)\n",
    "\n",
    "dnn2 = skflow.TensorFlowDNNClassifier(\n",
    "        hidden_units=[10, 10, 10, 10, 10], # [1000, 500, 100, 10]\n",
    "        n_classes=2,\n",
    "        batch_size=512,\n",
    "        optimizer=\"Adam\",\n",
    "        steps=100000,\n",
    "        dropout=0.5,\n",
    "        learning_rate=0.01,\n",
    "        continue_training=False)\n",
    "\n",
    "dnn3 = skflow.TensorFlowDNNClassifier(\n",
    "        hidden_units=[500, 100, 10], # [1000, 500, 100, 10]\n",
    "        n_classes=2,\n",
    "        batch_size=512,\n",
    "        optimizer=\"Adam\",\n",
    "        steps=100000,\n",
    "        dropout=0.5,\n",
    "        learning_rate=0.01,\n",
    "        continue_training=False)\n",
    "\n",
    "dnn4 = skflow.TensorFlowDNNClassifier(\n",
    "    hidden_units=[370, 100, 10], \n",
    "    n_classes=2, \n",
    "    batch_size=512, \n",
    "    steps=10000, \n",
    "    learning_rate=0.01)\n",
    "\n",
    "# this was submit1\n",
    "# train.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))\n",
    "\n",
    "# classifier = skflow.TensorFlowDNNClassifier(hidden_units=[370, 100, 10], \n",
    "#                                             n_classes=2, batch_size=512, steps=10000, learning_rate=0.01)\n",
    "\n",
    "# classifier.fit(train, train_target)\n",
    "\n",
    "classifiers = [\n",
    "    dnn0,\n",
    "    dnn1,\n",
    "    dnn2,\n",
    "    dnn3,\n",
    "    dnn4\n",
    "    ]\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# iterate over classifiers\n",
    "for name, clf in zip(names, classifiers):\n",
    "    print(name)\n",
    "    clf.fit(X_train, y_train)\n",
    "    result = clf.predict(X_test)\n",
    "    print(\"ROC = \",roc_auc_score(y_test, result))\n",
    "    \n",
    "print(\"All done.\")\n",
    "    \n",
    "# filling target values with 0s will yield ROC = 0.5\n",
    "# current Kaggle leader has ROC = 0.844038\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
