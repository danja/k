{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:31:31\n",
      "(76020, 371)\n",
      "(103092, 369)\n",
      "(103092,)\n",
      "10:31:35\n",
      "Step #99, avg. train loss: 37736.20312\n",
      "Step #199, avg. train loss: 155.95708\n",
      "Step #300, epoch #1, avg. train loss: 0.60174\n",
      "Step #400, epoch #1, avg. train loss: 0.60432\n",
      "Step #500, epoch #2, avg. train loss: 0.60368\n",
      "Step #600, epoch #2, avg. train loss: 0.60124\n",
      "Step #700, epoch #3, avg. train loss: 0.60206\n",
      "Step #800, epoch #3, avg. train loss: 0.60258\n",
      "Step #900, epoch #4, avg. train loss: 0.60269\n",
      "Step #1000, epoch #4, avg. train loss: 0.60084\n",
      "Step #1100, epoch #5, avg. train loss: 0.60256\n",
      "Step #1200, epoch #5, avg. train loss: 0.60212\n",
      "Step #1300, epoch #6, avg. train loss: 21.86688\n",
      "Step #1400, epoch #6, avg. train loss: 0.60102\n",
      "Step #1500, epoch #7, avg. train loss: 0.60253\n",
      "Step #1600, epoch #7, avg. train loss: 0.59988\n",
      "Step #1700, epoch #8, avg. train loss: 0.60162\n",
      "Step #1800, epoch #8, avg. train loss: 0.60136\n",
      "Step #1900, epoch #9, avg. train loss: 0.60066\n",
      "Step #2000, epoch #9, avg. train loss: 0.59997\n",
      "Step #2100, epoch #10, avg. train loss: 0.60140\n",
      "Step #2200, epoch #10, avg. train loss: 0.60135\n",
      "Step #2300, epoch #11, avg. train loss: 0.60257\n",
      "Step #2400, epoch #11, avg. train loss: 0.60269\n",
      "Step #2500, epoch #12, avg. train loss: 0.59918\n",
      "Step #2600, epoch #12, avg. train loss: 0.60252\n",
      "Step #2700, epoch #13, avg. train loss: 0.60118\n",
      "Step #2800, epoch #13, avg. train loss: 0.60038\n",
      "Step #2900, epoch #14, avg. train loss: 0.59950\n",
      "Step #3000, epoch #14, avg. train loss: 0.60195\n",
      "Step #3100, epoch #15, avg. train loss: 0.60142\n",
      "Step #3200, epoch #15, avg. train loss: 0.60219\n",
      "Step #3300, epoch #16, avg. train loss: 0.60111\n",
      "Step #3400, epoch #16, avg. train loss: 0.60226\n",
      "Step #3500, epoch #17, avg. train loss: 0.60112\n",
      "Step #3600, epoch #17, avg. train loss: 0.60038\n",
      "Step #3700, epoch #18, avg. train loss: 0.60358\n",
      "Step #3800, epoch #18, avg. train loss: 0.60734\n",
      "Step #3900, epoch #19, avg. train loss: 0.60410\n",
      "Step #4000, epoch #19, avg. train loss: 0.59890\n",
      "Step #4100, epoch #20, avg. train loss: 0.59711\n",
      "Step #4200, epoch #20, avg. train loss: 0.59786\n",
      "Step #4300, epoch #21, avg. train loss: 0.59561\n",
      "Step #4400, epoch #21, avg. train loss: 2.67400\n",
      "Step #4500, epoch #22, avg. train loss: 4.48420\n",
      "Step #4600, epoch #22, avg. train loss: 13.93225\n",
      "Step #4700, epoch #23, avg. train loss: 0.59616\n",
      "Step #4800, epoch #23, avg. train loss: 0.59612\n",
      "Step #4900, epoch #24, avg. train loss: 9.06247\n",
      "Step #5000, epoch #24, avg. train loss: 3.44324\n",
      "Step #5100, epoch #25, avg. train loss: 2.67360\n",
      "Step #5200, epoch #25, avg. train loss: 0.61082\n",
      "Step #5300, epoch #26, avg. train loss: 0.59617\n",
      "Step #5400, epoch #26, avg. train loss: 0.60663\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import gmtime, strftime\n",
    "\n",
    "import tensorflow.contrib.learn as skflow\n",
    "from sklearn import datasets, metrics\n",
    "\n",
    "print(strftime(\"%H:%M:%S\", gmtime()))\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "\n",
    "print(train.shape)\n",
    "\n",
    "train_true = train[train['TARGET'] == 1]\n",
    "\n",
    "for num in range(0,9): \n",
    "    train = pd.concat([train_true, train])\n",
    "\n",
    "train.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "train_id = train.pop('ID')\n",
    "train_target = train.pop('TARGET')\n",
    "\n",
    "print(train.shape)\n",
    "\n",
    "print(train_target.shape)\n",
    "\n",
    "print(strftime(\"%H:%M:%S\", gmtime()))\n",
    "\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "train.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))\n",
    "\n",
    "classifier = skflow.TensorFlowDNNClassifier(hidden_units=[370, 100, 10], \n",
    "                                            n_classes=2, batch_size=512, steps=10000, learning_rate=0.01)\n",
    "# classifier = skflow.TensorFlowLinearClassifier(n_classes=2)\n",
    "\n",
    "classifier.fit(train, train_target)\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "id = test.pop('ID')\n",
    "\n",
    "test.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))\n",
    "\n",
    "print(test.shape)\n",
    "\n",
    "result = classifier.predict(test)\n",
    "\n",
    "print(result.shape)\n",
    "\n",
    "print(result)\n",
    "\n",
    "# df['TARGET'] = pd.DataFrame(result)\n",
    "\n",
    "# df['ID'] = id\n",
    "\n",
    "#df = pd.concat([id, result[0]], axis=1)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "'ID' : id,\n",
    "'TARGET' : result\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "df.to_csv('submit1.csv', sep=',', encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
